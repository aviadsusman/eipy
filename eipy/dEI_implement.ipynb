{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import eipy.ei as e\n",
    "import tensorflow as tf\n",
    "import pickle as pkl\n",
    "from skimage.transform import resize\n",
    "from importlib import reload\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from eipy.additional_ensembles import MeanAggregation, CES\n",
    "from eipy.metrics import fmax_score\n",
    "from sklearn.metrics import roc_auc_score, matthews_corrcoef\n",
    "from keras import layers, models\n",
    "from keras.applications import ResNet50, MobileNet, InceptionV3, DenseNet121\n",
    "import keras\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.neural_network._multilayer_perceptron.MLPClassifier"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(MLPClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_predictors = {\n",
    "                    'Mean' : MeanAggregation(),\n",
    "                    'CES' : CES(scoring=lambda y_test, y_pred: fmax_score(y_test, y_pred)[0]),\n",
    "                    'S.ADAB': AdaBoostClassifier(),\n",
    "                    'S.XGB': XGBClassifier(),\n",
    "                    'S.DT': DecisionTreeClassifier(),\n",
    "                    \"S.RF\": RandomForestClassifier(),\n",
    "                    'S.GB': GradientBoostingClassifier(),\n",
    "                    'S.KNN': KNeighborsClassifier(),\n",
    "                    'S.LR': LogisticRegression(),\n",
    "                    'S.NB': GaussianNB(),\n",
    "                    'S.MLP': MLPClassifier(),\n",
    "                    'S.SVM': SVC(probability=True),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    }
   ],
   "source": [
    "res_model = ResNet50(weights='imagenet', include_top=False)\n",
    "for layer in res_model.layers:\n",
    "    layer.trainable = False\n",
    "collecting_layer = layers.GlobalAveragePooling2D()(res_model.output)\n",
    "output_layer = layers.Dense(1, activation='sigmoid')(collecting_layer)\n",
    "res_model = models.Model(inputs=res_model.input, outputs=output_layer)\n",
    "res_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "base_model = MobileNet(weights='imagenet', include_top=False)\n",
    "x = base_model.output\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "predictions = layers.Dense(1, activation='sigmoid')(x)\n",
    "net_model = models.Model(inputs=base_model.input, outputs=predictions)\n",
    "net_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "pretrained_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "for layer in pretrained_model.layers:\n",
    "    layer.trainable = False\n",
    "collecting_layer = layers.GlobalAveragePooling2D()(pretrained_model.output)\n",
    "output_layer = layers.Dense(1, activation='sigmoid')(collecting_layer)\n",
    "v3_model = models.Model(inputs=pretrained_model.input, outputs=output_layer)\n",
    "v3_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "dense_model = DenseNet121(weights='imagenet', include_top=False)\n",
    "for layer in pretrained_model.layers:\n",
    "    layer.trainable = False\n",
    "collecting_layer = layers.GlobalAveragePooling2D()(pretrained_model.output)\n",
    "output_layer = layers.Dense(1, activation='sigmoid')(collecting_layer)\n",
    "dense121_model = models.Model(inputs=pretrained_model.input, outputs=output_layer)\n",
    "dense121_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "base_predictors = {\n",
    "                   \"MobileNet\" : net_model,\n",
    "                #    \"Inception\" : v3_model,\n",
    "                #    \"ResNet\" : res_model,\n",
    "                   \"DenseNet\" : dense121_model\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\n",
    "            'f_max': fmax_score,\n",
    "            'auc': roc_auc_score,\n",
    "            'mcc': matthews_corrcoef\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 100\n",
    "X_train, y_train = X_train[:train_size], y_train[:train_size]\n",
    "X_test, y_test = X_test[train_size:train_size+int(train_size/10)], y_test[train_size:train_size+int(train_size/10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "inanimate_labels=[0,1,8,9]\n",
    "def binarize_array(arr):\n",
    "    mask = np.isin(arr, inanimate_labels)\n",
    "\n",
    "    arr = np.where(mask, 0, 1)\n",
    "\n",
    "    return arr\n",
    "y_train = binarize_array(y_train)\n",
    "y_test = binarize_array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_size = (224, 224)\n",
    "\n",
    "X_train_resized = np.empty((X_train.shape[0], new_size[0], new_size[1], 3))\n",
    "X_test_resized = np.empty((X_test.shape[0], new_size[0], new_size[1], 3))\n",
    "\n",
    "for i in range(X_train.shape[0]):\n",
    "    X_train_resized[i] = resize(X_train[i], new_size, preserve_range=True, mode='reflect')\n",
    "for i in range(X_test.shape[0]):\n",
    "    X_test_resized[i] = resize(X_test[i], new_size, preserve_range=True, mode='reflect')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# sanity check\\nfrom sklearn.metrics import accuracy_score\\nres_model.fit(X_train_resized, y_train, batch_size=20)\\ny_pred = res_model.predict(X_test_resized)\\ny_pred_argmax = [y > 0.5 for y in y_pred]\\ny_pred, y_pred_argmax\\naccuracy_score(y_pred_argmax, y_test)\\n'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# sanity check\n",
    "from sklearn.metrics import accuracy_score\n",
    "res_model.fit(X_train_resized, y_train, batch_size=20)\n",
    "y_pred = res_model.predict(X_test_resized)\n",
    "y_pred_argmax = [y > 0.5 for y in y_pred]\n",
    "y_pred, y_pred_argmax\n",
    "accuracy_score(y_pred_argmax, y_test)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'eipy.ei' from '/home/opc/eipy/eipy/ei.py'>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####HI OVER HERE###\n",
    "reload(e)\n",
    "###HEYOOOOOO#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "EI = e.EnsembleIntegration(\n",
    "                        base_predictors=base_predictors,\n",
    "                        k_outer=2,\n",
    "                        k_inner=2,\n",
    "                        n_samples=2,\n",
    "                        sampling_strategy=\"hybrid\",\n",
    "                        sampling_aggregation=\"mean\",\n",
    "                        n_jobs=-1,\n",
    "                        metrics=metrics,\n",
    "                        random_state=38,\n",
    "                        project_name=\"dl\",\n",
    "                        model_building=True,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training base predictors on images...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_fit_base() got an unexpected keyword argument 'base_predictors'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mEI\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_base\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_resized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodality_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/eipy/eipy/ei.py:232\u001b[0m, in \u001b[0;36mEnsembleIntegration.fit_base\u001b[0;34m(self, X, y, base_predictors, modality_name)\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_base(\n\u001b[1;32m    226\u001b[0m             X\u001b[38;5;241m=\u001b[39mmodality,\n\u001b[1;32m    227\u001b[0m             y\u001b[38;5;241m=\u001b[39my,\n\u001b[1;32m    228\u001b[0m             base_predictors\u001b[38;5;241m=\u001b[39mbase_predictors,\n\u001b[1;32m    229\u001b[0m             modality_name\u001b[38;5;241m=\u001b[39mmodality_name,\n\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 232\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_base\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_predictors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_predictors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodality_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodality_name\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/sklearn/utils/_testing.py:188\u001b[0m, in \u001b[0;36m_IgnoreWarnings.__call__.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[1;32m    187\u001b[0m     warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcategory)\n\u001b[0;32m--> 188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: _fit_base() got an unexpected keyword argument 'base_predictors'"
     ]
    }
   ],
   "source": [
    "EI.fit_base(X_train_resized, y_train, modality_name=\"images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>modality</th>\n",
       "      <th colspan=\"2\" halign=\"left\">images</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base predictor</th>\n",
       "      <th>DenseNet</th>\n",
       "      <th>MobileNet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f_max</th>\n",
       "      <td>0.550725</td>\n",
       "      <td>0.681319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auc</th>\n",
       "      <td>0.566426</td>\n",
       "      <td>0.764431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mcc</th>\n",
       "      <td>0.142498</td>\n",
       "      <td>0.429995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "modality          images          \n",
       "base predictor  DenseNet MobileNet\n",
       "f_max           0.550725  0.681319\n",
       "auc             0.566426  0.764431\n",
       "mcc             0.142498  0.429995"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EI.base_summary[\"metrics\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing ensembles: |██████████|100%\n",
      "Training final ensemble models: |██████████|100%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<eipy.ei.EnsembleIntegration at 0x7fc1dc0a0b80>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EI.fit_ensemble(ensemble_predictors=ensemble_predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>CES</th>\n",
       "      <th>S.ADAB</th>\n",
       "      <th>S.XGB</th>\n",
       "      <th>S.DT</th>\n",
       "      <th>S.RF</th>\n",
       "      <th>S.GB</th>\n",
       "      <th>S.KNN</th>\n",
       "      <th>S.LR</th>\n",
       "      <th>S.NB</th>\n",
       "      <th>S.MLP</th>\n",
       "      <th>S.SVM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f_max</th>\n",
       "      <td>0.659794</td>\n",
       "      <td>0.659794</td>\n",
       "      <td>0.550725</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.550725</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.550725</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.701299</td>\n",
       "      <td>0.579710</td>\n",
       "      <td>0.701299</td>\n",
       "      <td>0.675676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auc</th>\n",
       "      <td>0.717742</td>\n",
       "      <td>0.717742</td>\n",
       "      <td>0.643039</td>\n",
       "      <td>0.719015</td>\n",
       "      <td>0.643039</td>\n",
       "      <td>0.720076</td>\n",
       "      <td>0.643039</td>\n",
       "      <td>0.731324</td>\n",
       "      <td>0.752971</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.754669</td>\n",
       "      <td>0.660017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mcc</th>\n",
       "      <td>0.257926</td>\n",
       "      <td>0.257926</td>\n",
       "      <td>0.312773</td>\n",
       "      <td>0.442946</td>\n",
       "      <td>0.312773</td>\n",
       "      <td>0.386635</td>\n",
       "      <td>0.312773</td>\n",
       "      <td>0.462174</td>\n",
       "      <td>0.359178</td>\n",
       "      <td>0.330331</td>\n",
       "      <td>0.359178</td>\n",
       "      <td>0.366167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Mean       CES    S.ADAB     S.XGB      S.DT      S.RF      S.GB  \\\n",
       "f_max  0.659794  0.659794  0.550725  0.648649  0.550725  0.675000  0.550725   \n",
       "auc    0.717742  0.717742  0.643039  0.719015  0.643039  0.720076  0.643039   \n",
       "mcc    0.257926  0.257926  0.312773  0.442946  0.312773  0.386635  0.312773   \n",
       "\n",
       "          S.KNN      S.LR      S.NB     S.MLP     S.SVM  \n",
       "f_max  0.666667  0.701299  0.579710  0.701299  0.675676  \n",
       "auc    0.731324  0.752971  0.677419  0.754669  0.660017  \n",
       "mcc    0.462174  0.359178  0.330331  0.359178  0.366167  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EI.ensemble_summary[\"metrics\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 297ms/step\n",
      "1/1 [==============================] - 0s 314ms/step\n",
      "1/1 [==============================] - 1s 833ms/step\n",
      "WARNING:tensorflow:5 out of the last 85 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc23005f8b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 829ms/step\n"
     ]
    }
   ],
   "source": [
    "preferred_ensemble_key = EI.ensemble_summary[\"metrics\"].loc[\"auc\"].idxmax()\n",
    "X_test_dict = {\"images\": X_test_resized}\n",
    "y_pred = EI.predict(X_test_dict, ensemble_model_key=preferred_ensemble_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = [y > 0.5 for y in y_pred]\n",
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<class 'sklearn.linear_model._logistic.LogisticRegression'>\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "str(type(LogisticRegression()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
