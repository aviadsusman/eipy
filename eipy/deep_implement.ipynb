{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-07 17:12:46.549155: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-07 17:12:46.579360: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-07 17:12:46.579403: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-07 17:12:46.580232: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-07 17:12:46.585476: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-07 17:12:46.586068: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-07 17:12:47.408030: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "import pickle as pkl\n",
    "import eipy.deep_ei as d\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eipy.metrics import fmax_score, fmax_precision_recall_threshold\n",
    "from sklearn.metrics import roc_auc_score, matthews_corrcoef\n",
    "\n",
    "metric_funs = {\n",
    "            'f_max': fmax_score,\n",
    "            'auc': roc_auc_score,\n",
    "            'mcc': matthews_corrcoef\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "inanimate_labels=[0,1,8,9]\n",
    "def binarize_array(arr):\n",
    "    mask = np.isin(arr, inanimate_labels)\n",
    "\n",
    "    arr = np.where(mask, 0, 1)\n",
    "\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = binarize_array(y_train)\n",
    "y_test = binarize_array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# with open(\"/home/opc/block_vol/cifar_10_resized_224/X_train.pkl\", \"rb\") as file:\n",
    "#     X_train_resized=pkl.load(file=file)\n",
    "# file.close()\n",
    "# with open(\"/home/opc/block_vol/cifar_10_resized_224/X_test.pkl\", \"rb\") as file:\n",
    "#     X_test_resized=pkl.load(file=file)\n",
    "# file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "new_size = (224, 224)\n",
    "\n",
    "X_train_resized = np.empty((X_train.shape[0], new_size[0], new_size[1], 3))\n",
    "X_test_resized = np.empty((X_test.shape[0], new_size[0], new_size[1], 3))\n",
    "\n",
    "for i in range(X_train.shape[0]):\n",
    "    X_train_resized[i] = resize(X_train[i], new_size, preserve_range=True, mode='reflect')\n",
    "for i in range(X_test.shape[0]):\n",
    "    X_test_resized[i] = resize(X_test[i], new_size, preserve_range=True, mode='reflect')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 224, 224, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sample = X_train_resized[0:5000]\n",
    "X_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3017\n",
       "0    1983\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_sample = y_train[0:5000]\n",
    "y_sample.shape\n",
    "pd.Series(y_sample.flatten()).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 32, 32, 3),\n",
       " 1    593\n",
       " 0    407\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_sample = X_test[0:1000]\n",
    "y_test_sample = y_test[0:1000]\n",
    "\n",
    "X_test_sample.shape, pd.Series(y_test_sample.flatten()).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"/home/opc/block_vol/cifar_10_resized_224/X_train.pkl\", \"wb\") as file:\n",
    "#     pkl.dump(file=file, obj=X_train_resized)\n",
    "# with open(\"/home/opc/block_vol/cifar_10_resized_224/X_test.pkl\", \"wb\") as file:\n",
    "#     pkl.dump(file=file, obj=X_test_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####HI OVER HERE###\n",
    "import importlib\n",
    "importlib.reload(d)\n",
    "###HEYOOOOOO#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"/home/opc/eipy/eipy/res_output_weights.pkl\", \"wb\") as file:\n",
    "#     pkl.dump(res_model.layers[-1].weights, file=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers, models\n",
    "from keras.applications import ResNet50\n",
    "res_model = ResNet50(weights='imagenet', include_top=False)\n",
    "for layer in res_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "with open(\"/home/opc/eipy/eipy/bp_initial_output_weights/res_output_weights.pkl\",\"rb\") as file:\n",
    "    res_output_weights = pkl.load(file=file)\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "collecting_layer = layers.GlobalAveragePooling2D()(res_model.output)\n",
    "output_layer = layers.Dense(1, activation='sigmoid', weights=res_output_weights)(collecting_layer)\n",
    "\n",
    "res_model = models.Model(inputs=res_model.input, outputs=output_layer)\n",
    "res_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net_output_weights=net_model.layers[-1].weights\n",
    "# with open(\"/home/opc/eipy/eipy/net_output_weights.pkl\", \"wb\") as file:\n",
    "#     pkl.dump(net_output_weights, file=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "\n",
    "base_model = MobileNet(weights='imagenet', include_top=False)\n",
    "\n",
    "with open(\"/home/opc/eipy/eipy/bp_initial_output_weights/net_output_weights.pkl\", \"rb\") as file:\n",
    "    net_output_weights = pkl.load(file=file)\n",
    "\n",
    "x = base_model.output\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "tf.random.set_seed(42)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(1, activation='sigmoid', weights=net_output_weights)(x)\n",
    "net_model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "net_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v3_output_weights = v3_model.layers[-1].weights\n",
    "# with open(\"/home/opc/eipy/eipy/v3_output_weights.pkl\", \"wb\") as file:\n",
    "#     pkl.dump(v3_output_weights, file=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers, models\n",
    "from keras.applications import InceptionV3\n",
    "\n",
    "pretrained_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "with open(\"/home/opc/eipy/eipy/bp_initial_output_weights/v3_output_weights.pkl\", \"rb\") as file:\n",
    "    v3_output_weights = pkl.load(file=file)\n",
    "\n",
    "for layer in pretrained_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "collecting_layer = layers.GlobalAveragePooling2D()(pretrained_model.output)\n",
    "output_layer = layers.Dense(1, activation='sigmoid', weights=v3_output_weights)(collecting_layer)\n",
    "\n",
    "v3_model = models.Model(inputs=pretrained_model.input, outputs=output_layer)\n",
    "v3_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dense_output_weights = dense_model.layers[-1].weights\n",
    "# with open(\"/home/opc/eipy/eipy/dense_output_weights.pkl\", \"wb\") as file:\n",
    "#     pkl.dump(dense_output_weights, file=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers, models\n",
    "from keras.applications import DenseNet121\n",
    "\n",
    "pretrained_model = DenseNet121(weights='imagenet', include_top=False)\n",
    "\n",
    "for layer in pretrained_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "with open(\"/home/opc/eipy/eipy/bp_initial_output_weights/dense_output_weights.pkl\", \"rb\") as file:\n",
    "    dense_output_weights = pkl.load(file=file)\n",
    "\n",
    "collecting_layer = layers.GlobalAveragePooling2D()(pretrained_model.output)\n",
    "\n",
    "output_layer = layers.Dense(1, activation='sigmoid', weights=dense_output_weights)(collecting_layer)\n",
    "\n",
    "dense_model = models.Model(inputs=pretrained_model.input, outputs=output_layer)\n",
    "dense_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_predictors = {\n",
    "    # \"ResNet50\" : res_model,\n",
    "    \"MobileNet\" : net_model,\n",
    "    # \"InceptionV3\" : v3_model,\n",
    "    \"Dense121\" : dense_model\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EI = d.EnsembleIntegration(\n",
    "                        k_outer=2,\n",
    "                        k_inner=2,\n",
    "                        n_samples=1,\n",
    "                        sampling_aggregation=None,\n",
    "                        sampling_strategy=None,\n",
    "                        n_jobs=-1,\n",
    "                        metrics=metric_funs,\n",
    "                        random_state=38,\n",
    "                        project_name=\"images\",\n",
    "                        parallel_backend=\"multiprocessing\",\n",
    "                        model_building=True,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "EI.fit_base(X_sample, y_sample, modality_name=\"images\", base_predictors=base_predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EI.base_summary[\"metrics\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import pandas as pd\n",
    "from eipy.ei import EnsembleIntegration\n",
    "from eipy.additional_ensembles import MeanAggregation, CES\n",
    "ensemble_predictors = {\n",
    "                    'Mean' : MeanAggregation(),\n",
    "                    'CES' : CES(scoring=lambda y_test, y_pred: fmax_score(y_test, y_pred)[0]),\n",
    "                    'S.ADAB': AdaBoostClassifier(),\n",
    "                    'S.XGB': XGBClassifier(),\n",
    "                    'S.DT': DecisionTreeClassifier(),\n",
    "                    \"S.RF\": RandomForestClassifier(),\n",
    "                    'S.GB': GradientBoostingClassifier(),\n",
    "                    'S.KNN': KNeighborsClassifier(),\n",
    "                    'S.LR': LogisticRegression(),\n",
    "                    'S.NB': GaussianNB(),\n",
    "                    'S.MLP': MLPClassifier(),\n",
    "                    'S.SVM': SVC(probability=True),\n",
    "}\n",
    "EI.fit_ensemble(ensemble_predictors=ensemble_predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EI.ensemble_summary[\"metrics\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dict = {\"images\": X_test_sample}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_key(metric):\n",
    "    return EI.ensemble_summary[\"metrics\"].loc[f\"{metric}\"].idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = EI.ensemble_summary[\"metrics\"].index.tolist()\n",
    "y_preds = {}\n",
    "for metric in metrics:\n",
    "    y_preds[metric] = EI.predict(X_dict=X_dict, ensemble_model_key=model_key(metric))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results={}\n",
    "# for k,v in y_preds.items():\n",
    "#     results[k]= metric_funs[k](y_test, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_test_sample, y_preds[\"auc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmax_score(y_test_sample, y_preds[\"f_max\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_mcc = [y>0.5 for y in y_preds[\"mcc\"]]\n",
    "matthews_corrcoef(y_test_sample, y_preds_mcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
