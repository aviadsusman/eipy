{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-09 20:47:48.166334: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-09 20:47:48.195224: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-09 20:47:48.195257: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-09 20:47:48.195280: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-09 20:47:48.201258: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-09 20:47:48.201804: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-09 20:47:49.022513: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from eipy.deep_ei import EnsembleIntegration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eipy.metrics import fmax_score\n",
    "from sklearn.metrics import roc_auc_score, matthews_corrcoef\n",
    "\n",
    "metrics = {\n",
    "            'f_max': fmax_score,\n",
    "            'auc': roc_auc_score,\n",
    "            'mcc': matthews_corrcoef\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.where(y_train != 1, 0, y_train)\n",
    "y_test = np.where(y_test != 1, 0, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "with open(\"/home/opc/block_vol/cifar_10_resized_224/X_train.pkl\", \"rb\") as file:\n",
    "    X_train_resized=pkl.load(file=file)\n",
    "file.close()\n",
    "with open(\"/home/opc/block_vol/cifar_10_resized_224/X_test.pkl\", \"rb\") as file:\n",
    "    X_test_resized=pkl.load(file=file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"from sklearn.utils.class_weight import compute_class_weight\\nclass_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\\nclass_weight_dict = {i: weight for i, weight in enumerate(class_weights)}\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from sklearn.utils.class_weight import compute_class_weight\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weight_dict = {i: weight for i, weight in enumerate(class_weights)}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "res_model = ResNet50(weights='imagenet', include_top=False)\n",
    "\n",
    "for layer in res_model.layers:\n",
    "    layer.trainable = False\n",
    "averaging_layer = layers.GlobalAveragePooling2D()(res_model.output)\n",
    "output_layer = layers.Dense(1, activation='sigmoid')(averaging_layer)\n",
    "\n",
    "res_model = models.Model(inputs=res_model.input, outputs=output_layer)\n",
    "res_model.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"from skimage.transform import resize\\n\\nnew_size = (224, 224)\\n\\nX_train_resized = np.empty((X_train.shape[0], new_size[0], new_size[1], 3))\\nX_test_resized = np.empty((X_test.shape[0], new_size[0], new_size[1], 3))\\n\\nfor i in range(X_train.shape[0]):\\n    X_train_resized[i] = resize(X_train[i], new_size, preserve_range=True, mode='reflect')\\nfor i in range(X_test.shape[0]):\\n    X_test_resized[i] = resize(X_test[i], new_size, preserve_range=True, mode='reflect')\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from skimage.transform import resize\n",
    "\n",
    "new_size = (224, 224)\n",
    "\n",
    "X_train_resized = np.empty((X_train.shape[0], new_size[0], new_size[1], 3))\n",
    "X_test_resized = np.empty((X_test.shape[0], new_size[0], new_size[1], 3))\n",
    "\n",
    "for i in range(X_train.shape[0]):\n",
    "    X_train_resized[i] = resize(X_train[i], new_size, preserve_range=True, mode='reflect')\n",
    "for i in range(X_test.shape[0]):\n",
    "    X_test_resized[i] = resize(X_test[i], new_size, preserve_range=True, mode='reflect')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'with open(\"/home/opc/block_vol/cifar_10_resized_224/X_train.pkl\", \"wb\") as file:\\n    pkl.dump(X_train_resized, file=file)\\nfile.close()\\nwith open(\"/home/opc/block_vol/cifar_10_resized_224/X_test.pkl\", \"wb\") as file:\\n    pkl.dump(X_test_resized, file=file)\\nfile.close()'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''with open(\"/home/opc/block_vol/cifar_10_resized_224/X_train.pkl\", \"wb\") as file:\n",
    "    pkl.dump(X_train_resized, file=file)\n",
    "file.close()\n",
    "with open(\"/home/opc/block_vol/cifar_10_resized_224/X_test.pkl\", \"wb\") as file:\n",
    "    pkl.dump(X_test_resized, file=file)\n",
    "file.close()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.mobilenet import MobileNet\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "\n",
    "base_model = MobileNet(weights='imagenet', include_top=False)\n",
    "\n",
    "x = base_model.output\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "net_model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "net_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_predictors = {\n",
    "    \"ResNet50\" : res_model,\n",
    "    \"MobileNet\" : net_model\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "EI = EnsembleIntegration(\n",
    "                        base_predictors=base_predictors,\n",
    "                        k_outer=2,\n",
    "                        k_inner=2,\n",
    "                        n_samples=1,\n",
    "                        sampling_aggregation=None,\n",
    "                        n_jobs=-1,\n",
    "                        metrics=metrics,\n",
    "                        random_state=38,\n",
    "                        project_name=\"images\",\n",
    "                        model_building=False,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training base predictors on None...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |          |  0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://d158b73fb0344074934469a9467250b5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://d158b73fb0344074934469a9467250b5/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://d80f0521a9524ac48dc788d9feaf0062/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://d80f0521a9524ac48dc788d9feaf0062/assets\n",
      "2023-11-09 20:48:32.678063: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-09 20:48:32.705346: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-09 20:48:32.705390: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-09 20:48:32.705416: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-09 20:48:32.711087: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-09 20:48:32.711327: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-09 20:48:33.469169: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-11-09 20:48:38.397689: W tensorflow/core/util/tensor_slice_reader.cc:98] Could not open ram://4cd83de698d54538a2faaa6011ff69ef: INVALID_ARGUMENT: ram://4cd83de698d54538a2faaa6011ff69ef is a directory.\n",
      "2023-11-09 20:48:40.662675: W tensorflow/core/util/tensor_slice_reader.cc:98] Could not open ram://330ccf7e094f485b89cb0c7e1e5ee232: INVALID_ARGUMENT: ram://330ccf7e094f485b89cb0c7e1e5ee232 is a directory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://797819491ddc48ceb8ef3a53d9e6d935/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://797819491ddc48ceb8ef3a53d9e6d935/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://b1de677a8961446eab72637b24f448d3/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://b1de677a8961446eab72637b24f448d3/assets\n",
      "2023-11-09 20:48:48.495105: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-09 20:48:48.521223: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-09 20:48:48.521262: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-09 20:48:48.521288: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-09 20:48:48.526717: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-09 20:48:48.526944: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-09 20:48:49.224887: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-11-09 20:48:53.952499: W tensorflow/core/util/tensor_slice_reader.cc:98] Could not open ram://ef9dee657088406ea6a2de673e8d45d0: INVALID_ARGUMENT: ram://ef9dee657088406ea6a2de673e8d45d0 is a directory.\n",
      "2023-11-09 20:48:56.234446: W tensorflow/core/util/tensor_slice_reader.cc:98] Could not open ram://a23b58a65c9b46aa83b35a965d340697: INVALID_ARGUMENT: ram://a23b58a65c9b46aa83b35a965d340697 is a directory.\n",
      "2023-11-09 20:48:56.250168: W tensorflow/core/util/tensor_slice_reader.cc:98] Could not open ram://ffe8c9e4c3f4450d8be8ed31aedc63ff: INVALID_ARGUMENT: ram://ffe8c9e4c3f4450d8be8ed31aedc63ff is a directory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://79df2f01f90c4123b93f9bf1fda37beb/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://79df2f01f90c4123b93f9bf1fda37beb/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://a77aafe0c8ee4554880336aa17bde4bf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://a77aafe0c8ee4554880336aa17bde4bf/assets\n",
      "2023-11-09 20:49:04.631795: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-09 20:49:04.658782: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-09 20:49:04.658823: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-09 20:49:04.658846: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-09 20:49:04.664517: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-09 20:49:04.664754: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-09 20:49:05.395929: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Generating ensemble training data: |          |  0%\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 4. None expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/opc/.venv/lib64/python3.9/site-packages/joblib/externals/loky/process_executor.py\", line 463, in _process_worker\n    r = call_item()\n  File \"/home/opc/.venv/lib64/python3.9/site-packages/joblib/externals/loky/process_executor.py\", line 291, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/home/opc/.venv/lib64/python3.9/site-packages/joblib/parallel.py\", line 589, in __call__\n    return [func(*args, **kwargs)\n  File \"/home/opc/.venv/lib64/python3.9/site-packages/joblib/parallel.py\", line 589, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"/home/opc/.venv/lib64/python3.9/site-packages/sklearn/utils/_testing.py\", line 188, in wrapper\n    return fn(*args, **kwargs)\n  File \"/home/opc/eipy/eipy/deep_ei.py\", line 572, in _train_predict_single_base_predictor\n    X_sample, y_sample = sample(\n  File \"/home/opc/eipy/eipy/utils.py\", line 160, in sample\n    X_resampled, y_resampled = sampler.fit_resample(X=X, y=y)\n  File \"/home/opc/.venv/lib64/python3.9/site-packages/imblearn/base.py\", line 208, in fit_resample\n    return super().fit_resample(X, y)\n  File \"/home/opc/.venv/lib64/python3.9/site-packages/imblearn/base.py\", line 106, in fit_resample\n    X, y, binarize_y = self._check_X_y(X, y)\n  File \"/home/opc/.venv/lib64/python3.9/site-packages/imblearn/under_sampling/_prototype_selection/_random_under_sampler.py\", line 101, in _check_X_y\n    X = _check_X(X)\n  File \"/home/opc/.venv/lib64/python3.9/site-packages/imblearn/utils/_validation.py\", line 624, in _check_X\n    return check_array(\n  File \"/home/opc/.venv/lib64/python3.9/site-packages/sklearn/utils/validation.py\", line 915, in check_array\n    raise ValueError(\nValueError: Found array with dim 4. None expected <= 2.\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/opc/eipy/eipy/deep_implement.ipynb Cell 13\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Baviad_bc/home/opc/eipy/eipy/deep_implement.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m EI\u001b[39m.\u001b[39;49mfit_base(X_train_resized, y_train)\n",
      "File \u001b[0;32m~/eipy/eipy/deep_ei.py:238\u001b[0m, in \u001b[0;36mEnsembleIntegration.fit_base\u001b[0;34m(self, X, y, base_predictors, modality_name)\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_base(\n\u001b[1;32m    232\u001b[0m             X\u001b[39m=\u001b[39mmodality,\n\u001b[1;32m    233\u001b[0m             y\u001b[39m=\u001b[39my,\n\u001b[1;32m    234\u001b[0m             base_predictors\u001b[39m=\u001b[39mbase_predictors,\n\u001b[1;32m    235\u001b[0m             modality_name\u001b[39m=\u001b[39mmodality_name,\n\u001b[1;32m    236\u001b[0m         )\n\u001b[1;32m    237\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 238\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_base(\n\u001b[1;32m    239\u001b[0m         X\u001b[39m=\u001b[39;49mX, y\u001b[39m=\u001b[39;49my, base_predictors\u001b[39m=\u001b[39;49mbase_predictors, modality_name\u001b[39m=\u001b[39;49mmodality_name\n\u001b[1;32m    240\u001b[0m     )\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/sklearn/utils/_testing.py:188\u001b[0m, in \u001b[0;36m_IgnoreWarnings.__call__.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[39mwith\u001b[39;00m warnings\u001b[39m.\u001b[39mcatch_warnings():\n\u001b[1;32m    187\u001b[0m     warnings\u001b[39m.\u001b[39msimplefilter(\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcategory)\n\u001b[0;32m--> 188\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/eipy/eipy/deep_ei.py:383\u001b[0m, in \u001b[0;36mEnsembleIntegration._fit_base\u001b[0;34m(self, X, y, base_predictors, modality_name)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_names[modality_name] \u001b[39m=\u001b[39m feature_names\n\u001b[1;32m    381\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_per_modality\u001b[39m.\u001b[39mappend(X\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m])\n\u001b[0;32m--> 383\u001b[0m ensemble_training_data_modality \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_base_inner(\n\u001b[1;32m    384\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m    385\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    386\u001b[0m     cv_outer\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcv_outer,\n\u001b[1;32m    387\u001b[0m     cv_inner\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcv_inner,\n\u001b[1;32m    388\u001b[0m     base_predictors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbase_predictors,\n\u001b[1;32m    389\u001b[0m     modality_name\u001b[39m=\u001b[39;49mmodality_name,\n\u001b[1;32m    390\u001b[0m )\n\u001b[1;32m    392\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mensemble_training_data \u001b[39m=\u001b[39m append_modality(\n\u001b[1;32m    393\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mensemble_training_data, ensemble_training_data_modality\n\u001b[1;32m    394\u001b[0m )\n\u001b[1;32m    396\u001b[0m ensemble_test_data_modality \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_base_outer(\n\u001b[1;32m    397\u001b[0m     X\u001b[39m=\u001b[39mX,\n\u001b[1;32m    398\u001b[0m     y\u001b[39m=\u001b[39my,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    401\u001b[0m     modality_name\u001b[39m=\u001b[39mmodality_name,\n\u001b[1;32m    402\u001b[0m )\n",
      "File \u001b[0;32m~/eipy/eipy/deep_ei.py:483\u001b[0m, in \u001b[0;36mEnsembleIntegration._fit_base_inner\u001b[0;34m(self, X, y, cv_outer, cv_inner, base_predictors, modality_name)\u001b[0m\n\u001b[1;32m    480\u001b[0m y_train_outer \u001b[39m=\u001b[39m y[train_index_outer]\n\u001b[1;32m    482\u001b[0m \u001b[39m# spawn n_jobs jobs for each sample, inner_fold and model\u001b[39;00m\n\u001b[0;32m--> 483\u001b[0m output \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    484\u001b[0m     delayed(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_predict_single_base_predictor)(\n\u001b[1;32m    485\u001b[0m         X\u001b[39m=\u001b[39;49mX_train_outer,\n\u001b[1;32m    486\u001b[0m         y\u001b[39m=\u001b[39;49my_train_outer,\n\u001b[1;32m    487\u001b[0m         model_params\u001b[39m=\u001b[39;49mmodel_params,\n\u001b[1;32m    488\u001b[0m         fold_params\u001b[39m=\u001b[39;49minner_fold_params,\n\u001b[1;32m    489\u001b[0m         sample_state\u001b[39m=\u001b[39;49msample_state,\n\u001b[1;32m    490\u001b[0m     )\n\u001b[1;32m    491\u001b[0m     \u001b[39mfor\u001b[39;49;00m model_params \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbase_predictors\u001b[39m.\u001b[39;49mitems()\n\u001b[1;32m    492\u001b[0m     \u001b[39mfor\u001b[39;49;00m inner_fold_params \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(\n\u001b[1;32m    493\u001b[0m         cv_inner\u001b[39m.\u001b[39;49msplit(X_train_outer, y_train_outer)\n\u001b[1;32m    494\u001b[0m     )\n\u001b[1;32m    495\u001b[0m     \u001b[39mfor\u001b[39;49;00m sample_state \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandom_numbers_for_samples)\n\u001b[1;32m    496\u001b[0m )\n\u001b[1;32m    498\u001b[0m combined_predictions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_combine_predictions_inner(\n\u001b[1;32m    499\u001b[0m     output, modality_name\n\u001b[1;32m    500\u001b[0m )\n\u001b[1;32m    501\u001b[0m ensemble_training_data_modality\u001b[39m.\u001b[39mappend(combined_predictions)\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1946\u001b[0m \u001b[39m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   1947\u001b[0m \u001b[39m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   1948\u001b[0m \u001b[39m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[1;32m   1949\u001b[0m \u001b[39m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   1950\u001b[0m \u001b[39mnext\u001b[39m(output)\n\u001b[0;32m-> 1952\u001b[0m \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39;49m(output)\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1592\u001b[0m     \u001b[39myield\u001b[39;00m\n\u001b[1;32m   1594\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1595\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_retrieve()\n\u001b[1;32m   1597\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1598\u001b[0m     \u001b[39m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1599\u001b[0m     \u001b[39m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1600\u001b[0m     \u001b[39m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1601\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1699\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1692\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wait_retrieval():\n\u001b[1;32m   1693\u001b[0m \n\u001b[1;32m   1694\u001b[0m     \u001b[39m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[1;32m   1695\u001b[0m     \u001b[39m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[1;32m   1696\u001b[0m     \u001b[39m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[1;32m   1697\u001b[0m     \u001b[39m# worker traceback.\u001b[39;00m\n\u001b[1;32m   1698\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_aborting:\n\u001b[0;32m-> 1699\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_error_fast()\n\u001b[1;32m   1700\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m   1702\u001b[0m     \u001b[39m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1703\u001b[0m     \u001b[39m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1734\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1730\u001b[0m \u001b[39m# If this error job exists, immediatly raise the error by\u001b[39;00m\n\u001b[1;32m   1731\u001b[0m \u001b[39m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[1;32m   1732\u001b[0m \u001b[39m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[1;32m   1733\u001b[0m \u001b[39mif\u001b[39;00m error_job \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1734\u001b[0m     error_job\u001b[39m.\u001b[39;49mget_result(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout)\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/joblib/parallel.py:736\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    730\u001b[0m backend \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparallel\u001b[39m.\u001b[39m_backend\n\u001b[1;32m    732\u001b[0m \u001b[39mif\u001b[39;00m backend\u001b[39m.\u001b[39msupports_retrieve_callback:\n\u001b[1;32m    733\u001b[0m     \u001b[39m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[1;32m    734\u001b[0m     \u001b[39m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[1;32m    735\u001b[0m     \u001b[39m# be returned.\u001b[39;00m\n\u001b[0;32m--> 736\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_return_or_raise()\n\u001b[1;32m    738\u001b[0m \u001b[39m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[1;32m    739\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/joblib/parallel.py:754\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    752\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    753\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstatus \u001b[39m==\u001b[39m TASK_ERROR:\n\u001b[0;32m--> 754\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result\n\u001b[1;32m    755\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result\n\u001b[1;32m    756\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with dim 4. None expected <= 2."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://37251d84502a41878996114b4779a30d/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://37251d84502a41878996114b4779a30d/assets\n"
     ]
    }
   ],
   "source": [
    "EI.fit_base(X_train_resized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
