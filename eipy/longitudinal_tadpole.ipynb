{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import pandas as pd\n",
    "import eipy.ei as e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eipy.metrics import fmax_score\n",
    "from sklearn.metrics import roc_auc_score, matthews_corrcoef\n",
    "\n",
    "metrics = {\n",
    "            'f_max': fmax_score,\n",
    "            'auc': roc_auc_score,\n",
    "            'mcc': matthews_corrcoef\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_predictors = {\n",
    "                    'ADAB': AdaBoostClassifier(),\n",
    "                    'XGB': XGBClassifier(),\n",
    "                    'DT': DecisionTreeClassifier(),\n",
    "                    'RF': RandomForestClassifier(),\n",
    "                    'GB': GradientBoostingClassifier(),\n",
    "                    'KNN': KNeighborsClassifier(),\n",
    "                    'LR': LogisticRegression(),\n",
    "                    'NB': GaussianNB(),\n",
    "                    'MLP': MLPClassifier(),\n",
    "                    'SVM': SVC(probability=True),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "with open(\"/home/opc/eipy/tadpole/tadpole_data_time_imptn_norm_v1.pickle\", \"rb\") as file:\n",
    "    data = pkl.load(file)\n",
    "with open(\"/home/opc/eipy/tadpole/tadpole_labels_time_imptn_norm_v1.pickle\", \"rb\") as file:\n",
    "    labels = pkl.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [data[k] for k in data.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in labels.items():\n",
    "    labels[k] = v.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#intermediate transformation to make sure labels are ordered correctly in time\n",
    "labels = pd.DataFrame(labels)\n",
    "\n",
    "labels = labels.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "encoding_dict = {'NL': 0, 'MCI': 1, 'Dementia': 2}\n",
    "\n",
    "# Use numpy.vectorize with a lambda function to apply the encoding\n",
    "labels = np.vectorize(lambda x: encoding_dict[x])(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''data misalignment'''\n",
    "data=data[:-1]\n",
    "labels = labels[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    480\n",
      "0    195\n",
      "2     27\n",
      "Name: count, dtype: int64\n",
      "1    451\n",
      "0    192\n",
      "2     59\n",
      "Name: count, dtype: int64\n",
      "1    378\n",
      "0    188\n",
      "2    136\n",
      "Name: count, dtype: int64\n",
      "1    348\n",
      "2    178\n",
      "0    176\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for i in range(labels.shape[-1]):\n",
    "    print(pd.Series(labels[:,i]).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    378\n",
       "1    250\n",
       "2     72\n",
       "3      2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''x patients have dementia 0 times in their label sequence,\n",
    " y patients have dementia once in their label sequence...'''\n",
    "dem_freq = np.sum(labels == 2, axis=1)\n",
    "pd.Series(dem_freq).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "324"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''how many patients get dementia at some point'''\n",
    "np.any(labels == 2, axis=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n"
     ]
    }
   ],
   "source": [
    "'''data split to validate hyper-parameter tuning'''\n",
    "data_train = []\n",
    "data_test = []\n",
    "labels_train = []\n",
    "labels_test = []\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "for i in range(len(data)):\n",
    "    print(\"hi\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'eipy.ei' from '/home/opc/eipy/eipy/ei.py'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####HI OVER HERE###\n",
    "import importlib\n",
    "importlib.reload(e)\n",
    "###HEYOOOOOO#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_folds = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating metadata for timestep 0\n",
      "Training base predictors on Main cognitive tests...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on MRI volumes...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on Demo, APOE4 & others...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on MRI ROI: Volume (WM Parcellation)...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on MRI ROI: Volume (Cortical Parcellation)...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on MRI ROI: Surface Area...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on MRI ROI: Cortical Thickness Average...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on MRI ROI: Cortical Thickness Standard Deviation...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "generating metadata for timestep 1\n",
      "Training base predictors on Main cognitive tests...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on MRI volumes...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on Demo, APOE4 & others...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on MRI ROI: Volume (WM Parcellation)...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on MRI ROI: Volume (Cortical Parcellation)...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on MRI ROI: Surface Area...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on MRI ROI: Cortical Thickness Average...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on MRI ROI: Cortical Thickness Standard Deviation...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "generating metadata for timestep 2\n",
      "Training base predictors on Main cognitive tests...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on MRI volumes...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on Demo, APOE4 & others...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on MRI ROI: Volume (WM Parcellation)...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on MRI ROI: Volume (Cortical Parcellation)...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on MRI ROI: Surface Area...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on MRI ROI: Cortical Thickness Average...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on MRI ROI: Cortical Thickness Standard Deviation...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "generating metadata for timestep 3\n",
      "Training base predictors on Main cognitive tests...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on MRI volumes...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on Demo, APOE4 & others...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on MRI ROI: Volume (WM Parcellation)...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on MRI ROI: Volume (Cortical Parcellation)...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on MRI ROI: Surface Area...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on MRI ROI: Cortical Thickness Average...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on MRI ROI: Cortical Thickness Standard Deviation...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "meta_data = []\n",
    "for t in range(len(data)):\n",
    "    #time dependent data splitting\n",
    "    X_train_timestep = data[t]\n",
    "    labels_at_timestep = labels[:, t]\n",
    "    EI_for_timestep = e.EnsembleIntegration(\n",
    "                        base_predictors=base_predictors,\n",
    "                        k_outer=outer_folds,\n",
    "                        k_inner=5,\n",
    "                        n_samples=1,\n",
    "                        sampling_strategy=\"oversampling\",\n",
    "                        sampling_aggregation=\"mean\",\n",
    "                        n_jobs=-1,\n",
    "                        metrics=metrics,\n",
    "                        random_state=38,\n",
    "                        project_name=f\"time step {t}\",\n",
    "                        verbose=0,\n",
    "                        model_building=False,\n",
    "                        )\n",
    "    print(f\"generating metadata for timestep {t}\")\n",
    "    EI_for_timestep.final_label_frequency = dem_freq\n",
    "    EI_for_timestep.fit_base(X_train_timestep, labels_at_timestep)\n",
    "    meta_data.append([EI_for_timestep.ensemble_training_data, EI_for_timestep.ensemble_test_data, EI_for_timestep.ensemble_training_data_final, EI_for_timestep.base_summary])\n",
    "\n",
    "warnings.filterwarnings(\"default\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_training_data = [[dfs[0][i] for dfs in meta_data] for i in range(outer_folds)]\n",
    "RNN_test_data = [[dfs[1][i] for dfs in meta_data] for i in range(outer_folds)]\n",
    "RNN_training_data_final = [df[2] for df in meta_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make first time point in meta-data multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_column_names(frame):\n",
    "#     column_names = []\n",
    "#     for i in range(frame.columns.nlevels):\n",
    "#         if i == 0:\n",
    "#             column_names.append(frame.columns.get_level_values(i).unique().drop(\"labels\"))\n",
    "            \n",
    "#         else:\n",
    "#             column_names.append(frame.columns.get_level_values(i).unique().drop(''))\n",
    "    \n",
    "#     return column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fix_first_time_point(df):\n",
    "#     new_columns = get_column_names(df)\n",
    "#     classes=[0,1,2]\n",
    "#     new_columns.append(classes)\n",
    "#     new_mux=pd.MultiIndex.from_product(iterables=new_columns, names=[\"modality\", \"base predictor\", \"sample\", \"class\"])\n",
    "#     new_df = pd.DataFrame(columns=new_mux)\n",
    "\n",
    "#     for col in new_df.columns:\n",
    "#         if col[-1] == 0:\n",
    "#             new_df[col] = 1 - df[col[:-1]]\n",
    "#         elif col[-1] == 1:\n",
    "#             new_df[col] = df[col[:-1]]\n",
    "#         else:\n",
    "#             new_df[col] = 0\n",
    "    \n",
    "#     new_df['labels'] = df['labels']\n",
    "\n",
    "#     return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of names must match number of levels in MultiIndex.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(RNN_training_data)):\n\u001b[0;32m----> 2\u001b[0m     RNN_training_data[i][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfix_first_time_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRNN_training_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     RNN_test_data[i][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m fix_first_time_point(RNN_test_data[i][\u001b[38;5;241m0\u001b[39m])\n",
      "Cell \u001b[0;32mIn[19], line 5\u001b[0m, in \u001b[0;36mfix_first_time_point\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      3\u001b[0m classes\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m      4\u001b[0m new_columns\u001b[38;5;241m.\u001b[39mappend(classes)\n\u001b[0;32m----> 5\u001b[0m new_mux\u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMultiIndex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_product\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodality\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbase predictor\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msample\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclass\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m new_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(columns\u001b[38;5;241m=\u001b[39mnew_mux)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m new_df\u001b[38;5;241m.\u001b[39mcolumns:\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/pandas/core/indexes/multi.py:658\u001b[0m, in \u001b[0;36mMultiIndex.from_product\u001b[0;34m(cls, iterables, sortorder, names)\u001b[0m\n\u001b[1;32m    656\u001b[0m \u001b[38;5;66;03m# codes are all ndarrays, so cartesian_product is lossless\u001b[39;00m\n\u001b[1;32m    657\u001b[0m codes \u001b[38;5;241m=\u001b[39m cartesian_product(codes)\n\u001b[0;32m--> 658\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msortorder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msortorder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/pandas/core/indexes/multi.py:345\u001b[0m, in \u001b[0;36mMultiIndex.__new__\u001b[0;34m(cls, levels, codes, sortorder, names, dtype, copy, name, verify_integrity)\u001b[0m\n\u001b[1;32m    342\u001b[0m result\u001b[38;5;241m.\u001b[39m_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(levels)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;66;03m# handles name validation\u001b[39;00m\n\u001b[0;32m--> 345\u001b[0m     \u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnames\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sortorder \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     result\u001b[38;5;241m.\u001b[39msortorder \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(sortorder)\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/pandas/core/indexes/multi.py:1433\u001b[0m, in \u001b[0;36mMultiIndex._set_names\u001b[0;34m(self, names, level, validate)\u001b[0m\n\u001b[1;32m   1431\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of names must match length of level.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1432\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(names) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnlevels:\n\u001b[0;32m-> 1433\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1434\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of names must match number of levels in MultiIndex.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1435\u001b[0m         )\n\u001b[1;32m   1437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1438\u001b[0m     level \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnlevels)\n",
      "\u001b[0;31mValueError\u001b[0m: Length of names must match number of levels in MultiIndex."
     ]
    }
   ],
   "source": [
    "# for i in range(len(RNN_training_data)):\n",
    "#     RNN_training_data[i][0] = fix_first_time_point(RNN_training_data[i][0])\n",
    "#     RNN_test_data[i][0] = fix_first_time_point(RNN_test_data[i][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TIME SERIES TIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-16 16:26:04.641118: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-16 16:26:04.667226: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-16 16:26:04.667253: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-16 16:26:04.668050: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-16 16:26:04.672562: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-16 16:26:04.673084: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-16 16:26:05.446037: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "'''Alternate loss function that is label appropriate'''\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "def ordinal_regression_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Ordinal regression loss function.\n",
    "\n",
    "    Parameters:\n",
    "    - y_true: true labels (ground truth)\n",
    "    - y_pred: predicted labels\n",
    "\n",
    "    Returns:\n",
    "    - loss value\n",
    "    \"\"\"\n",
    "    # Assuming y_true and y_pred are tensors of shape (batch_size, num_classes)\n",
    "\n",
    "    # Calculate cumulative probabilities for true and predicted labels\n",
    "    true_cum_probs = K.cumsum(K.softmax(y_true, axis=-1), axis=-1)\n",
    "    pred_cum_probs = K.cumsum(K.softmax(y_pred, axis=-1), axis=-1)\n",
    "\n",
    "    # Calculate the ordinal regression loss\n",
    "    loss = K.sum((true_cum_probs - pred_cum_probs) ** 2)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3047662/4047874034.py:17: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  RNN_training_data_fold = [data.drop(columns=[\"labels\"], axis=1) for data in RNN_training_data[i]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 1s 4ms/step - loss: 0.9666 - accuracy: 0.5851\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.8850 - accuracy: 0.6038\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.8610 - accuracy: 0.6105\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.8675 - accuracy: 0.6020\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.8452 - accuracy: 0.6136\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.8363 - accuracy: 0.6212\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.8289 - accuracy: 0.6239\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.8183 - accuracy: 0.6283\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.8074 - accuracy: 0.6341\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7993 - accuracy: 0.6417\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7851 - accuracy: 0.6506\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7646 - accuracy: 0.6631\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7619 - accuracy: 0.6640\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7476 - accuracy: 0.6622\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7245 - accuracy: 0.6832\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7140 - accuracy: 0.6930\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6923 - accuracy: 0.7014\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.7001\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6643 - accuracy: 0.7166\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6403 - accuracy: 0.7335\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6157 - accuracy: 0.7460\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5914 - accuracy: 0.7527\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5768 - accuracy: 0.7643\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5730 - accuracy: 0.7638\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5399 - accuracy: 0.7910\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5243 - accuracy: 0.7946\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4962 - accuracy: 0.7977\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4763 - accuracy: 0.8079\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4439 - accuracy: 0.8333\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4118 - accuracy: 0.8578\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3912 - accuracy: 0.8636\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3735 - accuracy: 0.8632\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3651 - accuracy: 0.8685\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3414 - accuracy: 0.8837\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3090 - accuracy: 0.8984\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3036 - accuracy: 0.8944\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2925 - accuracy: 0.9002\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2726 - accuracy: 0.9073\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2616 - accuracy: 0.9135\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2459 - accuracy: 0.9180\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2333 - accuracy: 0.9247\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2287 - accuracy: 0.9180\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2167 - accuracy: 0.9260\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2083 - accuracy: 0.9291\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2027 - accuracy: 0.9318\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1951 - accuracy: 0.9367\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1855 - accuracy: 0.9403\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1755 - accuracy: 0.9407\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1691 - accuracy: 0.9447\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1728 - accuracy: 0.9430\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1663 - accuracy: 0.9488\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1592 - accuracy: 0.9456\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1606 - accuracy: 0.9430\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1577 - accuracy: 0.9479\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1481 - accuracy: 0.9479\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1425 - accuracy: 0.9501\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1365 - accuracy: 0.9532\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1347 - accuracy: 0.9563\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1368 - accuracy: 0.9559\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1290 - accuracy: 0.9581\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1230 - accuracy: 0.9568\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1208 - accuracy: 0.9617\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1180 - accuracy: 0.9586\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1162 - accuracy: 0.9657\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1115 - accuracy: 0.9679\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1082 - accuracy: 0.9666\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1068 - accuracy: 0.9684\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1038 - accuracy: 0.9652\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1082 - accuracy: 0.9652\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1037 - accuracy: 0.9666\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.1020 - accuracy: 0.9635\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0993 - accuracy: 0.9697\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0962 - accuracy: 0.9737\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0940 - accuracy: 0.9755\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0912 - accuracy: 0.9764\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0894 - accuracy: 0.9737\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0846 - accuracy: 0.9746\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0876 - accuracy: 0.9715\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0832 - accuracy: 0.9795\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0816 - accuracy: 0.9799\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0791 - accuracy: 0.9786\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0779 - accuracy: 0.9795\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0763 - accuracy: 0.9808\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0731 - accuracy: 0.9831\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0740 - accuracy: 0.9808\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0725 - accuracy: 0.9795\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0688 - accuracy: 0.9862\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0687 - accuracy: 0.9840\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0695 - accuracy: 0.9804\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0694 - accuracy: 0.9799\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0647 - accuracy: 0.9857\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0631 - accuracy: 0.9862\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0615 - accuracy: 0.9866\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0597 - accuracy: 0.9871\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0595 - accuracy: 0.9862\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0588 - accuracy: 0.9871\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0572 - accuracy: 0.9866\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0575 - accuracy: 0.9875\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0547 - accuracy: 0.9884\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0519 - accuracy: 0.9906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3047662/4047874034.py:24: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  RNN_test_data_fold = [data.drop(columns=[\"labels\"], axis=1) for data in RNN_test_data[i]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 1s 4ms/step - loss: 0.9798 - accuracy: 0.5735\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.8895 - accuracy: 0.5945\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.8677 - accuracy: 0.5989\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.8682 - accuracy: 0.5998\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.8494 - accuracy: 0.6083\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.8472 - accuracy: 0.6065\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.8364 - accuracy: 0.6105\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.8311 - accuracy: 0.6119\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.8232 - accuracy: 0.6194\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.8188 - accuracy: 0.6234\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.8087 - accuracy: 0.6315\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.7955 - accuracy: 0.6279\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.7933 - accuracy: 0.6377\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.7732 - accuracy: 0.6569\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.7642 - accuracy: 0.6564\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.7508 - accuracy: 0.6716\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.7316 - accuracy: 0.6760\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.7109 - accuracy: 0.6956\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.7046 - accuracy: 0.6912\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.7320 - accuracy: 0.6716\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6888 - accuracy: 0.6988\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6567 - accuracy: 0.7291\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6255 - accuracy: 0.7442\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6155 - accuracy: 0.7473\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5889 - accuracy: 0.7522\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5584 - accuracy: 0.7839\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5303 - accuracy: 0.7865\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5076 - accuracy: 0.8017\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4766 - accuracy: 0.8240\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4656 - accuracy: 0.8244\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4352 - accuracy: 0.8373\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4152 - accuracy: 0.8471\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4086 - accuracy: 0.8418\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3792 - accuracy: 0.8627\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3331 - accuracy: 0.8913\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3172 - accuracy: 0.8957\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3062 - accuracy: 0.8975\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2893 - accuracy: 0.8966\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2784 - accuracy: 0.9051\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2617 - accuracy: 0.9122\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2515 - accuracy: 0.9153\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2279 - accuracy: 0.9247\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2172 - accuracy: 0.9260\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2139 - accuracy: 0.9283\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2116 - accuracy: 0.9260\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1931 - accuracy: 0.9376\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1889 - accuracy: 0.9327\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1811 - accuracy: 0.9430\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1779 - accuracy: 0.9389\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1670 - accuracy: 0.9465\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1586 - accuracy: 0.9470\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1529 - accuracy: 0.9550\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1463 - accuracy: 0.9488\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1519 - accuracy: 0.9510\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1370 - accuracy: 0.9603\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1368 - accuracy: 0.9519\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1327 - accuracy: 0.9563\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1248 - accuracy: 0.9568\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1200 - accuracy: 0.9626\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1150 - accuracy: 0.9626\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1118 - accuracy: 0.9626\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1098 - accuracy: 0.9675\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1130 - accuracy: 0.9608\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1122 - accuracy: 0.9599\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1060 - accuracy: 0.9688\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1028 - accuracy: 0.9679\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0967 - accuracy: 0.9706\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0983 - accuracy: 0.9675\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0929 - accuracy: 0.9750\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0899 - accuracy: 0.9737\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0854 - accuracy: 0.9768\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0871 - accuracy: 0.9742\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0840 - accuracy: 0.9768\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0804 - accuracy: 0.9768\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0781 - accuracy: 0.9773\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0764 - accuracy: 0.9808\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0738 - accuracy: 0.9831\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0718 - accuracy: 0.9840\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0746 - accuracy: 0.9782\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0708 - accuracy: 0.9831\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0661 - accuracy: 0.9844\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0638 - accuracy: 0.9840\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0631 - accuracy: 0.9840\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0646 - accuracy: 0.9848\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0612 - accuracy: 0.9880\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0588 - accuracy: 0.9880\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0602 - accuracy: 0.9844\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0543 - accuracy: 0.9889\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0532 - accuracy: 0.9920\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0527 - accuracy: 0.9929\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0548 - accuracy: 0.9875\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0523 - accuracy: 0.9924\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0491 - accuracy: 0.9889\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0498 - accuracy: 0.9915\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0458 - accuracy: 0.9911\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0446 - accuracy: 0.9929\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0424 - accuracy: 0.9947\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0417 - accuracy: 0.9938\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0454 - accuracy: 0.9915\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0409 - accuracy: 0.9942\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 1s 5ms/step - loss: 0.9831 - accuracy: 0.5761\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.8824 - accuracy: 0.6054\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.8560 - accuracy: 0.6197\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.8473 - accuracy: 0.6192\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.8411 - accuracy: 0.6228\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.8322 - accuracy: 0.6281\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.8231 - accuracy: 0.6254\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.8247 - accuracy: 0.6246\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.8177 - accuracy: 0.6366\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.8008 - accuracy: 0.6432\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.7937 - accuracy: 0.6548\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.7825 - accuracy: 0.6561\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.7804 - accuracy: 0.6472\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.7677 - accuracy: 0.6708\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.7541 - accuracy: 0.6762\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.7263 - accuracy: 0.6975\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6998 - accuracy: 0.7028\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6805 - accuracy: 0.7135\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6553 - accuracy: 0.7318\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6330 - accuracy: 0.7313\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6041 - accuracy: 0.7433\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5910 - accuracy: 0.7496\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5531 - accuracy: 0.7754\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5163 - accuracy: 0.7994\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5093 - accuracy: 0.7918\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4715 - accuracy: 0.8194\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4284 - accuracy: 0.8412\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4175 - accuracy: 0.8403\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3969 - accuracy: 0.8443\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3779 - accuracy: 0.8510\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3506 - accuracy: 0.8728\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3354 - accuracy: 0.8688\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3072 - accuracy: 0.8857\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2862 - accuracy: 0.8923\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2773 - accuracy: 0.8964\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2696 - accuracy: 0.9008\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2528 - accuracy: 0.9030\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2376 - accuracy: 0.9101\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2396 - accuracy: 0.9012\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2140 - accuracy: 0.9199\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2005 - accuracy: 0.9293\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1907 - accuracy: 0.9310\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1837 - accuracy: 0.9355\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1791 - accuracy: 0.9391\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1769 - accuracy: 0.9315\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1732 - accuracy: 0.9346\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1691 - accuracy: 0.9368\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1665 - accuracy: 0.9373\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1579 - accuracy: 0.9457\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1558 - accuracy: 0.9466\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1491 - accuracy: 0.9471\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1403 - accuracy: 0.9551\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1324 - accuracy: 0.9586\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1319 - accuracy: 0.9533\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1304 - accuracy: 0.9515\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1321 - accuracy: 0.9480\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1215 - accuracy: 0.9569\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1179 - accuracy: 0.9609\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1147 - accuracy: 0.9582\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1102 - accuracy: 0.9617\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1116 - accuracy: 0.9622\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1089 - accuracy: 0.9604\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1146 - accuracy: 0.9573\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1139 - accuracy: 0.9600\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1023 - accuracy: 0.9649\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0990 - accuracy: 0.9644\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1007 - accuracy: 0.9591\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1005 - accuracy: 0.9653\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0941 - accuracy: 0.9702\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0899 - accuracy: 0.9720\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0901 - accuracy: 0.9698\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0876 - accuracy: 0.9702\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0841 - accuracy: 0.9746\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0853 - accuracy: 0.9733\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0813 - accuracy: 0.9706\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0773 - accuracy: 0.9782\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0811 - accuracy: 0.9724\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0771 - accuracy: 0.9809\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0766 - accuracy: 0.9795\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0727 - accuracy: 0.9764\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0723 - accuracy: 0.9809\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0688 - accuracy: 0.9809\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0703 - accuracy: 0.9791\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0653 - accuracy: 0.9849\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0649 - accuracy: 0.9813\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0623 - accuracy: 0.9867\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0618 - accuracy: 0.9840\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0601 - accuracy: 0.9818\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0567 - accuracy: 0.9880\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0546 - accuracy: 0.9875\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0541 - accuracy: 0.9893\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0533 - accuracy: 0.9880\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0523 - accuracy: 0.9902\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0600 - accuracy: 0.9809\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0546 - accuracy: 0.9889\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0484 - accuracy: 0.9915\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0487 - accuracy: 0.9902\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0473 - accuracy: 0.9902\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0440 - accuracy: 0.9947\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0426 - accuracy: 0.9942\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 2s 5ms/step - loss: 0.9696 - accuracy: 0.5810\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.8845 - accuracy: 0.6050\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.8702 - accuracy: 0.5970\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.8550 - accuracy: 0.5983\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.8511 - accuracy: 0.6103\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.8404 - accuracy: 0.6099\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.8325 - accuracy: 0.6148\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.8285 - accuracy: 0.6117\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.8247 - accuracy: 0.6134\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.8026 - accuracy: 0.6343\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.7900 - accuracy: 0.6335\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.7756 - accuracy: 0.6512\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.7552 - accuracy: 0.6575\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.7377 - accuracy: 0.6797\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.7232 - accuracy: 0.6913\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.7003 - accuracy: 0.6917\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6782 - accuracy: 0.7077\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6572 - accuracy: 0.7206\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6280 - accuracy: 0.7398\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5823 - accuracy: 0.7687\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5489 - accuracy: 0.7807\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5286 - accuracy: 0.7936\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4986 - accuracy: 0.8043\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4683 - accuracy: 0.8163\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4330 - accuracy: 0.8332\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3941 - accuracy: 0.8554\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3769 - accuracy: 0.8617\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3607 - accuracy: 0.8697\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3187 - accuracy: 0.8883\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3017 - accuracy: 0.8906\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2892 - accuracy: 0.8968\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2689 - accuracy: 0.9088\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2568 - accuracy: 0.9079\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2534 - accuracy: 0.9115\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2452 - accuracy: 0.9079\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2171 - accuracy: 0.9266\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2068 - accuracy: 0.9270\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1995 - accuracy: 0.9324\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1942 - accuracy: 0.9324\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1830 - accuracy: 0.9364\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1750 - accuracy: 0.9373\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1688 - accuracy: 0.9404\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1574 - accuracy: 0.9475\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1541 - accuracy: 0.9502\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1504 - accuracy: 0.9511\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1505 - accuracy: 0.9520\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1468 - accuracy: 0.9493\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1449 - accuracy: 0.9502\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1305 - accuracy: 0.9577\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1226 - accuracy: 0.9591\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1232 - accuracy: 0.9609\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1196 - accuracy: 0.9609\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1194 - accuracy: 0.9635\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1165 - accuracy: 0.9626\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1113 - accuracy: 0.9622\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1073 - accuracy: 0.9666\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1034 - accuracy: 0.9662\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1002 - accuracy: 0.9689\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0978 - accuracy: 0.9631\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1036 - accuracy: 0.9604\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0942 - accuracy: 0.9702\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0939 - accuracy: 0.9702\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0910 - accuracy: 0.9715\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0853 - accuracy: 0.9742\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0824 - accuracy: 0.9764\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0801 - accuracy: 0.9773\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0806 - accuracy: 0.9751\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0783 - accuracy: 0.9769\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0763 - accuracy: 0.9738\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0777 - accuracy: 0.9751\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0735 - accuracy: 0.9786\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0697 - accuracy: 0.9818\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0681 - accuracy: 0.9795\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0659 - accuracy: 0.9840\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0642 - accuracy: 0.9835\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0624 - accuracy: 0.9809\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0617 - accuracy: 0.9835\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0591 - accuracy: 0.9844\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0579 - accuracy: 0.9853\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0599 - accuracy: 0.9804\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0604 - accuracy: 0.9840\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0561 - accuracy: 0.9840\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0544 - accuracy: 0.9875\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0522 - accuracy: 0.9871\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0488 - accuracy: 0.9898\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0494 - accuracy: 0.9898\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0454 - accuracy: 0.9907\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0429 - accuracy: 0.9929\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0423 - accuracy: 0.9929\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0439 - accuracy: 0.9911\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0403 - accuracy: 0.9920\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0394 - accuracy: 0.9969\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0390 - accuracy: 0.9942\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0377 - accuracy: 0.9951\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0361 - accuracy: 0.9933\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0339 - accuracy: 0.9964\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0330 - accuracy: 0.9964\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0318 - accuracy: 0.9996\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0325 - accuracy: 0.9951\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0310 - accuracy: 0.9987\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n",
      "18/18 [==============================] - 1s 5ms/step - loss: 0.9819 - accuracy: 0.5596\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.8972 - accuracy: 0.5859\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.8715 - accuracy: 0.5948\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.8725 - accuracy: 0.5988\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.8581 - accuracy: 0.6001\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.8486 - accuracy: 0.6099\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.8411 - accuracy: 0.6139\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.8326 - accuracy: 0.6179\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.8151 - accuracy: 0.6272\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.8190 - accuracy: 0.6299\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.7926 - accuracy: 0.6450\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.7795 - accuracy: 0.6548\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.7931 - accuracy: 0.6299\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.7533 - accuracy: 0.6686\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.7309 - accuracy: 0.6762\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.7159 - accuracy: 0.6748\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6806 - accuracy: 0.7046\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6624 - accuracy: 0.7224\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6330 - accuracy: 0.7251\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6114 - accuracy: 0.7278\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5713 - accuracy: 0.7620\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5330 - accuracy: 0.7825\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5021 - accuracy: 0.8003\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4859 - accuracy: 0.8065\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4637 - accuracy: 0.8194\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4102 - accuracy: 0.8425\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.3682 - accuracy: 0.8603\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.3435 - accuracy: 0.8683\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.3348 - accuracy: 0.8794\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.3000 - accuracy: 0.8946\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.2900 - accuracy: 0.8932\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.2719 - accuracy: 0.9044\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.2499 - accuracy: 0.9133\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.2395 - accuracy: 0.9159\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.2172 - accuracy: 0.9266\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.2168 - accuracy: 0.9253\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.2025 - accuracy: 0.9310\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.1886 - accuracy: 0.9337\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.1799 - accuracy: 0.9373\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.1708 - accuracy: 0.9413\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.1671 - accuracy: 0.9480\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.1566 - accuracy: 0.9520\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.1481 - accuracy: 0.9484\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.1426 - accuracy: 0.9502\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.1416 - accuracy: 0.9528\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1319 - accuracy: 0.9560\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1376 - accuracy: 0.9506\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.1347 - accuracy: 0.9546\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.1356 - accuracy: 0.9493\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.1202 - accuracy: 0.9600\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.1138 - accuracy: 0.9595\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.1118 - accuracy: 0.9604\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.1089 - accuracy: 0.9591\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.1091 - accuracy: 0.9626\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.1013 - accuracy: 0.9657\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0983 - accuracy: 0.9689\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.1008 - accuracy: 0.9666\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0975 - accuracy: 0.9666\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0967 - accuracy: 0.9671\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0894 - accuracy: 0.9706\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0891 - accuracy: 0.9715\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0861 - accuracy: 0.9720\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0835 - accuracy: 0.9746\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0843 - accuracy: 0.9729\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0866 - accuracy: 0.9733\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0812 - accuracy: 0.9760\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0779 - accuracy: 0.9746\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0743 - accuracy: 0.9751\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0705 - accuracy: 0.9818\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0684 - accuracy: 0.9818\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0704 - accuracy: 0.9791\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0646 - accuracy: 0.9862\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0637 - accuracy: 0.9822\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0611 - accuracy: 0.9853\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0634 - accuracy: 0.9813\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0661 - accuracy: 0.9800\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0583 - accuracy: 0.9853\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0551 - accuracy: 0.9884\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0566 - accuracy: 0.9862\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0542 - accuracy: 0.9853\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0519 - accuracy: 0.9902\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0485 - accuracy: 0.9911\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0474 - accuracy: 0.9920\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0459 - accuracy: 0.9911\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0453 - accuracy: 0.9942\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0482 - accuracy: 0.9889\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0427 - accuracy: 0.9947\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0413 - accuracy: 0.9933\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0419 - accuracy: 0.9951\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0397 - accuracy: 0.9947\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0376 - accuracy: 0.9956\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0388 - accuracy: 0.9942\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0361 - accuracy: 0.9973\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0342 - accuracy: 0.9964\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0374 - accuracy: 0.9929\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0327 - accuracy: 0.9973\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0308 - accuracy: 0.9969\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0303 - accuracy: 0.9978\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0303 - accuracy: 0.9973\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0309 - accuracy: 0.9964\n",
      "5/5 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM,Dense\n",
    "import tensorflow as tf\n",
    "y_preds = [] # LSTM predictions at every time point. Will be populated by 5 arrays\n",
    "for i in range(len(RNN_training_data)):\n",
    "    tf.random.set_seed(38)\n",
    "    lstm = Sequential()\n",
    "    lstm.add(LSTM(units=100+20*(i+1), input_shape=(len(data),240), return_sequences=True)) #units=80+10*(i+1)\n",
    "    lstm.add(Dense(units=3, activation='softmax'))\n",
    "    lstm.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']) #loss='categorical_crossentropy'\n",
    "\n",
    "\n",
    "    labels_across_time = np.column_stack([df['labels'].values for df in RNN_training_data[i]])\n",
    "    labels_across_time = np.eye(3)[labels_across_time]\n",
    "\n",
    "\n",
    "    RNN_training_data_fold = [data.drop(columns=[\"labels\"], axis=1) for data in RNN_training_data[i]]\n",
    "    data_arrays_per_timepoint = [df.to_numpy() for df in RNN_training_data_fold]\n",
    "    tensor_3d = np.stack(data_arrays_per_timepoint, axis=0)\n",
    "    tensor_3d = np.transpose(tensor_3d, (1,0,2))\n",
    "\n",
    "    lstm.fit(tensor_3d, labels_across_time, epochs=100)\n",
    "\n",
    "    RNN_test_data_fold = [data.drop(columns=[\"labels\"], axis=1) for data in RNN_test_data[i]]\n",
    "    data_arrays_per_timepoint_test = [df.to_numpy() for df in RNN_test_data_fold]\n",
    "    tensor_3d_test = np.stack(data_arrays_per_timepoint_test, axis=0)\n",
    "    tensor_3d_test = np.transpose(tensor_3d_test, (1,0,2))\n",
    "\n",
    "    y_preds.append(lstm.predict(tensor_3d_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_argmax = [np.argmax(pred, axis=-1) for pred in y_preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trues = []\n",
    "for i in range(len(RNN_test_data)):\n",
    "    y_true = pd.concat([data[\"labels\"] for data in RNN_test_data[i]], axis=1).to_numpy()\n",
    "    y_trues.append(y_true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bl</th>\n",
       "      <th>m06</th>\n",
       "      <th>m12</th>\n",
       "      <th>m24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.631206</td>\n",
       "      <td>0.588652</td>\n",
       "      <td>0.425532</td>\n",
       "      <td>0.432624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.602837</td>\n",
       "      <td>0.574468</td>\n",
       "      <td>0.390071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.485714</td>\n",
       "      <td>0.471429</td>\n",
       "      <td>0.435714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.592857</td>\n",
       "      <td>0.614286</td>\n",
       "      <td>0.485714</td>\n",
       "      <td>0.457143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.528571</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.442857</td>\n",
       "      <td>0.485714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         bl       m06       m12       m24\n",
       "0  0.631206  0.588652  0.425532  0.432624\n",
       "1  0.680851  0.602837  0.574468  0.390071\n",
       "2  0.571429  0.485714  0.471429  0.435714\n",
       "3  0.592857  0.614286  0.485714  0.457143\n",
       "4  0.528571  0.571429  0.442857  0.485714"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1s=[]\n",
    "for i in range(len(y_preds_argmax)):\n",
    "    f1s_for_fold=[]\n",
    "    for j in range(y_preds_argmax[i].shape[-1]):\n",
    "        f1s_for_fold.append(f1_score(y_preds_argmax[i][:,j], y_trues[i][:,j], average='micro'))\n",
    "    f1s.append(f1s_for_fold)\n",
    "\n",
    "f1_df = pd.DataFrame(data=f1s, columns=[\"bl\", \"m06\", \"m12\", \"m24\"])\n",
    "f1_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "\n",
    "confusion_matrices = [ [confusion_matrix(y_pred=y_preds_argmax[i][:,j], y_true=y_trues[i][:,j]) for j in range(len(data))] for i in range(len(y_trues))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " FOLD 1 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.42      0.41        38\n",
      "           1       0.72      0.75      0.74        97\n",
      "           2       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.63       141\n",
      "   macro avg       0.37      0.39      0.38       141\n",
      "weighted avg       0.61      0.63      0.62       141\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.38      0.38        34\n",
      "           1       0.72      0.72      0.72        96\n",
      "           2       0.09      0.09      0.09        11\n",
      "\n",
      "    accuracy                           0.59       141\n",
      "   macro avg       0.40      0.40      0.40       141\n",
      "weighted avg       0.59      0.59      0.59       141\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.44      0.36        36\n",
      "           1       0.61      0.49      0.55        79\n",
      "           2       0.22      0.19      0.20        26\n",
      "\n",
      "    accuracy                           0.43       141\n",
      "   macro avg       0.37      0.38      0.37       141\n",
      "weighted avg       0.46      0.43      0.43       141\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.34      0.36        38\n",
      "           1       0.56      0.57      0.56        65\n",
      "           2       0.27      0.29      0.28        38\n",
      "\n",
      "    accuracy                           0.43       141\n",
      "   macro avg       0.40      0.40      0.40       141\n",
      "weighted avg       0.43      0.43      0.43       141\n",
      "\n",
      " \n",
      " FOLD 2 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.19      0.26        37\n",
      "           1       0.72      0.91      0.81        98\n",
      "           2       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.68       141\n",
      "   macro avg       0.38      0.37      0.35       141\n",
      "weighted avg       0.61      0.68      0.63       141\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.33      0.38        42\n",
      "           1       0.67      0.80      0.73        88\n",
      "           2       0.20      0.09      0.13        11\n",
      "\n",
      "    accuracy                           0.60       141\n",
      "   macro avg       0.44      0.41      0.41       141\n",
      "weighted avg       0.57      0.60      0.58       141\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.46      0.47        41\n",
      "           1       0.67      0.72      0.69        75\n",
      "           2       0.40      0.32      0.36        25\n",
      "\n",
      "    accuracy                           0.57       141\n",
      "   macro avg       0.51      0.50      0.51       141\n",
      "weighted avg       0.56      0.57      0.57       141\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.30      0.36        37\n",
      "           1       0.47      0.54      0.50        65\n",
      "           2       0.21      0.23      0.22        39\n",
      "\n",
      "    accuracy                           0.39       141\n",
      "   macro avg       0.38      0.36      0.36       141\n",
      "weighted avg       0.40      0.39      0.39       141\n",
      "\n",
      " \n",
      " FOLD 3 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.17      0.21        42\n",
      "           1       0.63      0.81      0.71        90\n",
      "           2       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.57       140\n",
      "   macro avg       0.30      0.33      0.31       140\n",
      "weighted avg       0.49      0.57      0.52       140\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.34      0.33        41\n",
      "           1       0.63      0.62      0.62        87\n",
      "           2       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.49       140\n",
      "   macro avg       0.32      0.32      0.32       140\n",
      "weighted avg       0.49      0.49      0.49       140\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.37      0.43        54\n",
      "           1       0.49      0.68      0.57        59\n",
      "           2       0.30      0.22      0.26        27\n",
      "\n",
      "    accuracy                           0.47       140\n",
      "   macro avg       0.44      0.42      0.42       140\n",
      "weighted avg       0.47      0.47      0.46       140\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.42      0.37        33\n",
      "           1       0.61      0.55      0.58        76\n",
      "           2       0.17      0.16      0.17        31\n",
      "\n",
      "    accuracy                           0.44       140\n",
      "   macro avg       0.37      0.38      0.37       140\n",
      "weighted avg       0.45      0.44      0.44       140\n",
      "\n",
      " \n",
      " FOLD 4 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.24      0.27        42\n",
      "           1       0.68      0.78      0.72        94\n",
      "           2       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.59       140\n",
      "   macro avg       0.33      0.34      0.33       140\n",
      "weighted avg       0.55      0.59      0.57       140\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.32      0.39        44\n",
      "           1       0.65      0.86      0.74        84\n",
      "           2       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.61       140\n",
      "   macro avg       0.38      0.39      0.38       140\n",
      "weighted avg       0.55      0.61      0.57       140\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.27      0.25        30\n",
      "           1       0.64      0.61      0.63        80\n",
      "           2       0.38      0.37      0.37        30\n",
      "\n",
      "    accuracy                           0.49       140\n",
      "   macro avg       0.42      0.42      0.42       140\n",
      "weighted avg       0.50      0.49      0.49       140\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.42      0.42        33\n",
      "           1       0.56      0.60      0.58        73\n",
      "           2       0.21      0.18      0.19        34\n",
      "\n",
      "    accuracy                           0.46       140\n",
      "   macro avg       0.40      0.40      0.40       140\n",
      "weighted avg       0.44      0.46      0.45       140\n",
      "\n",
      " \n",
      " FOLD 5 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.19      0.18        36\n",
      "           1       0.68      0.66      0.67       101\n",
      "           2       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.53       140\n",
      "   macro avg       0.28      0.29      0.29       140\n",
      "weighted avg       0.54      0.53      0.53       140\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.29      0.28        31\n",
      "           1       0.70      0.72      0.71        96\n",
      "           2       0.22      0.15      0.18        13\n",
      "\n",
      "    accuracy                           0.57       140\n",
      "   macro avg       0.40      0.39      0.39       140\n",
      "weighted avg       0.56      0.57      0.57       140\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.22      0.17        27\n",
      "           1       0.68      0.54      0.60        85\n",
      "           2       0.33      0.36      0.34        28\n",
      "\n",
      "    accuracy                           0.44       140\n",
      "   macro avg       0.38      0.37      0.37       140\n",
      "weighted avg       0.50      0.44      0.47       140\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.34      0.34        35\n",
      "           1       0.63      0.65      0.64        69\n",
      "           2       0.32      0.31      0.31        36\n",
      "\n",
      "    accuracy                           0.49       140\n",
      "   macro avg       0.43      0.43      0.43       140\n",
      "weighted avg       0.48      0.49      0.48       140\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/opc/.venv/lib64/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/opc/.venv/lib64/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/opc/.venv/lib64/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/opc/.venv/lib64/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/opc/.venv/lib64/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/opc/.venv/lib64/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "final_f1_dem = []\n",
    "for i in range(len(y_preds_argmax)):\n",
    "    print(f\" \\n FOLD {i+1} \\n\")\n",
    "    for j in range(len(data)):\n",
    "        print(classification_report(y_pred=y_preds_argmax[i][:,j], y_true=y_trues[i][:,j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.23449879516586686, 0.054411615812831604)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "dem_f1 = []\n",
    "for i in range(len(y_preds_argmax)):\n",
    "    precision, recall, f1, support = precision_recall_fscore_support(y_pred=y_preds_argmax[i][:,-1], y_true=y_trues[i][:,-1])\n",
    "    dem_f1.append(f1[2])\n",
    "\n",
    "np.mean(dem_f1), np.std(dem_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.27848101265822783,\n",
       " 0.21951219512195125,\n",
       " 0.16666666666666669,\n",
       " 0.1935483870967742,\n",
       " 0.31428571428571433]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dem_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(range(1, len(dem_f1)+1), bins=len(dem_f1), weights=dem_f1, edgecolor='black', alpha=1)\n",
    "plt.title('Distribution of Values in the List')\n",
    "plt.xlabel('# of LSTM Nodes')\n",
    "plt.ylabel('f1 for dementia at final timepoint')\n",
    "plt.xticks(range(1, len(dem_f1) + 1), range(60, 60 + 10 * len(dem_f1), 10))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
