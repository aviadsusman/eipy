{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import pandas as pd\n",
    "import eipy.ei as e\n",
    "from eipy.additional_ensembles import MeanAggregation, CES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eipy.metrics import fmax_score\n",
    "from sklearn.metrics import roc_auc_score, matthews_corrcoef\n",
    "\n",
    "metrics = {\n",
    "            'f_max': fmax_score,\n",
    "            'auc': roc_auc_score,\n",
    "            'mcc': matthews_corrcoef\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_predictors = {\n",
    "                    'ADAB': AdaBoostClassifier(),\n",
    "                    'XGB': XGBClassifier(),\n",
    "                    'DT': DecisionTreeClassifier(),\n",
    "                    'RF': RandomForestClassifier(),\n",
    "                    'GB': GradientBoostingClassifier(),\n",
    "                    'KNN': KNeighborsClassifier(),\n",
    "                    'LR': LogisticRegression(),\n",
    "                    'NB': GaussianNB(),\n",
    "                    'MLP': MLPClassifier(),\n",
    "                    'SVM': SVC(probability=True),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "with open(\"/home/opc/eipy/tadpole/tadpole_data_time_imptn_norm_v1.pickle\", \"rb\") as file:\n",
    "    data = pkl.load(file)\n",
    "with open(\"/home/opc/eipy/tadpole/tadpole_labels_time_imptn_norm_v1.pickle\", \"rb\") as file:\n",
    "    labels = pkl.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [data[k] for k in data.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in labels.items():\n",
    "    labels[k] = v.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#intermediate transformation to make sure labels are ordered correctly in time\n",
    "labels = pd.DataFrame(labels)\n",
    "\n",
    "labels = labels.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# encoding_dict = {'NL': 0, 'MCI': 1, 'Dementia': 2}\n",
    "encoding_dict = {'NL': 0, 'MCI': 1, 'Dementia': 1} # for testsing binary\n",
    "\n",
    "# Use numpy.vectorize with a lambda function to apply the encoding\n",
    "labels = np.vectorize(lambda x: encoding_dict[x])(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(702, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    502\n",
      "0    200\n",
      "Name: count, dtype: int64\n",
      "1    507\n",
      "0    195\n",
      "Name: count, dtype: int64\n",
      "1    510\n",
      "0    192\n",
      "Name: count, dtype: int64\n",
      "1    514\n",
      "0    188\n",
      "Name: count, dtype: int64\n",
      "1    526\n",
      "0    176\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(pd.Series(labels[:,i]).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''misalign data'''\n",
    "data = data[1:]\n",
    "labels = labels[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, (702, 4))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data), labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating metadata for timestep 0\n",
      "Training base predictors on Main cognitive tests...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on MRI volumes...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on Demo, APOE4 & others...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on MRI ROI: Volume (WM Parcellation)...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on MRI ROI: Volume (Cortical Parcellation)...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on MRI ROI: Surface Area...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on MRI ROI: Cortical Thickness Average...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on MRI ROI: Cortical Thickness Standard Deviation...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "generating metadata for timestep 1\n",
      "Training base predictors on Main cognitive tests...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on MRI volumes...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on Demo, APOE4 & others...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on MRI ROI: Volume (WM Parcellation)...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on MRI ROI: Volume (Cortical Parcellation)...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on MRI ROI: Surface Area...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on MRI ROI: Cortical Thickness Average...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on MRI ROI: Cortical Thickness Standard Deviation...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "generating metadata for timestep 2\n",
      "Training base predictors on Main cognitive tests...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on MRI volumes...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on Demo, APOE4 & others...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on MRI ROI: Volume (WM Parcellation)...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on MRI ROI: Volume (Cortical Parcellation)...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on MRI ROI: Surface Area...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on MRI ROI: Cortical Thickness Average...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on MRI ROI: Cortical Thickness Standard Deviation...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "generating metadata for timestep 3\n",
      "Training base predictors on Main cognitive tests...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on MRI volumes...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on Demo, APOE4 & others...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on MRI ROI: Volume (WM Parcellation)...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on MRI ROI: Volume (Cortical Parcellation)...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on MRI ROI: Surface Area...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on MRI ROI: Cortical Thickness Average...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on MRI ROI: Cortical Thickness Standard Deviation...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "meta_data = []\n",
    "for t in range(len(data)):\n",
    "    #time dependent data splitting\n",
    "    X_train_test_timestep = data[t]\n",
    "    labels_at_timestep = labels[:, t]\n",
    "    EI_for_timestep = e.EnsembleIntegration(\n",
    "                        base_predictors=base_predictors,\n",
    "                        k_outer=5,\n",
    "                        k_inner=5,\n",
    "                        n_samples=1,\n",
    "                        sampling_strategy=None,\n",
    "                        sampling_aggregation=\"mean\",\n",
    "                        n_jobs=-1,\n",
    "                        metrics=metrics,\n",
    "                        random_state=38,\n",
    "                        project_name=f\"time step {t}\",\n",
    "                        model_building=False,\n",
    "                        )\n",
    "    print(f\"generating metadata for timestep {t}\")\n",
    "    EI_for_timestep.fit_base(X_train_test_timestep, labels_at_timestep)\n",
    "    meta_data.append([EI_for_timestep.ensemble_training_data, EI_for_timestep.ensemble_test_data, EI_for_timestep.ensemble_training_data_final, EI_for_timestep.base_summary])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_training_data = [[dfs[0][i] for dfs in meta_data] for i in range(5)]\n",
    "RNN_test_data = [[dfs[1][i] for dfs in meta_data] for i in range(5)]\n",
    "RNN_training_data_final = [df[2] for df in meta_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>modality</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Main cognitive tests</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"9\" halign=\"left\">MRI ROI: Cortical Thickness Standard Deviation</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base predictor</th>\n",
       "      <th>ADAB</th>\n",
       "      <th>XGB</th>\n",
       "      <th>DT</th>\n",
       "      <th>RF</th>\n",
       "      <th>GB</th>\n",
       "      <th>KNN</th>\n",
       "      <th>LR</th>\n",
       "      <th>NB</th>\n",
       "      <th>MLP</th>\n",
       "      <th>SVM</th>\n",
       "      <th>...</th>\n",
       "      <th>XGB</th>\n",
       "      <th>DT</th>\n",
       "      <th>RF</th>\n",
       "      <th>GB</th>\n",
       "      <th>KNN</th>\n",
       "      <th>LR</th>\n",
       "      <th>NB</th>\n",
       "      <th>MLP</th>\n",
       "      <th>SVM</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>...</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.505486</td>\n",
       "      <td>0.958904</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.788702</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.663143</td>\n",
       "      <td>0.492347</td>\n",
       "      <td>0.652059</td>\n",
       "      <td>0.711980</td>\n",
       "      <td>...</td>\n",
       "      <td>0.951356</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.787485</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.662486</td>\n",
       "      <td>0.217019</td>\n",
       "      <td>0.673205</td>\n",
       "      <td>0.711213</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.500068</td>\n",
       "      <td>0.727477</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.417248</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.740257</td>\n",
       "      <td>0.810885</td>\n",
       "      <td>0.729524</td>\n",
       "      <td>0.717001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.888306</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.708750</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.831279</td>\n",
       "      <td>0.501342</td>\n",
       "      <td>0.896478</td>\n",
       "      <td>0.747484</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.503276</td>\n",
       "      <td>0.916745</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.741648</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.654685</td>\n",
       "      <td>0.575966</td>\n",
       "      <td>0.636532</td>\n",
       "      <td>0.711819</td>\n",
       "      <td>...</td>\n",
       "      <td>0.080768</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.570000</td>\n",
       "      <td>0.612974</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.517669</td>\n",
       "      <td>0.154307</td>\n",
       "      <td>0.455728</td>\n",
       "      <td>0.614581</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.505286</td>\n",
       "      <td>0.991051</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.741844</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.669352</td>\n",
       "      <td>0.498383</td>\n",
       "      <td>0.648012</td>\n",
       "      <td>0.715373</td>\n",
       "      <td>...</td>\n",
       "      <td>0.403720</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.541566</td>\n",
       "      <td>0.147661</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.621391</td>\n",
       "      <td>0.091220</td>\n",
       "      <td>0.684182</td>\n",
       "      <td>0.708136</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.496880</td>\n",
       "      <td>0.021519</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.216745</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.659404</td>\n",
       "      <td>0.345839</td>\n",
       "      <td>0.624848</td>\n",
       "      <td>0.722468</td>\n",
       "      <td>...</td>\n",
       "      <td>0.737148</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.495242</td>\n",
       "      <td>0.460196</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.521172</td>\n",
       "      <td>0.074794</td>\n",
       "      <td>0.459600</td>\n",
       "      <td>0.668568</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>0.596718</td>\n",
       "      <td>0.591450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.705602</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.686991</td>\n",
       "      <td>0.743053</td>\n",
       "      <td>0.679712</td>\n",
       "      <td>0.716385</td>\n",
       "      <td>...</td>\n",
       "      <td>0.996372</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>0.884912</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.763059</td>\n",
       "      <td>0.998963</td>\n",
       "      <td>0.667635</td>\n",
       "      <td>0.734061</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>0.509774</td>\n",
       "      <td>0.992870</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.865255</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.734773</td>\n",
       "      <td>0.733307</td>\n",
       "      <td>0.767306</td>\n",
       "      <td>0.717208</td>\n",
       "      <td>...</td>\n",
       "      <td>0.720703</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.715780</td>\n",
       "      <td>0.731600</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.742040</td>\n",
       "      <td>0.282675</td>\n",
       "      <td>0.678986</td>\n",
       "      <td>0.749463</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>0.502417</td>\n",
       "      <td>0.898339</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.841495</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.737363</td>\n",
       "      <td>0.801142</td>\n",
       "      <td>0.748774</td>\n",
       "      <td>0.716365</td>\n",
       "      <td>...</td>\n",
       "      <td>0.996742</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.895556</td>\n",
       "      <td>0.945541</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.876282</td>\n",
       "      <td>0.998675</td>\n",
       "      <td>0.864391</td>\n",
       "      <td>0.752014</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>0.502839</td>\n",
       "      <td>0.741628</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.719824</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.693575</td>\n",
       "      <td>0.686652</td>\n",
       "      <td>0.683713</td>\n",
       "      <td>0.714863</td>\n",
       "      <td>...</td>\n",
       "      <td>0.994618</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.913090</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.838823</td>\n",
       "      <td>0.999871</td>\n",
       "      <td>0.808769</td>\n",
       "      <td>0.742413</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>0.496914</td>\n",
       "      <td>0.291351</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.404681</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.798245</td>\n",
       "      <td>0.888762</td>\n",
       "      <td>0.724508</td>\n",
       "      <td>0.703333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.995968</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.967966</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.925654</td>\n",
       "      <td>0.998404</td>\n",
       "      <td>0.958983</td>\n",
       "      <td>0.741548</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>561 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "modality       Main cognitive tests                                      \\\n",
       "base predictor                 ADAB       XGB   DT    RF        GB  KNN   \n",
       "sample                            0         0    0     0         0    0   \n",
       "0                          0.505486  0.958904  1.0  0.81  0.788702  0.4   \n",
       "1                          0.500068  0.727477  0.0  0.70  0.417248  0.6   \n",
       "2                          0.503276  0.916745  1.0  0.78  0.741648  1.0   \n",
       "3                          0.505286  0.991051  1.0  0.85  0.741844  0.6   \n",
       "4                          0.496880  0.021519  0.0  0.13  0.216745  0.2   \n",
       "..                              ...       ...  ...   ...       ...  ...   \n",
       "556                        0.596718  0.591450  0.0  0.55  0.705602  0.6   \n",
       "557                        0.509774  0.992870  1.0  0.94  0.865255  1.0   \n",
       "558                        0.502417  0.898339  1.0  0.67  0.841495  0.8   \n",
       "559                        0.502839  0.741628  0.0  0.66  0.719824  0.6   \n",
       "560                        0.496914  0.291351  1.0  0.46  0.404681  0.6   \n",
       "\n",
       "modality                                                ...  \\\n",
       "base predictor        LR        NB       MLP       SVM  ...   \n",
       "sample                 0         0         0         0  ...   \n",
       "0               0.663143  0.492347  0.652059  0.711980  ...   \n",
       "1               0.740257  0.810885  0.729524  0.717001  ...   \n",
       "2               0.654685  0.575966  0.636532  0.711819  ...   \n",
       "3               0.669352  0.498383  0.648012  0.715373  ...   \n",
       "4               0.659404  0.345839  0.624848  0.722468  ...   \n",
       "..                   ...       ...       ...       ...  ...   \n",
       "556             0.686991  0.743053  0.679712  0.716385  ...   \n",
       "557             0.734773  0.733307  0.767306  0.717208  ...   \n",
       "558             0.737363  0.801142  0.748774  0.716365  ...   \n",
       "559             0.693575  0.686652  0.683713  0.714863  ...   \n",
       "560             0.798245  0.888762  0.724508  0.703333  ...   \n",
       "\n",
       "modality       MRI ROI: Cortical Thickness Standard Deviation                  \\\n",
       "base predictor                                            XGB    DT        RF   \n",
       "sample                                                      0     0         0   \n",
       "0                                                    0.951356  0.00  0.600000   \n",
       "1                                                    0.888306  0.00  0.620000   \n",
       "2                                                    0.080768  0.00  0.570000   \n",
       "3                                                    0.403720  0.00  0.541566   \n",
       "4                                                    0.737148  1.00  0.495242   \n",
       "..                                                        ...   ...       ...   \n",
       "556                                                  0.996372  1.00  0.830000   \n",
       "557                                                  0.720703  0.72  0.715780   \n",
       "558                                                  0.996742  1.00  0.895556   \n",
       "559                                                  0.994618  1.00  0.720000   \n",
       "560                                                  0.995968  1.00  0.780000   \n",
       "\n",
       "modality                                                              labels  \n",
       "base predictor        GB  KNN        LR        NB       MLP       SVM         \n",
       "sample                 0    0         0         0         0         0         \n",
       "0               0.787485  1.0  0.662486  0.217019  0.673205  0.711213      0  \n",
       "1               0.708750  0.8  0.831279  0.501342  0.896478  0.747484      0  \n",
       "2               0.612974  0.8  0.517669  0.154307  0.455728  0.614581      1  \n",
       "3               0.147661  1.0  0.621391  0.091220  0.684182  0.708136      0  \n",
       "4               0.460196  0.8  0.521172  0.074794  0.459600  0.668568      1  \n",
       "..                   ...  ...       ...       ...       ...       ...    ...  \n",
       "556             0.884912  0.6  0.763059  0.998963  0.667635  0.734061      0  \n",
       "557             0.731600  1.0  0.742040  0.282675  0.678986  0.749463      1  \n",
       "558             0.945541  1.0  0.876282  0.998675  0.864391  0.752014      1  \n",
       "559             0.913090  1.0  0.838823  0.999871  0.808769  0.742413      1  \n",
       "560             0.967966  0.8  0.925654  0.998404  0.958983  0.741548      1  \n",
       "\n",
       "[561 rows x 81 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RNN_training_data[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make first time point in meta-data multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_column_names(frame):\n",
    "    column_names = []\n",
    "    for i in range(frame.columns.nlevels):\n",
    "        if i == 0:\n",
    "            column_names.append(frame.columns.get_level_values(i).unique().drop(\"labels\"))\n",
    "            \n",
    "        else:\n",
    "            column_names.append(frame.columns.get_level_values(i).unique().drop(''))\n",
    "    \n",
    "    return column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_first_time_point(df):\n",
    "    new_columns = get_column_names(df)\n",
    "    classes=[0,1,2]\n",
    "    new_columns.append(classes)\n",
    "    new_mux=pd.MultiIndex.from_product(iterables=new_columns, names=[\"modality\", \"base predictor\", \"sample\", \"class\"])\n",
    "    new_df = pd.DataFrame(columns=new_mux)\n",
    "\n",
    "    for col in new_df.columns:\n",
    "        if col[-1] == 0:\n",
    "            new_df[col] = 1 - df[col[:-1]]\n",
    "        elif col[-1] == 1:\n",
    "            new_df[col] = df[col[:-1]]\n",
    "        else:\n",
    "            new_df[col] = 0\n",
    "    \n",
    "    new_df['labels'] = df['labels']\n",
    "\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(RNN_training_data)):\n",
    "    RNN_training_data[i][0] = fix_first_time_point(RNN_training_data[i][0])\n",
    "    RNN_test_data[i][0] = fix_first_time_point(RNN_test_data[i][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TIME SERIES TIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-18 18:17:31.496225: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-18 18:17:31.522673: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-18 18:17:31.522700: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-18 18:17:31.523491: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-18 18:17:31.528068: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-18 18:17:31.528565: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-18 18:17:32.311366: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def ordinal_regression_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Ordinal regression loss function.\n",
    "\n",
    "    Parameters:\n",
    "    - y_true: true labels (ground truth)\n",
    "    - y_pred: predicted labels\n",
    "\n",
    "    Returns:\n",
    "    - loss value\n",
    "    \"\"\"\n",
    "    # Assuming y_true and y_pred are tensors of shape (batch_size, num_classes)\n",
    "\n",
    "    # Calculate cumulative probabilities for true and predicted labels\n",
    "    true_cum_probs = K.cumsum(K.softmax(y_true, axis=-1), axis=-1)\n",
    "    pred_cum_probs = K.cumsum(K.softmax(y_pred, axis=-1), axis=-1)\n",
    "\n",
    "    # Calculate the ordinal regression loss\n",
    "    loss = K.sum((true_cum_probs - pred_cum_probs) ** 2)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = [] # LSTM predictions at every time point. Will be populated by 5 arrays\n",
    "for i in range(len(RNN_training_data)):\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import LSTM,Dense\n",
    "    lstm = Sequential()\n",
    "    lstm.add(LSTM(units=50+10*i, input_shape=(4,240), return_sequences=True))\n",
    "    lstm.add(Dense(units=3, activation='softmax'))\n",
    "    lstm.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']) #loss='categorical_crossentropy'\n",
    "\n",
    "\n",
    "    labels_across_time = np.column_stack([df['labels'].values for df in RNN_training_data[i]])\n",
    "    labels_across_time = np.eye(3)[labels_across_time]\n",
    "\n",
    "    RNN_training_data_fold = [data.drop(columns=[\"labels\"], axis=1) for data in RNN_training_data[i]]\n",
    "    data_arrays_per_timepoint = [df.to_numpy() for df in RNN_training_data_fold]\n",
    "    tensor_3d = np.stack(data_arrays_per_timepoint, axis=0)\n",
    "    tensor_3d = np.transpose(tensor_3d, (1,0,2))\n",
    "\n",
    "    lstm.fit(tensor_3d, labels_across_time)\n",
    "\n",
    "    RNN_test_data_fold = [data.drop(columns=[\"labels\"], axis=1) for data in RNN_test_data[i]]\n",
    "    data_arrays_per_timepoint_test = [df.to_numpy() for df in RNN_test_data_fold]\n",
    "    tensor_3d_test = np.stack(data_arrays_per_timepoint_test, axis=0)\n",
    "    tensor_3d_test = np.transpose(tensor_3d_test, (1,0,2))\n",
    "\n",
    "    y_preds.append(lstm.predict(tensor_3d_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_argmax = [np.argmax(pred, axis=-1) for pred in y_preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trues = []\n",
    "for i in range(len(RNN_test_data)):\n",
    "    y_true = pd.concat([data[\"labels\"] for data in RNN_test_data[i]], axis=1).to_numpy()\n",
    "    y_trues.append(y_true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "for i in range(len(y_preds_argmax)):\n",
    "    print(f\" \\n FOLD {i+1} \\n\")\n",
    "    for j in range(4):\n",
    "        print(classification_report(y_pred=y_preds_argmax[i][:,j], y_true=y_trues[i][:,j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "dem_f1 = []\n",
    "for i in range(len(y_preds_argmax)):\n",
    "    precision, recall, f1, support = precision_recall_fscore_support(y_pred=y_preds_argmax[i][:,-1], y_true=y_trues[i][:,-1])\n",
    "    dem_f1.append(f1[2])\n",
    "\n",
    "np.mean(dem_f1), np.std(dem_f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
