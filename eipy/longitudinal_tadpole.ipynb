{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import pandas as pd\n",
    "import eipy.ei as e\n",
    "from eipy.additional_ensembles import MeanAggregation, CES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eipy.metrics import fmax_score\n",
    "from sklearn.metrics import roc_auc_score, matthews_corrcoef\n",
    "\n",
    "metrics = {\n",
    "            'f_max': fmax_score,\n",
    "            'auc': roc_auc_score,\n",
    "            'mcc': matthews_corrcoef\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_predictors = {\n",
    "                    'ADAB': AdaBoostClassifier(),\n",
    "                    'XGB': XGBClassifier(),\n",
    "                    'DT': DecisionTreeClassifier(),\n",
    "                    'RF': RandomForestClassifier(),\n",
    "                    'GB': GradientBoostingClassifier(),\n",
    "                    'KNN': KNeighborsClassifier(),\n",
    "                    'LR': LogisticRegression(),\n",
    "                    'NB': GaussianNB(),\n",
    "                    'MLP': MLPClassifier(),\n",
    "                    'SVM': SVC(probability=True),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "with open(\"/home/opc/eipy/tadpole/tadpole_data_time_imptn_norm_v1.pickle\", \"rb\") as file:\n",
    "    data = pkl.load(file)\n",
    "with open(\"/home/opc/eipy/tadpole/tadpole_labels_time_imptn_norm_v1.pickle\", \"rb\") as file:\n",
    "    labels = pkl.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [data[k] for k in data.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in labels.items():\n",
    "    labels[k] = v.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#intermediate transformation to make sure labels are ordered correctly in time\n",
    "labels = pd.DataFrame(labels)\n",
    "\n",
    "labels = labels.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "encoding_dict = {'NL': 0, 'MCI': 1, 'Dementia': 2}\n",
    "\n",
    "# Use numpy.vectorize with a lambda function to apply the encoding\n",
    "labels = np.vectorize(lambda x: encoding_dict[x])(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(702, 5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    502\n",
      "0    200\n",
      "Name: count, dtype: int64\n",
      "1    480\n",
      "0    195\n",
      "2     27\n",
      "Name: count, dtype: int64\n",
      "1    451\n",
      "0    192\n",
      "2     59\n",
      "Name: count, dtype: int64\n",
      "1    378\n",
      "0    188\n",
      "2    136\n",
      "Name: count, dtype: int64\n",
      "1    348\n",
      "2    178\n",
      "0    176\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(pd.Series(labels[:,i]).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating metadata for timestep 0\n",
      "Training base predictors on Main cognitive tests...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |          |  0%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on MRI volumes...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on Demo, APOE4 & others...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on MRI ROI: Volume (WM Parcellation)...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on MRI ROI: Volume (Cortical Parcellation)...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on MRI ROI: Surface Area...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on MRI ROI: Cortical Thickness Average...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on MRI ROI: Cortical Thickness Standard Deviation...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "generating metadata for timestep 1\n",
      "Training base predictors on Main cognitive tests...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on MRI volumes...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on Demo, APOE4 & others...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on MRI ROI: Volume (WM Parcellation)...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on MRI ROI: Volume (Cortical Parcellation)...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on MRI ROI: Surface Area...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on MRI ROI: Cortical Thickness Average...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on MRI ROI: Cortical Thickness Standard Deviation...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "generating metadata for timestep 2\n",
      "Training base predictors on Main cognitive tests...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on MRI volumes...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on Demo, APOE4 & others...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on MRI ROI: Volume (WM Parcellation)...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on MRI ROI: Volume (Cortical Parcellation)...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on MRI ROI: Surface Area...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on MRI ROI: Cortical Thickness Average...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on MRI ROI: Cortical Thickness Standard Deviation...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "generating metadata for timestep 3\n",
      "Training base predictors on Main cognitive tests...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on MRI volumes...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on Demo, APOE4 & others...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on MRI ROI: Volume (WM Parcellation)...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on MRI ROI: Volume (Cortical Parcellation)...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on MRI ROI: Surface Area...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on MRI ROI: Cortical Thickness Average...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on MRI ROI: Cortical Thickness Standard Deviation...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "generating metadata for timestep 4\n",
      "Training base predictors on Main cognitive tests...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on MRI volumes...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on Demo, APOE4 & others...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on MRI ROI: Volume (WM Parcellation)...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on MRI ROI: Volume (Cortical Parcellation)...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on MRI ROI: Surface Area...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on MRI ROI: Cortical Thickness Average...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on MRI ROI: Cortical Thickness Standard Deviation...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "meta_data = []\n",
    "for t in range(len(data)):\n",
    "    #time dependent data splitting\n",
    "    X_train_timestep = data[t]\n",
    "    labels_at_timestep = labels[:, t]\n",
    "    EI_for_timestep = e.EnsembleIntegration(\n",
    "                        base_predictors=base_predictors,\n",
    "                        k_outer=5,\n",
    "                        k_inner=5,\n",
    "                        n_samples=1,\n",
    "                        sampling_strategy=None,\n",
    "                        sampling_aggregation=\"mean\",\n",
    "                        n_jobs=-1,\n",
    "                        metrics=metrics,\n",
    "                        random_state=38,\n",
    "                        project_name=f\"time step {t}\",\n",
    "                        model_building=False,\n",
    "                        )\n",
    "    print(f\"generating metadata for timestep {t}\")\n",
    "    EI_for_timestep.fit_base(X_train_timestep, labels_at_timestep)\n",
    "    meta_data.append([EI_for_timestep.ensemble_training_data, EI_for_timestep.ensemble_test_data, EI_for_timestep.ensemble_training_data_final, EI_for_timestep.base_summary])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_training_data = [[dfs[0][i] for dfs in meta_data] for i in range(5)]\n",
    "RNN_test_data = [[dfs[1][i] for dfs in meta_data] for i in range(5)]\n",
    "RNN_training_data_final = [df[2] for df in meta_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make first time point in meta-data multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_column_names(frame):\n",
    "    column_names = []\n",
    "    for i in range(frame.columns.nlevels):\n",
    "        if i == 0:\n",
    "            column_names.append(frame.columns.get_level_values(i).unique().drop(\"labels\"))\n",
    "            \n",
    "        else:\n",
    "            column_names.append(frame.columns.get_level_values(i).unique().drop(''))\n",
    "    \n",
    "    return column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_first_time_point(df):\n",
    "    new_columns = get_column_names(df)\n",
    "    classes=[0,1,2]\n",
    "    new_columns.append(classes)\n",
    "    new_mux=pd.MultiIndex.from_product(iterables=new_columns, names=[\"modality\", \"base predictor\", \"sample\", \"class\"])\n",
    "    new_df = pd.DataFrame(columns=new_mux)\n",
    "\n",
    "    for col in new_df.columns:\n",
    "        if col[-1] == 0:\n",
    "            new_df[col] = 1 - df[col[:-1]]\n",
    "        elif col[-1] == 1:\n",
    "            new_df[col] = df[col[:-1]]\n",
    "        else:\n",
    "            new_df[col] = 0\n",
    "    \n",
    "    new_df['labels'] = df['labels']\n",
    "\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2204953/2424389332.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df['labels'] = df['labels']\n",
      "/tmp/ipykernel_2204953/2424389332.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df['labels'] = df['labels']\n",
      "/tmp/ipykernel_2204953/2424389332.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df['labels'] = df['labels']\n",
      "/tmp/ipykernel_2204953/2424389332.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df['labels'] = df['labels']\n",
      "/tmp/ipykernel_2204953/2424389332.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df['labels'] = df['labels']\n",
      "/tmp/ipykernel_2204953/2424389332.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df['labels'] = df['labels']\n",
      "/tmp/ipykernel_2204953/2424389332.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df['labels'] = df['labels']\n",
      "/tmp/ipykernel_2204953/2424389332.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df['labels'] = df['labels']\n",
      "/tmp/ipykernel_2204953/2424389332.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df['labels'] = df['labels']\n",
      "/tmp/ipykernel_2204953/2424389332.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  new_df['labels'] = df['labels']\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(RNN_training_data)):\n",
    "    RNN_training_data[i][0] = fix_first_time_point(RNN_training_data[i][0])\n",
    "    RNN_test_data[i][0] = fix_first_time_point(RNN_test_data[i][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TIME SERIES TIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def ordinal_regression_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Ordinal regression loss function.\n",
    "\n",
    "    Parameters:\n",
    "    - y_true: true labels (ground truth)\n",
    "    - y_pred: predicted labels\n",
    "\n",
    "    Returns:\n",
    "    - loss value\n",
    "    \"\"\"\n",
    "    # Assuming y_true and y_pred are tensors of shape (batch_size, num_classes)\n",
    "\n",
    "    # Calculate cumulative probabilities for true and predicted labels\n",
    "    true_cum_probs = K.cumsum(K.softmax(y_true, axis=-1), axis=-1)\n",
    "    pred_cum_probs = K.cumsum(K.softmax(y_pred, axis=-1), axis=-1)\n",
    "\n",
    "    # Calculate the ordinal regression loss\n",
    "    loss = K.sum((true_cum_probs - pred_cum_probs) ** 2)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM,Dense\n",
    "lstm = Sequential()\n",
    "lstm.add(LSTM(units=50, input_shape=(5,240), return_sequences=True))\n",
    "lstm.add(Dense(units=3, activation='softmax'))\n",
    "lstm.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']) #loss='categorical_crossentropy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2204953/3712617700.py:14: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  RNN_training_data_fold = [data.drop(columns=[\"labels\"], axis=1) for data in RNN_training_data[i]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 2s 3ms/step - loss: 0.7588 - accuracy: 0.6799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2204953/3712617700.py:21: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  RNN_test_data_fold = [data.drop(columns=[\"labels\"], axis=1) for data in RNN_test_data[i]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 1s 3ms/step - loss: 0.7067 - accuracy: 0.7116\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 1s 3ms/step - loss: 0.9007 - accuracy: 0.6075\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 1s 3ms/step - loss: 0.8386 - accuracy: 0.6181\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 1s 3ms/step - loss: 0.8366 - accuracy: 0.6537\n",
      "5/5 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "y_preds = [] # LSTM predictions at every time point. Will be populated by 5 arrays\n",
    "for i in range(len(RNN_training_data)):\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import LSTM,Dense\n",
    "    lstm = Sequential()\n",
    "    lstm.add(LSTM(units=50, input_shape=(5,240), return_sequences=True))\n",
    "    lstm.add(Dense(units=3, activation='softmax'))\n",
    "    lstm.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']) #loss='categorical_crossentropy'\n",
    "\n",
    "\n",
    "    labels_across_time = np.column_stack([df['labels'].values for df in RNN_training_data[i]])\n",
    "    labels_across_time = np.eye(3)[labels_across_time]\n",
    "\n",
    "    RNN_training_data_fold = [data.drop(columns=[\"labels\"], axis=1) for data in RNN_training_data[i]]\n",
    "    data_arrays_per_timepoint = [df.to_numpy() for df in RNN_training_data_fold]\n",
    "    tensor_3d = np.stack(data_arrays_per_timepoint, axis=0)\n",
    "    tensor_3d = np.transpose(tensor_3d, (1,0,2))\n",
    "\n",
    "    lstm.fit(tensor_3d, labels_across_time)\n",
    "\n",
    "    RNN_test_data_fold = [data.drop(columns=[\"labels\"], axis=1) for data in RNN_test_data[i]]\n",
    "    data_arrays_per_timepoint_test = [df.to_numpy() for df in RNN_test_data_fold]\n",
    "    tensor_3d_test = np.stack(data_arrays_per_timepoint_test, axis=0)\n",
    "    tensor_3d_test = np.transpose(tensor_3d_test, (1,0,2))\n",
    "\n",
    "    y_preds.append(lstm.predict(tensor_3d_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_argmax = [np.argmax(pred, axis=-1) for pred in y_preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trues = []\n",
    "for i in range(len(RNN_test_data)):\n",
    "    y_true = pd.concat([data[\"labels\"] for data in RNN_test_data[i]], axis=1).to_numpy()\n",
    "    y_trues.append(y_true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m06</th>\n",
       "      <th>m12</th>\n",
       "      <th>m24</th>\n",
       "      <th>m36</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.939721</td>\n",
       "      <td>0.881370</td>\n",
       "      <td>0.885276</td>\n",
       "      <td>0.908874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.887696</td>\n",
       "      <td>0.929288</td>\n",
       "      <td>0.883930</td>\n",
       "      <td>0.884863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.902486</td>\n",
       "      <td>0.866775</td>\n",
       "      <td>0.895492</td>\n",
       "      <td>0.891497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.898553</td>\n",
       "      <td>0.934735</td>\n",
       "      <td>0.903700</td>\n",
       "      <td>0.915057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.803002</td>\n",
       "      <td>0.766356</td>\n",
       "      <td>0.876446</td>\n",
       "      <td>0.904618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        m06       m12       m24       m36\n",
       "0  0.939721  0.881370  0.885276  0.908874\n",
       "1  0.887696  0.929288  0.883930  0.884863\n",
       "2  0.902486  0.866775  0.895492  0.891497\n",
       "3  0.898553  0.934735  0.903700  0.915057\n",
       "4  0.803002  0.766356  0.876446  0.904618"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "aucs=[]\n",
    "for i in range(len(y_preds)):\n",
    "    aucs_for_fold=[]\n",
    "    for j in range(1, y_preds[i].shape[-2]):\n",
    "        aucs_for_fold.append(roc_auc_score(y_trues[i][:,j], y_preds[i][:,j], multi_class='ovr'))\n",
    "    aucs.append(aucs_for_fold)\n",
    "\n",
    "auc_df = pd.DataFrame(data=aucs, columns=[\"m06\", \"m12\", \"m24\", \"m36\"])\n",
    "auc_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bl</th>\n",
       "      <th>m06</th>\n",
       "      <th>m12</th>\n",
       "      <th>m24</th>\n",
       "      <th>m36</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.964539</td>\n",
       "      <td>0.865248</td>\n",
       "      <td>0.801418</td>\n",
       "      <td>0.659574</td>\n",
       "      <td>0.695035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.886525</td>\n",
       "      <td>0.822695</td>\n",
       "      <td>0.773050</td>\n",
       "      <td>0.673759</td>\n",
       "      <td>0.638298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.778571</td>\n",
       "      <td>0.764286</td>\n",
       "      <td>0.721429</td>\n",
       "      <td>0.685714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.871429</td>\n",
       "      <td>0.807143</td>\n",
       "      <td>0.707143</td>\n",
       "      <td>0.707143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.778571</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.678571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         bl       m06       m12       m24       m36\n",
       "0  0.964539  0.865248  0.801418  0.659574  0.695035\n",
       "1  0.886525  0.822695  0.773050  0.673759  0.638298\n",
       "2  0.950000  0.778571  0.764286  0.721429  0.685714\n",
       "3  0.928571  0.871429  0.807143  0.707143  0.707143\n",
       "4  0.800000  0.828571  0.778571  0.650000  0.678571"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1s=[]\n",
    "for i in range(len(y_preds_argmax)):\n",
    "    f1s_for_fold=[]\n",
    "    for j in range(y_preds_argmax[i].shape[-1]):\n",
    "        f1s_for_fold.append(f1_score(y_preds_argmax[i][:,j], y_trues[i][:,j], average='micro'))\n",
    "    f1s.append(f1s_for_fold)\n",
    "\n",
    "f1_df = pd.DataFrame(data=f1s, columns=[\"bl\", \"m06\", \"m12\", \"m24\", \"m36\"])\n",
    "f1_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "\n",
    "confusion_matrices = [ [confusion_matrix(y_pred=y_preds_argmax[i][:,j], y_true=y_trues[i][:,j]) for j in range(5)] for i in range(len(y_trues))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_reports = [[classification_report(y_pred=y_preds_argmax[i][:,j], y_true=y_trues[i][:,j]) for j in range(5)] for i in range(len(y_trues))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " FOLD 1 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.90      0.94        40\n",
      "           1       0.96      0.99      0.98       101\n",
      "\n",
      "    accuracy                           0.96       141\n",
      "   macro avg       0.97      0.95      0.96       141\n",
      "weighted avg       0.96      0.96      0.96       141\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.72      0.81        39\n",
      "           1       0.85      0.98      0.91        96\n",
      "           2       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.87       141\n",
      "   macro avg       0.59      0.57      0.57       141\n",
      "weighted avg       0.83      0.87      0.84       141\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.74      0.78        39\n",
      "           1       0.79      0.93      0.86        90\n",
      "           2       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.80       141\n",
      "   macro avg       0.54      0.56      0.55       141\n",
      "weighted avg       0.74      0.80      0.76       141\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.47      0.58        38\n",
      "           1       0.63      0.93      0.75        76\n",
      "           2       1.00      0.15      0.26        27\n",
      "\n",
      "    accuracy                           0.66       141\n",
      "   macro avg       0.79      0.52      0.53       141\n",
      "weighted avg       0.73      0.66      0.61       141\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.64      0.69        36\n",
      "           1       0.64      0.87      0.74        69\n",
      "           2       0.94      0.42      0.58        36\n",
      "\n",
      "    accuracy                           0.70       141\n",
      "   macro avg       0.77      0.64      0.67       141\n",
      "weighted avg       0.74      0.70      0.68       141\n",
      "\n",
      " \n",
      " FOLD 2 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.60      0.75        40\n",
      "           1       0.86      1.00      0.93       101\n",
      "\n",
      "    accuracy                           0.89       141\n",
      "   macro avg       0.93      0.80      0.84       141\n",
      "weighted avg       0.90      0.89      0.88       141\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.54      0.69        39\n",
      "           1       0.80      0.99      0.88        96\n",
      "           2       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.82       141\n",
      "   macro avg       0.58      0.51      0.52       141\n",
      "weighted avg       0.81      0.82      0.79       141\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.59      0.70        39\n",
      "           1       0.75      0.96      0.84        90\n",
      "           2       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.77       141\n",
      "   macro avg       0.54      0.52      0.51       141\n",
      "weighted avg       0.72      0.77      0.73       141\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.61      0.68        38\n",
      "           1       0.65      0.95      0.77        76\n",
      "           2       0.00      0.00      0.00        27\n",
      "\n",
      "    accuracy                           0.67       141\n",
      "   macro avg       0.47      0.52      0.48       141\n",
      "weighted avg       0.56      0.67      0.60       141\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.66      0.66        35\n",
      "           1       0.62      0.91      0.74        70\n",
      "           2       1.00      0.08      0.15        36\n",
      "\n",
      "    accuracy                           0.64       141\n",
      "   macro avg       0.76      0.55      0.52       141\n",
      "weighted avg       0.73      0.64      0.57       141\n",
      "\n",
      " \n",
      " FOLD 3 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.82      0.90        40\n",
      "           1       0.93      1.00      0.97       100\n",
      "\n",
      "    accuracy                           0.95       140\n",
      "   macro avg       0.97      0.91      0.94       140\n",
      "weighted avg       0.95      0.95      0.95       140\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.44      0.57        39\n",
      "           1       0.77      0.96      0.86        96\n",
      "           2       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.78       140\n",
      "   macro avg       0.53      0.46      0.47       140\n",
      "weighted avg       0.76      0.78      0.74       140\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.55      0.65        38\n",
      "           1       0.76      0.95      0.84        91\n",
      "           2       0.00      0.00      0.00        11\n",
      "\n",
      "    accuracy                           0.76       140\n",
      "   macro avg       0.51      0.50      0.50       140\n",
      "weighted avg       0.71      0.76      0.72       140\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.55      0.68        38\n",
      "           1       0.67      0.99      0.80        75\n",
      "           2       1.00      0.22      0.36        27\n",
      "\n",
      "    accuracy                           0.72       140\n",
      "   macro avg       0.85      0.59      0.61       140\n",
      "weighted avg       0.79      0.72      0.68       140\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.46      0.56        35\n",
      "           1       0.64      0.94      0.76        70\n",
      "           2       0.93      0.40      0.56        35\n",
      "\n",
      "    accuracy                           0.69       140\n",
      "   macro avg       0.77      0.60      0.63       140\n",
      "weighted avg       0.74      0.69      0.66       140\n",
      "\n",
      " \n",
      " FOLD 4 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.75      0.86        40\n",
      "           1       0.91      1.00      0.95       100\n",
      "\n",
      "    accuracy                           0.93       140\n",
      "   macro avg       0.95      0.88      0.90       140\n",
      "weighted avg       0.94      0.93      0.93       140\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.67      0.80        39\n",
      "           1       0.84      1.00      0.91        96\n",
      "           2       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.87       140\n",
      "   macro avg       0.61      0.56      0.57       140\n",
      "weighted avg       0.86      0.87      0.85       140\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.63      0.76        38\n",
      "           1       0.77      0.99      0.87        90\n",
      "           2       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.81       140\n",
      "   macro avg       0.58      0.54      0.54       140\n",
      "weighted avg       0.76      0.81      0.76       140\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.62      0.74        37\n",
      "           1       0.65      0.99      0.79        75\n",
      "           2       1.00      0.07      0.13        28\n",
      "\n",
      "    accuracy                           0.71       140\n",
      "   macro avg       0.86      0.56      0.55       140\n",
      "weighted avg       0.79      0.71      0.64       140\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.69      0.77        35\n",
      "           1       0.65      1.00      0.79        70\n",
      "           2       1.00      0.14      0.25        35\n",
      "\n",
      "    accuracy                           0.71       140\n",
      "   macro avg       0.85      0.61      0.60       140\n",
      "weighted avg       0.80      0.71      0.65       140\n",
      "\n",
      " \n",
      " FOLD 5 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.30      0.46        40\n",
      "           1       0.78      1.00      0.88       100\n",
      "\n",
      "    accuracy                           0.80       140\n",
      "   macro avg       0.89      0.65      0.67       140\n",
      "weighted avg       0.84      0.80      0.76       140\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.54      0.69        39\n",
      "           1       0.81      0.99      0.89        96\n",
      "           2       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.83       140\n",
      "   macro avg       0.59      0.51      0.53       140\n",
      "weighted avg       0.82      0.83      0.80       140\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.53      0.68        38\n",
      "           1       0.75      0.99      0.85        90\n",
      "           2       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.78       140\n",
      "   macro avg       0.57      0.51      0.51       140\n",
      "weighted avg       0.74      0.78      0.73       140\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.57      0.62        37\n",
      "           1       0.64      0.89      0.74        76\n",
      "           2       1.00      0.07      0.14        27\n",
      "\n",
      "    accuracy                           0.65       140\n",
      "   macro avg       0.77      0.51      0.50       140\n",
      "weighted avg       0.72      0.65      0.59       140\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.57      0.67        35\n",
      "           1       0.62      0.94      0.75        69\n",
      "           2       0.91      0.28      0.43        36\n",
      "\n",
      "    accuracy                           0.68       140\n",
      "   macro avg       0.78      0.60      0.61       140\n",
      "weighted avg       0.74      0.68      0.65       140\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(y_preds_argmax)):\n",
    "    print(f\" \\n FOLD {i+1} \\n\")\n",
    "    for j in range(5):\n",
    "        print(classification_report(y_pred=y_preds_argmax[i][:,j], y_true=y_trues[i][:,j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
