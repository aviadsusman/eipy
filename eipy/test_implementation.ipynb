{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from eipy.ei import EnsembleIntegration\n",
    "from eipy.additional_ensembles import MeanAggregation, CES\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate multimodal multiclass data.\n",
    "https://dev.pages.lis-lab.fr/scikit-multimodallearn/tutorial/auto_examples/combo/plot_combo_3_views_3_classes.html#\n",
    "\"\"\"\n",
    "def generate_data(n_samples, lim):\n",
    "    \"\"\"Generate random data in a rectangle\"\"\"\n",
    "    lim = np.array(lim)\n",
    "    n_features = lim.shape[0]\n",
    "    data = np.random.random((n_samples, n_features))\n",
    "    data = (lim[:, 1]-lim[:, 0]) * data + lim[:, 0]\n",
    "    return data\n",
    "\n",
    "\n",
    "seed = 12\n",
    "np.random.seed(seed)\n",
    "\n",
    "n_samples = 300\n",
    "\n",
    "view_0 = np.concatenate((generate_data(n_samples, [[0., 1.], [0., 1.]]),\n",
    "                         generate_data(n_samples, [[1., 2.], [0., 1.]]),\n",
    "                         generate_data(n_samples, [[0., 2.], [0., 1.]])))\n",
    "\n",
    "view_1 = np.concatenate((generate_data(n_samples, [[1., 2.], [0., 1.]]),\n",
    "                         generate_data(n_samples, [[0., 2.], [0., 1.]]),\n",
    "                         generate_data(n_samples, [[0., 1.], [0., 1.]])))\n",
    "\n",
    "view_2 = np.concatenate((generate_data(n_samples, [[0., 2.], [0., 1.]]),\n",
    "                         generate_data(n_samples, [[0., 1.], [0., 1.]]),\n",
    "                         generate_data(n_samples, [[1., 2.], [0., 1.]])))\n",
    "\n",
    "X = np.concatenate((view_0, view_1, view_2), axis=1)\n",
    "\n",
    "y = np.zeros(3*n_samples, dtype=np.int64)\n",
    "y[n_samples:2*n_samples] = 1\n",
    "y[2*n_samples:] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_0_train, X_0_test, y_train, y_test = train_test_split(view_0, y, test_size=0.2, random_state=3, stratify=y)\n",
    "X_1_train, X_1_test, _, _ = train_test_split(view_1, y, test_size=0.2, random_state=3, stratify=y)\n",
    "X_2_train, X_2_test, _, _ = train_test_split(view_2, y, test_size=0.2, random_state=3, stratify=y)\n",
    "\n",
    "data_train = {\n",
    "                \"Modality_0\": X_0_train,\n",
    "                \"Modality_1\": X_1_train,\n",
    "                \"Modality_2\": X_2_train\n",
    "                }\n",
    "\n",
    "data_test = {\n",
    "                \"Modality_0\": X_0_test,\n",
    "                \"Modality_1\": X_1_test,\n",
    "                \"Modality_2\": X_2_test,\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_predictors = {\n",
    "                    'ADAB': AdaBoostClassifier(),\n",
    "                    'XGB': XGBClassifier(),\n",
    "                    'DT': DecisionTreeClassifier(),\n",
    "                    'RF': RandomForestClassifier(),\n",
    "                    'GB': GradientBoostingClassifier(),\n",
    "                    'KNN': KNeighborsClassifier(),\n",
    "                    'LR': LogisticRegression(),\n",
    "                    'NB': GaussianNB(),\n",
    "                    'MLP': MLPClassifier(),\n",
    "                    'SVM': SVC(probability=True),\n",
    "}\n",
    "meta_predictors = {\n",
    "                    'Mean' : MeanAggregation(),\n",
    "                    'CES' : CES(),\n",
    "                    'S.ADAB': AdaBoostClassifier(),\n",
    "                    'S.XGB': XGBClassifier(),\n",
    "                    'S.DT': DecisionTreeClassifier(),\n",
    "                    \"S.RF\": RandomForestClassifier(),\n",
    "                    'S.GB': GradientBoostingClassifier(),\n",
    "                    'S.KNN': KNeighborsClassifier(),\n",
    "                    'S.LR': LogisticRegression(),\n",
    "                    'S.NB': GaussianNB(),\n",
    "                    'S.MLP': MLPClassifier(),\n",
    "                    'S.SVM': SVC(probability=True),\n",
    "}\n",
    "n_classes = len(set(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training base predictors on Modality_0...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating meta training data: |██████████|100%\n",
      "Generating meta test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "... for final ensemble...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating meta training data: |██████████|100%\n",
      "Training final base predictors: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on Modality_1...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating meta training data: |██████████|100%\n",
      "Generating meta test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "... for final ensemble...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating meta training data: |██████████|100%\n",
      "Training final base predictors: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on Modality_2...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating meta training data: |██████████|100%\n",
      "Generating meta test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "... for final ensemble...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating meta training data: |██████████|100%\n",
      "Training final base predictors: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing ensembles: |██████████|100%\n",
      "Training final meta models: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training base predictors on Modality_0...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating meta training data: |██████████|100%\n",
      "Generating meta test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "... for final ensemble...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating meta training data: |██████████|100%\n",
      "Training final base predictors: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on Modality_1...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating meta training data: |██████████|100%\n",
      "Generating meta test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "... for final ensemble...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating meta training data: |██████████|100%\n",
      "Training final base predictors: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on Modality_2...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating meta training data: |██████████|100%\n",
      "Generating meta test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "... for final ensemble...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating meta training data: |██████████|100%\n",
      "Training final base predictors: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing ensembles: |██████████|100%\n",
      "Training final meta models: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training base predictors on Modality_0...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating meta training data: |██████████|100%\n",
      "Generating meta test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "... for final ensemble...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating meta training data: |██████████|100%\n",
      "Training final base predictors: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on Modality_1...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating meta training data: |██████████|100%\n",
      "Generating meta test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "... for final ensemble...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating meta training data: |██████████|100%\n",
      "Training final base predictors: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on Modality_2...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating meta training data: |██████████|100%\n",
      "Generating meta test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "... for final ensemble...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating meta training data: |██████████|100%\n",
      "Training final base predictors: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing ensembles: |██████████|100%\n",
      "Training final meta models: |██████████|100%\n"
     ]
    }
   ],
   "source": [
    "class_EIs=[]\n",
    "for c in range(n_classes):\n",
    "    y_train_c = [1*(label==c)+0*(label != c) for label in y_train]\n",
    "    EI = EnsembleIntegration(\n",
    "                        base_predictors=base_predictors,\n",
    "                        k_outer=5,\n",
    "                        k_inner=5,\n",
    "                        n_samples=1,\n",
    "                        sampling_strategy=\"undersampling\",\n",
    "                        sampling_aggregation=\"mean\",\n",
    "                        n_jobs=-1,\n",
    "                        random_state=38,\n",
    "                        project_name=\"toy\",\n",
    "                        model_building=True,\n",
    "                        )\n",
    "    for name, modality in data_train.items():\n",
    "        EI.train_base(modality, y_train_c, modality_name=name)\n",
    "    EI.train_meta(meta_predictors=meta_predictors)\n",
    "    class_EIs.append(EI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>CES</th>\n",
       "      <th>S.ADAB</th>\n",
       "      <th>S.XGB</th>\n",
       "      <th>S.DT</th>\n",
       "      <th>S.RF</th>\n",
       "      <th>S.GB</th>\n",
       "      <th>S.KNN</th>\n",
       "      <th>S.LR</th>\n",
       "      <th>S.NB</th>\n",
       "      <th>S.MLP</th>\n",
       "      <th>S.SVM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fmax (minority)</th>\n",
       "      <td>0.970711</td>\n",
       "      <td>0.985386</td>\n",
       "      <td>0.989562</td>\n",
       "      <td>0.993763</td>\n",
       "      <td>0.987448</td>\n",
       "      <td>0.995816</td>\n",
       "      <td>0.995851</td>\n",
       "      <td>0.995816</td>\n",
       "      <td>0.987654</td>\n",
       "      <td>0.995816</td>\n",
       "      <td>0.993711</td>\n",
       "      <td>0.993711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f (majority)</th>\n",
       "      <td>0.985447</td>\n",
       "      <td>0.992716</td>\n",
       "      <td>0.994797</td>\n",
       "      <td>0.996872</td>\n",
       "      <td>0.993763</td>\n",
       "      <td>0.997921</td>\n",
       "      <td>0.997912</td>\n",
       "      <td>0.997921</td>\n",
       "      <td>0.993711</td>\n",
       "      <td>0.997921</td>\n",
       "      <td>0.996885</td>\n",
       "      <td>0.996885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>0.996467</td>\n",
       "      <td>0.998429</td>\n",
       "      <td>0.995313</td>\n",
       "      <td>0.999931</td>\n",
       "      <td>0.989583</td>\n",
       "      <td>0.999939</td>\n",
       "      <td>0.999970</td>\n",
       "      <td>0.997865</td>\n",
       "      <td>0.999696</td>\n",
       "      <td>0.999913</td>\n",
       "      <td>0.999870</td>\n",
       "      <td>0.999913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max MCC</th>\n",
       "      <td>0.956177</td>\n",
       "      <td>0.971848</td>\n",
       "      <td>0.984364</td>\n",
       "      <td>0.990640</td>\n",
       "      <td>0.981230</td>\n",
       "      <td>0.993756</td>\n",
       "      <td>0.993782</td>\n",
       "      <td>0.993756</td>\n",
       "      <td>0.981537</td>\n",
       "      <td>0.993756</td>\n",
       "      <td>0.990639</td>\n",
       "      <td>0.990639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Mean       CES    S.ADAB     S.XGB      S.DT      S.RF  \\\n",
       "fmax (minority)  0.970711  0.985386  0.989562  0.993763  0.987448  0.995816   \n",
       "f (majority)     0.985447  0.992716  0.994797  0.996872  0.993763  0.997921   \n",
       "AUC              0.996467  0.998429  0.995313  0.999931  0.989583  0.999939   \n",
       "max MCC          0.956177  0.971848  0.984364  0.990640  0.981230  0.993756   \n",
       "\n",
       "                     S.GB     S.KNN      S.LR      S.NB     S.MLP     S.SVM  \n",
       "fmax (minority)  0.995851  0.995816  0.987654  0.995816  0.993711  0.993711  \n",
       "f (majority)     0.997912  0.997921  0.993711  0.997921  0.996885  0.996885  \n",
       "AUC              0.999970  0.997865  0.999696  0.999913  0.999870  0.999913  \n",
       "max MCC          0.993782  0.993756  0.981537  0.993756  0.990639  0.990639  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_EIs[0].meta_summary[\"metrics\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = []\n",
    "thresholds = []\n",
    "\n",
    "# connfidence relative to threshold weighed by threshold. This is basically the only decision in the whole implementation.\n",
    "def confidence(prediction, thresh):\n",
    "    if prediction-threshold >= 0:\n",
    "        return (prediction-thresh)*thresh\n",
    "    else:\n",
    "        return (prediction-thresh)*(1-thresh)\n",
    "\n",
    "# unweighted distance from threshold. performs worse on toy data.\n",
    "def alt_confidence(prediction, thresh):\n",
    "    return prediction-thresh\n",
    "               \n",
    "\n",
    "for c in range(n_classes):\n",
    "    metrics = class_EIs[c].meta_summary[\"metrics\"]\n",
    "    class_preferred_model = metrics.loc[\"fmax (minority)\"].idxmax()\n",
    "    \n",
    "    y_pred = class_EIs[c].predict(X_dict=data_test, meta_model_key=class_preferred_model)\n",
    "    \n",
    "    threshold = class_EIs[c].meta_summary['thresholds'][class_preferred_model]['fmax (minority)']\n",
    "\n",
    "    y_pred = [confidence(pred, threshold) for pred in y_pred]\n",
    "    \n",
    "    y_preds.append(y_pred)\n",
    "\n",
    "y_preds = np.array(y_preds)\n",
    "\n",
    "final_pred = []\n",
    "for k in range(len(y_preds[0])):\n",
    "    most_confident_class = np.argmax(y_preds[:, k])\n",
    "    \n",
    "    final_pred.append(most_confident_class)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 2, 0, 0, 2, 1, 2, 0, 2, 1, 1, 2, 1, 0, 1, 1, 2, 1, 1, 0, 0,\n",
       "       2, 0, 1, 1, 1, 2, 2, 0, 2, 2, 0, 2, 0, 0, 2, 1, 0, 1, 0, 0, 2, 1,\n",
       "       1, 2, 1, 0, 2, 2, 1, 1, 0, 0, 1, 1, 1, 1, 2, 2, 1, 0, 0, 2, 0, 2,\n",
       "       0, 1, 0, 1, 1, 2, 2, 0, 1, 2, 1, 1, 2, 0, 0, 0, 2, 1, 0, 0, 1, 1,\n",
       "       2, 0, 0, 2, 0, 0, 0, 1, 1, 2, 2, 1, 1, 2, 1, 1, 2, 2, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 1, 2, 2, 1, 1, 0, 0, 0, 2, 0, 1, 1, 2, 2,\n",
       "       2, 2, 2, 0, 2, 0, 1, 1, 2, 0, 1, 0, 2, 2, 2, 2, 1, 0, 0, 2, 1, 1,\n",
       "       2, 1, 1, 2, 0, 2, 0, 1, 0, 0, 2, 2, 0, 2, 2, 2, 0, 0, 0, 2, 1, 2,\n",
       "       1, 2, 0, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = sum([1*(y==y_hat)+0*(y!=y_hat) for y,y_hat in list(zip(y_test, final_pred))])/len(y_test)\n",
    "accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
