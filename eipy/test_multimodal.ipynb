{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import eipy.ei as e\n",
    "from importlib import reload\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import KNNImputer\n",
    "import pickle as pkl\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import pandas as pd\n",
    "from eipy.additional_ensembles import MeanAggregation, CES\n",
    "from eipy.metrics import fmax_score\n",
    "from sklearn.metrics import roc_auc_score, matthews_corrcoef\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Input, Concatenate\n",
    "import seaborn as sns\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"/home/opc/block_vol/COVID-19 data\"\n",
    "data={}\n",
    "for file_name in os.listdir(directory):\n",
    "    if file_name.endswith('.csv') and not file_name.startswith('xgboost'):\n",
    "        key = file_name.split('.')[0]\n",
    "        file_path = os.path.join(directory, file_name)\n",
    "        df = pd.read_csv(file_path)\n",
    "        df = df.drop(columns=[\"NEW_MASKED_MRN\"])\n",
    "        imputer = KNNImputer(n_neighbors=5)\n",
    "        df = imputer.fit_transform(df)\n",
    "        data[key] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DECEASED_INDICATOR\n",
       "0    3460\n",
       "1    1323\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.read_csv('/home/opc/block_vol/COVID-19 data/Basics/outcome.csv')\n",
    "labels = labels[\"DECEASED_INDICATOR\"]\n",
    "labels.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dl bps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_deep_bps(input_dim):\n",
    "    # Architecture 1: Simple Feedforward Neural Network\n",
    "    model_1 = Sequential()\n",
    "    model_1.add(Dense(64, input_dim=input_dim, activation='relu'))\n",
    "    model_1.add(Dense(32, activation='relu'))\n",
    "    model_1.add(Dense(1, activation='sigmoid'))\n",
    "    model_1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Architecture 2: Deep Feedforward Neural Network with Dropout\n",
    "    model_2 = Sequential()\n",
    "    model_2.add(Dense(128, input_dim=input_dim, activation='relu'))\n",
    "    model_2.add(Dropout(0.5))\n",
    "    model_2.add(Dense(64, activation='relu'))\n",
    "    model_2.add(Dropout(0.3))\n",
    "    model_2.add(Dense(32, activation='relu'))\n",
    "    model_2.add(Dense(1, activation='sigmoid'))\n",
    "    model_2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Architecture 3: Wide and Deep Neural Network\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    wide_branch = Dense(32, activation='relu')(input_layer)\n",
    "    deep_branch = Dense(64, activation='relu')(input_layer)\n",
    "    deep_branch = Dense(32, activation='relu')(deep_branch)\n",
    "    merged = Concatenate()([wide_branch, deep_branch])\n",
    "    output_layer = Dense(1, activation='sigmoid')(merged)\n",
    "    model_3 = Model(inputs=input_layer, outputs=output_layer)\n",
    "    model_3.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Architecture 4: Deep Neural Network without Sequential Structure\n",
    "    model_4 = Sequential()\n",
    "    model_4.add(Dense(128, input_dim=input_dim, activation='relu'))\n",
    "    model_4.add(Dense(64, activation='relu'))\n",
    "    model_4.add(Dense(32, activation='relu'))\n",
    "    model_4.add(Dense(1, activation='sigmoid'))\n",
    "    model_4.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    d_base_predictors = {\"simple\" : model_1,\n",
    "                        \"deep_w_dropout\" : model_2,\n",
    "                        # \"wide_n_deep\" : model_3,\n",
    "                        # \"deeper\" : model_4\n",
    "                         }\n",
    "    return d_base_predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_predictors = {\n",
    "                    'ADAB': AdaBoostClassifier(),\n",
    "                    'XGB': XGBClassifier(),\n",
    "                    # 'DT': DecisionTreeClassifier(),\n",
    "                    # 'RF': RandomForestClassifier(),\n",
    "                    # 'GB': GradientBoostingClassifier(),\n",
    "                    # 'KNN': KNeighborsClassifier(),\n",
    "                    # 'LR': LogisticRegression(),\n",
    "                    # 'NB': GaussianNB(),\n",
    "                    # 'MLP': MLPClassifier(),\n",
    "                    # 'SVM': SVC(probability=True),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_predictors = {\n",
    "                    'Mean' : MeanAggregation(),\n",
    "                    'CES' : CES(scoring=lambda y_test, y_pred: fmax_score(y_test, y_pred)[0]),\n",
    "                    'S.ADAB': AdaBoostClassifier(),\n",
    "                    'S.XGB': XGBClassifier(),\n",
    "                    'S.DT': DecisionTreeClassifier(),\n",
    "                    \"S.RF\": RandomForestClassifier(),\n",
    "                    'S.GB': GradientBoostingClassifier(),\n",
    "                    'S.KNN': KNeighborsClassifier(),\n",
    "                    'S.LR': LogisticRegression(),\n",
    "                    'S.NB': GaussianNB(),\n",
    "                    'S.MLP': MLPClassifier(),\n",
    "                    'S.SVM': SVC(probability=True),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\n",
    "            'f_max': fmax_score,\n",
    "            'auc': roc_auc_score,\n",
    "            'mcc': matthews_corrcoef\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'eipy.ei' from '/home/opc/eipy/eipy/ei.py'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####HI OVER HERE###\n",
    "reload(e)\n",
    "###HEYOOOOOO#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performance = {k:([],[]) for k in data.keys()}\n",
    "# performance[\"EI\"] = ([],[])\n",
    "# for i in range(10):\n",
    "#     random_seed= i\n",
    "#     X_train = {}\n",
    "#     X_test = {}\n",
    "#     for k, v in data.items():\n",
    "#         X_train[k], X_test[k], y_train, y_test = train_test_split(v, labels, test_size=0.2, stratify=labels, random_state=i)\n",
    "#     for k in data.keys():\n",
    "#         EI = e.EnsembleIntegration(\n",
    "#                     k_outer=5,\n",
    "#                     k_inner=5,\n",
    "#                     n_samples=1,\n",
    "#                     sampling_strategy=\"undersampling\",\n",
    "#                     sampling_aggregation=None,\n",
    "#                     n_jobs=-1,\n",
    "#                     metrics=metrics,\n",
    "#                     random_state=i+1,\n",
    "#                     project_name=\"diabetes\",\n",
    "#                     model_building=True,\n",
    "#                     )\n",
    "#         if k == 'labs':\n",
    "#             EI.fit_base(X_train[k], y_train, modality_name=k, base_predictors=d_base_predictors)\n",
    "#         else:\n",
    "#             EI.fit_base(X_train[k], y_train, modality_name=k, base_predictors=base_predictors)\n",
    "        \n",
    "#         EI.fit_ensemble(ensemble_predictors=ensemble_predictors)\n",
    "        \n",
    "#         preferred_ensemble_fmax = EI.ensemble_summary[\"metrics\"].loc[\"f_max\"].idxmax()\n",
    "#         y_pred_fmax = EI.predict(X_dict={k:X_test[k]}, ensemble_model_key=preferred_ensemble_fmax)\n",
    "#         performance[k][0].append(fmax_score(y_test=y_test, y_score=y_pred_fmax))\n",
    "#         preferred_ensemble_auc = EI.ensemble_summary[\"metrics\"].loc[\"auc\"].idxmax()\n",
    "#         y_pred_auc = EI.predict(X_dict={k:X_test[k]}, ensemble_model_key=preferred_ensemble_auc)\n",
    "#         performance[k][1].append(roc_auc_score(y_true=y_test, y_score=y_pred_auc))\n",
    "#         print(f\"DONE WITH SEED {i}, MODALITY {k}\")\n",
    "    \n",
    "#     EI = e.EnsembleIntegration(\n",
    "#                     k_outer=5,\n",
    "#                     k_inner=5,\n",
    "#                     n_samples=1,\n",
    "#                     sampling_strategy=\"undersampling\",\n",
    "#                     sampling_aggregation=None,\n",
    "#                     n_jobs=-1,\n",
    "#                     metrics=metrics,\n",
    "#                     random_state=i+1,\n",
    "#                     project_name=\"diabetes\",\n",
    "#                     model_building=True,\n",
    "#                     )\n",
    "#     for k in data.keys():\n",
    "#         if k == 'labs':\n",
    "#             EI.fit_base(X_train[k], y_train, modality_name=k, base_predictors=d_base_predictors)\n",
    "#         else:\n",
    "#             EI.fit_base(X_train[k], y_train, modality_name=k, base_predictors=base_predictors)\n",
    "    \n",
    "#     EI.fit_ensemble(ensemble_predictors=ensemble_predictors)\n",
    "#     preferred_ensemble_fmax = EI.ensemble_summary[\"metrics\"].loc[\"f_max\"].idxmax()\n",
    "#     y_pred_fmax = EI.predict(X_dict=X_test, ensemble_model_key=preferred_ensemble_fmax)\n",
    "#     performance[\"EI\"][0].append(fmax_score(y_test=y_test, y_score=y_pred_fmax))\n",
    "#     preferred_ensemble_auc = EI.ensemble_summary[\"metrics\"].loc[\"auc\"].idxmax()\n",
    "#     y_pred_auc = EI.predict(X_dict=X_test, ensemble_model_key=preferred_ensemble_auc)\n",
    "#     performance[\"EI\"][1].append(roc_auc_score(y_true=y_test, y_score=y_pred_auc))\n",
    "#     print(f\"DONE WITH SEED {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training base predictors on labs...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |          |  0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "383/383 [==============================] - 1s 914us/step - loss: 9.6049 - accuracy: 0.5957\n",
      "Epoch 2/10\n",
      "383/383 [==============================] - 0s 878us/step - loss: 6.0945 - accuracy: 0.6244\n",
      "Epoch 3/10\n",
      "383/383 [==============================] - 0s 890us/step - loss: 5.3148 - accuracy: 0.6260\n",
      "Epoch 4/10\n",
      "383/383 [==============================] - 0s 883us/step - loss: 3.3104 - accuracy: 0.6370\n",
      "Epoch 5/10\n",
      "383/383 [==============================] - 0s 881us/step - loss: 2.9215 - accuracy: 0.6479\n",
      "Epoch 6/10\n",
      "383/383 [==============================] - 0s 881us/step - loss: 3.0597 - accuracy: 0.6260\n",
      "Epoch 7/10\n",
      "383/383 [==============================] - 0s 885us/step - loss: 2.7319 - accuracy: 0.6500\n",
      "Epoch 8/10\n",
      "383/383 [==============================] - 0s 877us/step - loss: 3.0332 - accuracy: 0.6383\n",
      "Epoch 9/10\n",
      "383/383 [==============================] - 0s 878us/step - loss: 2.0731 - accuracy: 0.6573\n",
      "Epoch 10/10\n",
      "383/383 [==============================] - 0s 862us/step - loss: 1.8129 - accuracy: 0.6581\n",
      "30/30 [==============================] - 0s 661us/step\n",
      "120/120 [==============================] - 0s 629us/step\n",
      "Epoch 1/10\n",
      "383/383 [==============================] - 0s 845us/step - loss: 11.8224 - accuracy: 0.5930\n",
      "Epoch 2/10\n",
      "383/383 [==============================] - 0s 843us/step - loss: 4.2685 - accuracy: 0.6025\n",
      "Epoch 3/10\n",
      "383/383 [==============================] - 0s 843us/step - loss: 3.0876 - accuracy: 0.6268\n",
      "Epoch 4/10\n",
      "383/383 [==============================] - 0s 852us/step - loss: 2.1134 - accuracy: 0.6385\n",
      "Epoch 5/10\n",
      "383/383 [==============================] - 0s 843us/step - loss: 1.7337 - accuracy: 0.6328\n",
      "Epoch 6/10\n",
      "383/383 [==============================] - 0s 848us/step - loss: 1.1820 - accuracy: 0.6511\n",
      "Epoch 7/10\n",
      "383/383 [==============================] - 0s 856us/step - loss: 1.1610 - accuracy: 0.6597\n",
      "Epoch 8/10\n",
      "383/383 [==============================] - 0s 849us/step - loss: 1.0072 - accuracy: 0.6563\n",
      "Epoch 9/10\n",
      "383/383 [==============================] - 0s 846us/step - loss: 1.0164 - accuracy: 0.6613\n",
      "Epoch 10/10\n",
      "383/383 [==============================] - 0s 859us/step - loss: 0.9322 - accuracy: 0.6602\n",
      "30/30 [==============================] - 0s 651us/step\n",
      "120/120 [==============================] - 0s 636us/step\n",
      "Epoch 1/10\n",
      "383/383 [==============================] - 0s 869us/step - loss: 10.1320 - accuracy: 0.5978\n",
      "Epoch 2/10\n",
      "383/383 [==============================] - 0s 888us/step - loss: 3.5876 - accuracy: 0.6163\n",
      "Epoch 3/10\n",
      "383/383 [==============================] - 0s 885us/step - loss: 3.3625 - accuracy: 0.6330\n",
      "Epoch 4/10\n",
      "383/383 [==============================] - 0s 882us/step - loss: 2.4250 - accuracy: 0.6273\n",
      "Epoch 5/10\n",
      "383/383 [==============================] - 0s 874us/step - loss: 1.7084 - accuracy: 0.6427\n",
      "Epoch 6/10\n",
      "383/383 [==============================] - 0s 863us/step - loss: 1.8523 - accuracy: 0.6432\n",
      "Epoch 7/10\n",
      "383/383 [==============================] - 0s 863us/step - loss: 1.6534 - accuracy: 0.6469\n",
      "Epoch 8/10\n",
      "383/383 [==============================] - 0s 881us/step - loss: 1.3725 - accuracy: 0.6678\n",
      "Epoch 9/10\n",
      "383/383 [==============================] - 0s 875us/step - loss: 1.1946 - accuracy: 0.6513\n",
      "Epoch 10/10\n",
      "383/383 [==============================] - 0s 852us/step - loss: 1.0251 - accuracy: 0.6749\n",
      "30/30 [==============================] - 0s 662us/step\n",
      "120/120 [==============================] - 0s 656us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██        | 20%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "383/383 [==============================] - 0s 860us/step - loss: 9.3496 - accuracy: 0.6072\n",
      "Epoch 2/10\n",
      "383/383 [==============================] - 0s 855us/step - loss: 3.9404 - accuracy: 0.6323\n",
      "Epoch 3/10\n",
      "383/383 [==============================] - 0s 856us/step - loss: 2.1644 - accuracy: 0.6519\n",
      "Epoch 4/10\n",
      "383/383 [==============================] - 0s 855us/step - loss: 2.3195 - accuracy: 0.6380\n",
      "Epoch 5/10\n",
      "383/383 [==============================] - 0s 857us/step - loss: 2.1711 - accuracy: 0.6485\n",
      "Epoch 6/10\n",
      "383/383 [==============================] - 0s 852us/step - loss: 1.3670 - accuracy: 0.6571\n",
      "Epoch 7/10\n",
      "383/383 [==============================] - 0s 843us/step - loss: 1.0437 - accuracy: 0.6681\n",
      "Epoch 8/10\n",
      "383/383 [==============================] - 0s 839us/step - loss: 1.0780 - accuracy: 0.6694\n",
      "Epoch 9/10\n",
      "383/383 [==============================] - 0s 836us/step - loss: 0.9829 - accuracy: 0.6733\n",
      "Epoch 10/10\n",
      "383/383 [==============================] - 0s 845us/step - loss: 0.6673 - accuracy: 0.6981\n",
      "30/30 [==============================] - 0s 675us/step\n",
      "120/120 [==============================] - 0s 644us/step\n",
      "Epoch 1/10\n",
      "383/383 [==============================] - 0s 881us/step - loss: 9.5089 - accuracy: 0.6176\n",
      "Epoch 2/10\n",
      "383/383 [==============================] - 0s 858us/step - loss: 3.4775 - accuracy: 0.6304\n",
      "Epoch 3/10\n",
      "383/383 [==============================] - 0s 865us/step - loss: 2.0355 - accuracy: 0.6404\n",
      "Epoch 4/10\n",
      "383/383 [==============================] - 0s 868us/step - loss: 1.8600 - accuracy: 0.6605\n",
      "Epoch 5/10\n",
      "383/383 [==============================] - 0s 864us/step - loss: 2.1201 - accuracy: 0.6411\n",
      "Epoch 6/10\n",
      "383/383 [==============================] - 0s 866us/step - loss: 1.6497 - accuracy: 0.6479\n",
      "Epoch 7/10\n",
      "383/383 [==============================] - 0s 856us/step - loss: 1.4381 - accuracy: 0.6466\n",
      "Epoch 8/10\n",
      "383/383 [==============================] - 0s 869us/step - loss: 1.2256 - accuracy: 0.6631\n",
      "Epoch 9/10\n",
      "383/383 [==============================] - 0s 869us/step - loss: 1.6600 - accuracy: 0.6513\n",
      "Epoch 10/10\n",
      "383/383 [==============================] - 0s 868us/step - loss: 1.2289 - accuracy: 0.6461\n",
      "30/30 [==============================] - 0s 669us/step\n",
      "120/120 [==============================] - 0s 614us/step\n",
      "Epoch 1/10\n",
      "383/383 [==============================] - 0s 858us/step - loss: 9.9225 - accuracy: 0.5776\n",
      "Epoch 2/10\n",
      "383/383 [==============================] - 0s 840us/step - loss: 4.1864 - accuracy: 0.6189\n",
      "Epoch 3/10\n",
      "383/383 [==============================] - 0s 880us/step - loss: 2.7400 - accuracy: 0.6210\n",
      "Epoch 4/10\n",
      "383/383 [==============================] - 0s 836us/step - loss: 2.2549 - accuracy: 0.6417\n",
      "Epoch 5/10\n",
      "383/383 [==============================] - 0s 853us/step - loss: 2.0627 - accuracy: 0.6461\n",
      "Epoch 6/10\n",
      "383/383 [==============================] - 0s 841us/step - loss: 1.8794 - accuracy: 0.6503\n",
      "Epoch 7/10\n",
      "383/383 [==============================] - 0s 844us/step - loss: 1.8561 - accuracy: 0.6579\n",
      "Epoch 8/10\n",
      "383/383 [==============================] - 0s 839us/step - loss: 1.3875 - accuracy: 0.6555\n",
      "Epoch 9/10\n",
      "383/383 [==============================] - 0s 835us/step - loss: 1.5226 - accuracy: 0.6516\n",
      "Epoch 10/10\n",
      "383/383 [==============================] - 0s 834us/step - loss: 1.2907 - accuracy: 0.6636\n",
      "30/30 [==============================] - 0s 646us/step\n",
      "120/120 [==============================] - 0s 622us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |████      | 40%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "383/383 [==============================] - 0s 866us/step - loss: 9.8680 - accuracy: 0.5896\n",
      "Epoch 2/10\n",
      "383/383 [==============================] - 0s 896us/step - loss: 2.8645 - accuracy: 0.6228\n",
      "Epoch 3/10\n",
      "383/383 [==============================] - 0s 836us/step - loss: 2.2172 - accuracy: 0.6262\n",
      "Epoch 4/10\n",
      "383/383 [==============================] - 0s 845us/step - loss: 3.0275 - accuracy: 0.6163\n",
      "Epoch 5/10\n",
      "383/383 [==============================] - 0s 850us/step - loss: 1.6383 - accuracy: 0.6417\n",
      "Epoch 6/10\n",
      "383/383 [==============================] - 0s 851us/step - loss: 1.7942 - accuracy: 0.6396\n",
      "Epoch 7/10\n",
      "383/383 [==============================] - 0s 854us/step - loss: 1.2102 - accuracy: 0.6568\n",
      "Epoch 8/10\n",
      "383/383 [==============================] - 0s 854us/step - loss: 1.7190 - accuracy: 0.6526\n",
      "Epoch 9/10\n",
      "383/383 [==============================] - 0s 854us/step - loss: 1.2746 - accuracy: 0.6445\n",
      "Epoch 10/10\n",
      "383/383 [==============================] - 0s 856us/step - loss: 1.4214 - accuracy: 0.6513\n",
      "30/30 [==============================] - 0s 637us/step\n",
      "120/120 [==============================] - 0s 601us/step\n",
      "Epoch 1/10\n",
      "383/383 [==============================] - 0s 856us/step - loss: 9.4730 - accuracy: 0.5941\n",
      "Epoch 2/10\n",
      "383/383 [==============================] - 0s 828us/step - loss: 3.2830 - accuracy: 0.6304\n",
      "Epoch 3/10\n",
      "383/383 [==============================] - 0s 861us/step - loss: 3.1191 - accuracy: 0.6100\n",
      "Epoch 4/10\n",
      "383/383 [==============================] - 0s 900us/step - loss: 2.2647 - accuracy: 0.6333\n",
      "Epoch 5/10\n",
      "383/383 [==============================] - 0s 852us/step - loss: 2.3598 - accuracy: 0.6289\n",
      "Epoch 6/10\n",
      "383/383 [==============================] - 0s 831us/step - loss: 1.5056 - accuracy: 0.6542\n",
      "Epoch 7/10\n",
      "383/383 [==============================] - 0s 834us/step - loss: 1.3923 - accuracy: 0.6657\n",
      "Epoch 8/10\n",
      "383/383 [==============================] - 0s 839us/step - loss: 1.9040 - accuracy: 0.6435\n",
      "Epoch 9/10\n",
      "383/383 [==============================] - 0s 852us/step - loss: 1.5412 - accuracy: 0.6532\n",
      "Epoch 10/10\n",
      "383/383 [==============================] - 0s 846us/step - loss: 1.0533 - accuracy: 0.6448\n",
      "30/30 [==============================] - 0s 650us/step\n",
      "120/120 [==============================] - 0s 630us/step\n",
      "Epoch 1/10\n",
      "383/383 [==============================] - 0s 847us/step - loss: 12.8084 - accuracy: 0.5781\n",
      "Epoch 2/10\n",
      "383/383 [==============================] - 0s 852us/step - loss: 3.8399 - accuracy: 0.6145\n",
      "Epoch 3/10\n",
      "383/383 [==============================] - 0s 852us/step - loss: 2.9142 - accuracy: 0.6197\n",
      "Epoch 4/10\n",
      "383/383 [==============================] - 0s 854us/step - loss: 2.2258 - accuracy: 0.6364\n",
      "Epoch 5/10\n",
      "383/383 [==============================] - 0s 867us/step - loss: 1.9198 - accuracy: 0.6440\n",
      "Epoch 6/10\n",
      "383/383 [==============================] - 0s 860us/step - loss: 2.0169 - accuracy: 0.6325\n",
      "Epoch 7/10\n",
      "383/383 [==============================] - 0s 860us/step - loss: 1.3935 - accuracy: 0.6479\n",
      "Epoch 8/10\n",
      "383/383 [==============================] - 0s 852us/step - loss: 1.3323 - accuracy: 0.6550\n",
      "Epoch 9/10\n",
      "383/383 [==============================] - 0s 837us/step - loss: 1.7502 - accuracy: 0.6495\n",
      "Epoch 10/10\n",
      "383/383 [==============================] - 0s 849us/step - loss: 1.1926 - accuracy: 0.6498\n",
      "30/30 [==============================] - 0s 648us/step\n",
      "120/120 [==============================] - 0s 621us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████    | 60%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "383/383 [==============================] - 0s 854us/step - loss: 9.8449 - accuracy: 0.6017\n",
      "Epoch 2/10\n",
      "383/383 [==============================] - 0s 841us/step - loss: 2.7781 - accuracy: 0.6411\n",
      "Epoch 3/10\n",
      "383/383 [==============================] - 0s 829us/step - loss: 2.8557 - accuracy: 0.6299\n",
      "Epoch 4/10\n",
      "383/383 [==============================] - 0s 840us/step - loss: 2.3182 - accuracy: 0.6451\n",
      "Epoch 5/10\n",
      "383/383 [==============================] - 0s 834us/step - loss: 1.9778 - accuracy: 0.6529\n",
      "Epoch 6/10\n",
      "383/383 [==============================] - 0s 841us/step - loss: 1.6515 - accuracy: 0.6461\n",
      "Epoch 7/10\n",
      "383/383 [==============================] - 0s 849us/step - loss: 2.1806 - accuracy: 0.6519\n",
      "Epoch 8/10\n",
      "383/383 [==============================] - 0s 849us/step - loss: 1.4313 - accuracy: 0.6636\n",
      "Epoch 9/10\n",
      "383/383 [==============================] - 0s 848us/step - loss: 1.9679 - accuracy: 0.6487\n",
      "Epoch 10/10\n",
      "383/383 [==============================] - 0s 848us/step - loss: 1.1650 - accuracy: 0.6730\n",
      "30/30 [==============================] - 0s 645us/step\n",
      "120/120 [==============================] - 0s 636us/step\n",
      "Epoch 1/10\n",
      "383/383 [==============================] - 0s 814us/step - loss: 8.5801 - accuracy: 0.6027\n",
      "Epoch 2/10\n",
      "383/383 [==============================] - 0s 836us/step - loss: 4.5002 - accuracy: 0.6119\n",
      "Epoch 3/10\n",
      "383/383 [==============================] - 0s 814us/step - loss: 2.5268 - accuracy: 0.6414\n",
      "Epoch 4/10\n",
      "383/383 [==============================] - 0s 814us/step - loss: 1.7799 - accuracy: 0.6424\n",
      "Epoch 5/10\n",
      "383/383 [==============================] - 0s 823us/step - loss: 2.4271 - accuracy: 0.6275\n",
      "Epoch 6/10\n",
      "383/383 [==============================] - 0s 817us/step - loss: 1.4999 - accuracy: 0.6451\n",
      "Epoch 7/10\n",
      "383/383 [==============================] - 0s 813us/step - loss: 1.5313 - accuracy: 0.6375\n",
      "Epoch 8/10\n",
      "383/383 [==============================] - 0s 809us/step - loss: 1.0738 - accuracy: 0.6579\n",
      "Epoch 9/10\n",
      "383/383 [==============================] - 0s 805us/step - loss: 0.9795 - accuracy: 0.6634\n",
      "Epoch 10/10\n",
      "383/383 [==============================] - 0s 836us/step - loss: 1.0421 - accuracy: 0.6589\n",
      "30/30 [==============================] - 0s 636us/step\n",
      "120/120 [==============================] - 0s 627us/step\n",
      "Epoch 1/10\n",
      "383/383 [==============================] - 0s 873us/step - loss: 9.7619 - accuracy: 0.6072\n",
      "Epoch 2/10\n",
      "383/383 [==============================] - 0s 860us/step - loss: 3.5164 - accuracy: 0.6294\n",
      "Epoch 3/10\n",
      "383/383 [==============================] - 0s 849us/step - loss: 2.7385 - accuracy: 0.6534\n",
      "Epoch 4/10\n",
      "383/383 [==============================] - 0s 845us/step - loss: 1.9741 - accuracy: 0.6414\n",
      "Epoch 5/10\n",
      "383/383 [==============================] - 0s 874us/step - loss: 1.7939 - accuracy: 0.6500\n",
      "Epoch 6/10\n",
      "383/383 [==============================] - 0s 896us/step - loss: 1.7823 - accuracy: 0.6534\n",
      "Epoch 7/10\n",
      "383/383 [==============================] - 0s 898us/step - loss: 2.0563 - accuracy: 0.6422\n",
      "Epoch 8/10\n",
      "383/383 [==============================] - 0s 878us/step - loss: 1.3195 - accuracy: 0.6576\n",
      "Epoch 9/10\n",
      "383/383 [==============================] - 0s 868us/step - loss: 1.2277 - accuracy: 0.6835\n",
      "Epoch 10/10\n",
      "383/383 [==============================] - 0s 874us/step - loss: 0.9700 - accuracy: 0.6809\n",
      "30/30 [==============================] - 0s 651us/step\n",
      "120/120 [==============================] - 0s 622us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |████████  | 80%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "383/383 [==============================] - 0s 863us/step - loss: 9.9569 - accuracy: 0.5954\n",
      "Epoch 2/10\n",
      "383/383 [==============================] - 0s 861us/step - loss: 3.7840 - accuracy: 0.6168\n",
      "Epoch 3/10\n",
      "383/383 [==============================] - 0s 868us/step - loss: 2.5294 - accuracy: 0.6281\n",
      "Epoch 4/10\n",
      "383/383 [==============================] - 0s 871us/step - loss: 2.6610 - accuracy: 0.6472\n",
      "Epoch 5/10\n",
      "383/383 [==============================] - 0s 864us/step - loss: 1.6586 - accuracy: 0.6641\n",
      "Epoch 6/10\n",
      "383/383 [==============================] - 0s 863us/step - loss: 2.3812 - accuracy: 0.6357\n",
      "Epoch 7/10\n",
      "383/383 [==============================] - 0s 840us/step - loss: 1.5262 - accuracy: 0.6534\n",
      "Epoch 8/10\n",
      "383/383 [==============================] - 0s 841us/step - loss: 1.3476 - accuracy: 0.6712\n",
      "Epoch 9/10\n",
      "383/383 [==============================] - 0s 844us/step - loss: 1.4442 - accuracy: 0.6571\n",
      "Epoch 10/10\n",
      "383/383 [==============================] - 0s 833us/step - loss: 1.4736 - accuracy: 0.6670\n",
      "30/30 [==============================] - 0s 645us/step\n",
      "120/120 [==============================] - 0s 631us/step\n",
      "Epoch 1/10\n",
      "383/383 [==============================] - 0s 824us/step - loss: 8.8628 - accuracy: 0.5745\n",
      "Epoch 2/10\n",
      "383/383 [==============================] - 0s 824us/step - loss: 3.4182 - accuracy: 0.6150\n",
      "Epoch 3/10\n",
      "383/383 [==============================] - 0s 817us/step - loss: 2.3218 - accuracy: 0.6351\n",
      "Epoch 4/10\n",
      "383/383 [==============================] - 0s 816us/step - loss: 1.8210 - accuracy: 0.6537\n",
      "Epoch 5/10\n",
      "383/383 [==============================] - 0s 802us/step - loss: 1.4764 - accuracy: 0.6532\n",
      "Epoch 6/10\n",
      "383/383 [==============================] - 0s 807us/step - loss: 1.3658 - accuracy: 0.6542\n",
      "Epoch 7/10\n",
      "383/383 [==============================] - 0s 809us/step - loss: 1.1726 - accuracy: 0.6707\n",
      "Epoch 8/10\n",
      "383/383 [==============================] - 0s 815us/step - loss: 1.3721 - accuracy: 0.6524\n",
      "Epoch 9/10\n",
      "383/383 [==============================] - 0s 820us/step - loss: 1.0850 - accuracy: 0.6618\n",
      "Epoch 10/10\n",
      "383/383 [==============================] - 0s 835us/step - loss: 1.0074 - accuracy: 0.6780\n",
      "30/30 [==============================] - 0s 680us/step\n",
      "120/120 [==============================] - 0s 644us/step\n",
      "Epoch 1/10\n",
      "383/383 [==============================] - 0s 830us/step - loss: 8.5879 - accuracy: 0.5792\n",
      "Epoch 2/10\n",
      "383/383 [==============================] - 0s 825us/step - loss: 3.0266 - accuracy: 0.6325\n",
      "Epoch 3/10\n",
      "383/383 [==============================] - 0s 816us/step - loss: 2.6853 - accuracy: 0.6281\n",
      "Epoch 4/10\n",
      "383/383 [==============================] - 0s 819us/step - loss: 1.4428 - accuracy: 0.6550\n",
      "Epoch 5/10\n",
      "383/383 [==============================] - 0s 813us/step - loss: 1.7283 - accuracy: 0.6424\n",
      "Epoch 6/10\n",
      "383/383 [==============================] - 0s 834us/step - loss: 1.2792 - accuracy: 0.6464\n",
      "Epoch 7/10\n",
      "383/383 [==============================] - 0s 836us/step - loss: 0.7409 - accuracy: 0.6735\n",
      "Epoch 8/10\n",
      "383/383 [==============================] - 0s 829us/step - loss: 0.7176 - accuracy: 0.6788\n",
      "Epoch 9/10\n",
      "383/383 [==============================] - 0s 833us/step - loss: 0.6843 - accuracy: 0.6848\n",
      "Epoch 10/10\n",
      "383/383 [==============================] - 0s 827us/step - loss: 0.7646 - accuracy: 0.6688\n",
      "30/30 [==============================] - 0s 663us/step\n",
      "120/120 [==============================] - 0s 637us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble training data: |          |  0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "383/383 [==============================] - 1s 1ms/step - loss: 14.4411 - accuracy: 0.5081\n",
      "Epoch 2/10\n",
      "383/383 [==============================] - 0s 949us/step - loss: 2.5788 - accuracy: 0.5204\n",
      "Epoch 3/10\n",
      "383/383 [==============================] - 0s 959us/step - loss: 1.3175 - accuracy: 0.5251\n",
      "Epoch 4/10\n",
      "383/383 [==============================] - 0s 947us/step - loss: 1.0256 - accuracy: 0.5199\n",
      "Epoch 5/10\n",
      "383/383 [==============================] - 0s 958us/step - loss: 0.7748 - accuracy: 0.5408\n",
      "Epoch 6/10\n",
      "383/383 [==============================] - 0s 976us/step - loss: 0.8366 - accuracy: 0.5175\n",
      "Epoch 7/10\n",
      "383/383 [==============================] - 0s 965us/step - loss: 0.7340 - accuracy: 0.5120\n",
      "Epoch 8/10\n",
      "383/383 [==============================] - 0s 937us/step - loss: 0.7066 - accuracy: 0.5227\n",
      "Epoch 9/10\n",
      "383/383 [==============================] - 0s 938us/step - loss: 0.7074 - accuracy: 0.5251\n",
      "Epoch 10/10\n",
      "383/383 [==============================] - 0s 949us/step - loss: 0.6953 - accuracy: 0.5374\n",
      "30/30 [==============================] - 0s 681us/step\n",
      "120/120 [==============================] - 0s 662us/step\n",
      "Epoch 1/10\n",
      "383/383 [==============================] - 0s 960us/step - loss: 5.7072 - accuracy: 0.4995\n",
      "Epoch 2/10\n",
      "383/383 [==============================] - 0s 963us/step - loss: 0.8554 - accuracy: 0.5173\n",
      "Epoch 3/10\n",
      "383/383 [==============================] - 0s 988us/step - loss: 0.7704 - accuracy: 0.4961\n",
      "Epoch 4/10\n",
      "383/383 [==============================] - 0s 962us/step - loss: 0.7408 - accuracy: 0.4987\n",
      "Epoch 5/10\n",
      "383/383 [==============================] - 0s 943us/step - loss: 0.7076 - accuracy: 0.5013\n",
      "Epoch 6/10\n",
      "383/383 [==============================] - 0s 943us/step - loss: 0.7237 - accuracy: 0.4982\n",
      "Epoch 7/10\n",
      "383/383 [==============================] - 0s 944us/step - loss: 0.7178 - accuracy: 0.4971\n",
      "Epoch 8/10\n",
      "383/383 [==============================] - 0s 931us/step - loss: 0.7036 - accuracy: 0.5068\n",
      "Epoch 9/10\n",
      "383/383 [==============================] - 0s 938us/step - loss: 0.7143 - accuracy: 0.5047\n",
      "Epoch 10/10\n",
      "383/383 [==============================] - 0s 936us/step - loss: 0.7149 - accuracy: 0.4956\n",
      "30/30 [==============================] - 0s 649us/step\n",
      "120/120 [==============================] - 0s 620us/step\n",
      "Epoch 1/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 4.9791 - accuracy: 0.5120\n",
      "Epoch 2/10\n",
      "383/383 [==============================] - 0s 980us/step - loss: 0.8484 - accuracy: 0.5107\n",
      "Epoch 3/10\n",
      "383/383 [==============================] - 0s 980us/step - loss: 0.7421 - accuracy: 0.5149\n",
      "Epoch 4/10\n",
      "383/383 [==============================] - 0s 971us/step - loss: 0.7105 - accuracy: 0.5214\n",
      "Epoch 5/10\n",
      "383/383 [==============================] - 0s 983us/step - loss: 0.7273 - accuracy: 0.5183\n",
      "Epoch 6/10\n",
      "383/383 [==============================] - 0s 979us/step - loss: 0.7107 - accuracy: 0.5034\n",
      "Epoch 7/10\n",
      "383/383 [==============================] - 0s 961us/step - loss: 0.7394 - accuracy: 0.5013\n",
      "Epoch 8/10\n",
      "383/383 [==============================] - 0s 961us/step - loss: 0.7207 - accuracy: 0.5044\n",
      "Epoch 9/10\n",
      "383/383 [==============================] - 0s 953us/step - loss: 0.6998 - accuracy: 0.5050\n",
      "Epoch 10/10\n",
      "383/383 [==============================] - 0s 957us/step - loss: 0.7122 - accuracy: 0.5055\n",
      "30/30 [==============================] - 0s 662us/step\n",
      "120/120 [==============================] - 0s 647us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██        | 20%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "383/383 [==============================] - 0s 952us/step - loss: 4.2608 - accuracy: 0.5201\n",
      "Epoch 2/10\n",
      "383/383 [==============================] - 0s 939us/step - loss: 0.7644 - accuracy: 0.5193\n",
      "Epoch 3/10\n",
      "383/383 [==============================] - 0s 953us/step - loss: 0.7439 - accuracy: 0.5084\n",
      "Epoch 4/10\n",
      "383/383 [==============================] - 0s 964us/step - loss: 0.7098 - accuracy: 0.5178\n",
      "Epoch 5/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.6958 - accuracy: 0.5068\n",
      "Epoch 6/10\n",
      "383/383 [==============================] - 0s 961us/step - loss: 0.6921 - accuracy: 0.5439\n",
      "Epoch 7/10\n",
      "383/383 [==============================] - 0s 957us/step - loss: 0.6954 - accuracy: 0.5656\n",
      "Epoch 8/10\n",
      "383/383 [==============================] - 0s 952us/step - loss: 0.6911 - accuracy: 0.5664\n",
      "Epoch 9/10\n",
      "383/383 [==============================] - 0s 954us/step - loss: 0.6736 - accuracy: 0.5891\n",
      "Epoch 10/10\n",
      "383/383 [==============================] - 0s 972us/step - loss: 0.6659 - accuracy: 0.6119\n",
      "30/30 [==============================] - 0s 672us/step\n",
      "120/120 [==============================] - 0s 660us/step\n",
      "Epoch 1/10\n",
      "383/383 [==============================] - 0s 988us/step - loss: 4.6711 - accuracy: 0.5081\n",
      "Epoch 2/10\n",
      "383/383 [==============================] - 0s 984us/step - loss: 0.8863 - accuracy: 0.5170\n",
      "Epoch 3/10\n",
      "383/383 [==============================] - 0s 973us/step - loss: 0.7522 - accuracy: 0.5298\n",
      "Epoch 4/10\n",
      "383/383 [==============================] - 0s 989us/step - loss: 0.7013 - accuracy: 0.5173\n",
      "Epoch 5/10\n",
      "383/383 [==============================] - 0s 995us/step - loss: 0.7023 - accuracy: 0.5222\n",
      "Epoch 6/10\n",
      "383/383 [==============================] - 0s 983us/step - loss: 0.7292 - accuracy: 0.5196\n",
      "Epoch 7/10\n",
      "383/383 [==============================] - 0s 987us/step - loss: 0.7065 - accuracy: 0.5204\n",
      "Epoch 8/10\n",
      "383/383 [==============================] - 0s 974us/step - loss: 0.6938 - accuracy: 0.5188\n",
      "Epoch 9/10\n",
      "383/383 [==============================] - 0s 981us/step - loss: 0.7168 - accuracy: 0.5303\n",
      "Epoch 10/10\n",
      "383/383 [==============================] - 0s 974us/step - loss: 0.6943 - accuracy: 0.5423\n",
      "30/30 [==============================] - 0s 663us/step\n",
      "120/120 [==============================] - 0s 653us/step\n",
      "Epoch 1/10\n",
      "383/383 [==============================] - 0s 968us/step - loss: 3.9755 - accuracy: 0.5139\n",
      "Epoch 2/10\n",
      "383/383 [==============================] - 0s 995us/step - loss: 0.7860 - accuracy: 0.4995\n",
      "Epoch 3/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.7667 - accuracy: 0.5005\n",
      "Epoch 4/10\n",
      "383/383 [==============================] - 0s 964us/step - loss: 0.7209 - accuracy: 0.5037\n",
      "Epoch 5/10\n",
      "383/383 [==============================] - 0s 974us/step - loss: 0.7348 - accuracy: 0.5060\n",
      "Epoch 6/10\n",
      "383/383 [==============================] - 0s 963us/step - loss: 0.6932 - accuracy: 0.5233\n",
      "Epoch 7/10\n",
      "383/383 [==============================] - 0s 982us/step - loss: 0.6960 - accuracy: 0.5120\n",
      "Epoch 8/10\n",
      "383/383 [==============================] - 0s 993us/step - loss: 0.7074 - accuracy: 0.5609\n",
      "Epoch 9/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.7001 - accuracy: 0.5889\n",
      "Epoch 10/10\n",
      "383/383 [==============================] - 0s 994us/step - loss: 0.6734 - accuracy: 0.6137\n",
      "30/30 [==============================] - 0s 673us/step\n",
      "120/120 [==============================] - 0s 652us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |████      | 40%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "383/383 [==============================] - 0s 965us/step - loss: 6.6026 - accuracy: 0.5204\n",
      "Epoch 2/10\n",
      "383/383 [==============================] - 0s 965us/step - loss: 1.0130 - accuracy: 0.5267\n",
      "Epoch 3/10\n",
      "383/383 [==============================] - 0s 969us/step - loss: 0.7801 - accuracy: 0.5178\n",
      "Epoch 4/10\n",
      "383/383 [==============================] - 0s 965us/step - loss: 0.7707 - accuracy: 0.5110\n",
      "Epoch 5/10\n",
      "383/383 [==============================] - 0s 966us/step - loss: 0.7291 - accuracy: 0.5076\n",
      "Epoch 6/10\n",
      "383/383 [==============================] - 0s 981us/step - loss: 0.7283 - accuracy: 0.5065\n",
      "Epoch 7/10\n",
      "383/383 [==============================] - 0s 954us/step - loss: 0.7352 - accuracy: 0.5000\n",
      "Epoch 8/10\n",
      "383/383 [==============================] - 0s 959us/step - loss: 0.7023 - accuracy: 0.5112\n",
      "Epoch 9/10\n",
      "383/383 [==============================] - 0s 967us/step - loss: 0.7149 - accuracy: 0.5186\n",
      "Epoch 10/10\n",
      "383/383 [==============================] - 0s 968us/step - loss: 0.6939 - accuracy: 0.5146\n",
      "30/30 [==============================] - 0s 668us/step\n",
      "120/120 [==============================] - 0s 645us/step\n",
      "Epoch 1/10\n",
      "383/383 [==============================] - 0s 963us/step - loss: 5.2246 - accuracy: 0.5222\n",
      "Epoch 2/10\n",
      "383/383 [==============================] - 0s 962us/step - loss: 0.8337 - accuracy: 0.5170\n",
      "Epoch 3/10\n",
      "383/383 [==============================] - 0s 966us/step - loss: 0.7906 - accuracy: 0.5342\n",
      "Epoch 4/10\n",
      "383/383 [==============================] - 0s 956us/step - loss: 0.7272 - accuracy: 0.5261\n",
      "Epoch 5/10\n",
      "383/383 [==============================] - 0s 962us/step - loss: 0.7120 - accuracy: 0.5585\n",
      "Epoch 6/10\n",
      "383/383 [==============================] - 0s 958us/step - loss: 0.6881 - accuracy: 0.5625\n",
      "Epoch 7/10\n",
      "383/383 [==============================] - 0s 960us/step - loss: 0.7338 - accuracy: 0.5823\n",
      "Epoch 8/10\n",
      "383/383 [==============================] - 0s 965us/step - loss: 0.6761 - accuracy: 0.6043\n",
      "Epoch 9/10\n",
      "383/383 [==============================] - 0s 970us/step - loss: 0.6664 - accuracy: 0.6085\n",
      "Epoch 10/10\n",
      "383/383 [==============================] - 0s 968us/step - loss: 0.6685 - accuracy: 0.6064\n",
      "30/30 [==============================] - 0s 663us/step\n",
      "120/120 [==============================] - 0s 647us/step\n",
      "Epoch 1/10\n",
      "383/383 [==============================] - 0s 935us/step - loss: 5.7820 - accuracy: 0.5259\n",
      "Epoch 2/10\n",
      "383/383 [==============================] - 0s 944us/step - loss: 0.9814 - accuracy: 0.5180\n",
      "Epoch 3/10\n",
      "383/383 [==============================] - 0s 941us/step - loss: 0.7715 - accuracy: 0.5348\n",
      "Epoch 4/10\n",
      "383/383 [==============================] - 0s 951us/step - loss: 0.7361 - accuracy: 0.5240\n",
      "Epoch 5/10\n",
      "383/383 [==============================] - 0s 956us/step - loss: 0.7395 - accuracy: 0.5225\n",
      "Epoch 6/10\n",
      "383/383 [==============================] - 0s 952us/step - loss: 0.7027 - accuracy: 0.5173\n",
      "Epoch 7/10\n",
      "383/383 [==============================] - 0s 953us/step - loss: 0.7038 - accuracy: 0.5235\n",
      "Epoch 8/10\n",
      "383/383 [==============================] - 0s 943us/step - loss: 0.7087 - accuracy: 0.5293\n",
      "Epoch 9/10\n",
      "383/383 [==============================] - 0s 949us/step - loss: 0.6888 - accuracy: 0.5768\n",
      "Epoch 10/10\n",
      "383/383 [==============================] - 0s 942us/step - loss: 0.6940 - accuracy: 0.5852\n",
      "30/30 [==============================] - 0s 672us/step\n",
      "120/120 [==============================] - 0s 624us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████    | 60%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "383/383 [==============================] - 0s 954us/step - loss: 5.1434 - accuracy: 0.5110\n",
      "Epoch 2/10\n",
      "383/383 [==============================] - 0s 992us/step - loss: 0.8204 - accuracy: 0.5214\n",
      "Epoch 3/10\n",
      "383/383 [==============================] - 0s 956us/step - loss: 0.7777 - accuracy: 0.5193\n",
      "Epoch 4/10\n",
      "383/383 [==============================] - 0s 968us/step - loss: 0.7161 - accuracy: 0.5361\n",
      "Epoch 5/10\n",
      "383/383 [==============================] - 0s 948us/step - loss: 0.7195 - accuracy: 0.5259\n",
      "Epoch 6/10\n",
      "383/383 [==============================] - 0s 951us/step - loss: 0.7070 - accuracy: 0.5277\n",
      "Epoch 7/10\n",
      "383/383 [==============================] - 0s 939us/step - loss: 0.6948 - accuracy: 0.5460\n",
      "Epoch 8/10\n",
      "383/383 [==============================] - 0s 944us/step - loss: 0.6971 - accuracy: 0.5405\n",
      "Epoch 9/10\n",
      "383/383 [==============================] - 0s 929us/step - loss: 0.6971 - accuracy: 0.5544\n",
      "Epoch 10/10\n",
      "383/383 [==============================] - 0s 930us/step - loss: 0.6879 - accuracy: 0.5669\n",
      "30/30 [==============================] - 0s 669us/step\n",
      "120/120 [==============================] - 0s 632us/step\n",
      "Epoch 1/10\n",
      "383/383 [==============================] - 0s 980us/step - loss: 5.1090 - accuracy: 0.5173\n",
      "Epoch 2/10\n",
      "383/383 [==============================] - 0s 984us/step - loss: 0.8859 - accuracy: 0.5288\n",
      "Epoch 3/10\n",
      "383/383 [==============================] - 0s 939us/step - loss: 0.7610 - accuracy: 0.5311\n",
      "Epoch 4/10\n",
      "383/383 [==============================] - 0s 969us/step - loss: 0.7464 - accuracy: 0.5298\n",
      "Epoch 5/10\n",
      "383/383 [==============================] - 0s 988us/step - loss: 0.7032 - accuracy: 0.5196\n",
      "Epoch 6/10\n",
      "383/383 [==============================] - 0s 985us/step - loss: 0.7313 - accuracy: 0.5222\n",
      "Epoch 7/10\n",
      "383/383 [==============================] - 0s 990us/step - loss: 0.6988 - accuracy: 0.5387\n",
      "Epoch 8/10\n",
      "383/383 [==============================] - 0s 977us/step - loss: 0.6922 - accuracy: 0.5664\n",
      "Epoch 9/10\n",
      "383/383 [==============================] - 0s 983us/step - loss: 0.6892 - accuracy: 0.5844\n",
      "Epoch 10/10\n",
      "383/383 [==============================] - 0s 985us/step - loss: 0.7018 - accuracy: 0.5852\n",
      "30/30 [==============================] - 0s 689us/step\n",
      "120/120 [==============================] - 0s 661us/step\n",
      "Epoch 1/10\n",
      "383/383 [==============================] - 0s 990us/step - loss: 3.9089 - accuracy: 0.5086\n",
      "Epoch 2/10\n",
      "383/383 [==============================] - 0s 980us/step - loss: 0.8335 - accuracy: 0.5180\n",
      "Epoch 3/10\n",
      "383/383 [==============================] - 0s 980us/step - loss: 0.7256 - accuracy: 0.5115\n",
      "Epoch 4/10\n",
      "383/383 [==============================] - 0s 974us/step - loss: 0.7189 - accuracy: 0.5073\n",
      "Epoch 5/10\n",
      "383/383 [==============================] - 0s 982us/step - loss: 0.8106 - accuracy: 0.5141\n",
      "Epoch 6/10\n",
      "383/383 [==============================] - 0s 990us/step - loss: 0.7176 - accuracy: 0.5034\n",
      "Epoch 7/10\n",
      "383/383 [==============================] - 0s 971us/step - loss: 0.7077 - accuracy: 0.4990\n",
      "Epoch 8/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.7081 - accuracy: 0.5008\n",
      "Epoch 9/10\n",
      "383/383 [==============================] - 0s 995us/step - loss: 0.6944 - accuracy: 0.5016\n",
      "Epoch 10/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.7171 - accuracy: 0.5008\n",
      "30/30 [==============================] - 0s 675us/step\n",
      "120/120 [==============================] - 0s 646us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |████████  | 80%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "383/383 [==============================] - 0s 998us/step - loss: 5.3925 - accuracy: 0.5084\n",
      "Epoch 2/10\n",
      "383/383 [==============================] - 0s 994us/step - loss: 0.8854 - accuracy: 0.5230\n",
      "Epoch 3/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.8241 - accuracy: 0.5193\n",
      "Epoch 4/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.7174 - accuracy: 0.5272\n",
      "Epoch 5/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.7242 - accuracy: 0.5267\n",
      "Epoch 6/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.7213 - accuracy: 0.5175\n",
      "Epoch 7/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.7335 - accuracy: 0.5123\n",
      "Epoch 8/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.7134 - accuracy: 0.5110\n",
      "Epoch 9/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.7099 - accuracy: 0.5078\n",
      "Epoch 10/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.7290 - accuracy: 0.5146\n",
      "30/30 [==============================] - 0s 663us/step\n",
      "120/120 [==============================] - 0s 667us/step\n",
      "Epoch 1/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 4.9723 - accuracy: 0.5212\n",
      "Epoch 2/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.8535 - accuracy: 0.5272\n",
      "Epoch 3/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.8021 - accuracy: 0.5267\n",
      "Epoch 4/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.7358 - accuracy: 0.5303\n",
      "Epoch 5/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.6947 - accuracy: 0.5395\n",
      "Epoch 6/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.7029 - accuracy: 0.5361\n",
      "Epoch 7/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.6871 - accuracy: 0.5742\n",
      "Epoch 8/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.6987 - accuracy: 0.5886\n",
      "Epoch 9/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.7032 - accuracy: 0.5964\n",
      "Epoch 10/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.6666 - accuracy: 0.5985\n",
      "30/30 [==============================] - 0s 696us/step\n",
      "120/120 [==============================] - 0s 663us/step\n",
      "Epoch 1/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 6.4075 - accuracy: 0.5120\n",
      "Epoch 2/10\n",
      "383/383 [==============================] - 0s 996us/step - loss: 0.8133 - accuracy: 0.5084\n",
      "Epoch 3/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.7513 - accuracy: 0.4992\n",
      "Epoch 4/10\n",
      "383/383 [==============================] - 0s 993us/step - loss: 0.7109 - accuracy: 0.5180\n",
      "Epoch 5/10\n",
      "383/383 [==============================] - 0s 989us/step - loss: 0.7335 - accuracy: 0.5470\n",
      "Epoch 6/10\n",
      "383/383 [==============================] - 0s 989us/step - loss: 0.7110 - accuracy: 0.5518\n",
      "Epoch 7/10\n",
      "383/383 [==============================] - 0s 984us/step - loss: 0.6950 - accuracy: 0.5546\n",
      "Epoch 8/10\n",
      "383/383 [==============================] - 0s 973us/step - loss: 0.6864 - accuracy: 0.5635\n",
      "Epoch 9/10\n",
      "383/383 [==============================] - 0s 976us/step - loss: 0.6927 - accuracy: 0.5719\n",
      "Epoch 10/10\n",
      "383/383 [==============================] - 0s 991us/step - loss: 0.6807 - accuracy: 0.5787\n",
      "30/30 [==============================] - 0s 686us/step\n",
      "120/120 [==============================] - 0s 657us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "... for final ensemble...\n",
      "Epoch 1/10\n",
      "121/479 [======>.......................] - ETA: 0s - loss: 16.8670 - accuracy: 0.5661"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "479/479 [==============================] - 0s 840us/step - loss: 8.8463 - accuracy: 0.6012\n",
      "Epoch 2/10\n",
      "479/479 [==============================] - 0s 851us/step - loss: 3.6335 - accuracy: 0.6347\n",
      "Epoch 3/10\n",
      "479/479 [==============================] - 0s 837us/step - loss: 2.4789 - accuracy: 0.6416\n",
      "Epoch 4/10\n",
      "479/479 [==============================] - 0s 848us/step - loss: 1.8909 - accuracy: 0.6508\n",
      "Epoch 5/10\n",
      "479/479 [==============================] - 0s 831us/step - loss: 1.6937 - accuracy: 0.6437\n",
      "Epoch 6/10\n",
      "479/479 [==============================] - 0s 826us/step - loss: 1.5676 - accuracy: 0.6512\n",
      "Epoch 7/10\n",
      "479/479 [==============================] - 0s 838us/step - loss: 1.4769 - accuracy: 0.6671\n",
      "Epoch 8/10\n",
      "479/479 [==============================] - 0s 850us/step - loss: 1.2774 - accuracy: 0.6648\n",
      "Epoch 9/10\n",
      "479/479 [==============================] - 0s 844us/step - loss: 0.9665 - accuracy: 0.6642\n",
      "Epoch 10/10\n",
      "479/479 [==============================] - 0s 839us/step - loss: 1.0033 - accuracy: 0.6660\n",
      "150/150 [==============================] - 0s 613us/step\n",
      "Epoch 1/10\n",
      "479/479 [==============================] - 0s 840us/step - loss: 8.7433 - accuracy: 0.5997\n",
      "Epoch 2/10\n",
      "479/479 [==============================] - 0s 840us/step - loss: 3.7212 - accuracy: 0.6165\n",
      "Epoch 3/10\n",
      "479/479 [==============================] - 0s 826us/step - loss: 1.9213 - accuracy: 0.6437\n",
      "Epoch 4/10\n",
      "479/479 [==============================] - 0s 833us/step - loss: 1.4373 - accuracy: 0.6564\n",
      "Epoch 5/10\n",
      "479/479 [==============================] - 0s 833us/step - loss: 1.8203 - accuracy: 0.6455\n",
      "Epoch 6/10\n",
      "479/479 [==============================] - 0s 839us/step - loss: 1.5681 - accuracy: 0.6455\n",
      "Epoch 7/10\n",
      "479/479 [==============================] - 0s 838us/step - loss: 1.2547 - accuracy: 0.6453\n",
      "Epoch 8/10\n",
      "479/479 [==============================] - 0s 840us/step - loss: 0.9956 - accuracy: 0.6656\n",
      "Epoch 9/10\n",
      "479/479 [==============================] - 0s 832us/step - loss: 1.0200 - accuracy: 0.6824\n",
      "Epoch 10/10\n",
      "479/479 [==============================] - 0s 844us/step - loss: 0.9766 - accuracy: 0.6723\n",
      "150/150 [==============================] - 0s 615us/step\n",
      "Epoch 1/10\n",
      "479/479 [==============================] - 0s 829us/step - loss: 8.8104 - accuracy: 0.5891\n",
      "Epoch 2/10\n",
      "479/479 [==============================] - 0s 836us/step - loss: 1.9865 - accuracy: 0.6322\n",
      "Epoch 3/10\n",
      "479/479 [==============================] - 0s 868us/step - loss: 1.8731 - accuracy: 0.6278\n",
      "Epoch 4/10\n",
      "479/479 [==============================] - 0s 840us/step - loss: 1.3471 - accuracy: 0.6430\n",
      "Epoch 5/10\n",
      "479/479 [==============================] - 0s 842us/step - loss: 1.1448 - accuracy: 0.6455\n",
      "Epoch 6/10\n",
      "479/479 [==============================] - 0s 837us/step - loss: 1.1889 - accuracy: 0.6581\n",
      "Epoch 7/10\n",
      "479/479 [==============================] - 0s 846us/step - loss: 0.9383 - accuracy: 0.6740\n",
      "Epoch 8/10\n",
      "479/479 [==============================] - 0s 847us/step - loss: 0.8989 - accuracy: 0.6673\n",
      "Epoch 9/10\n",
      "479/479 [==============================] - 0s 845us/step - loss: 0.8262 - accuracy: 0.6742\n",
      "Epoch 10/10\n",
      "479/479 [==============================] - 0s 835us/step - loss: 0.8925 - accuracy: 0.6734\n",
      "150/150 [==============================] - 0s 600us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating final ensemble training data: |          |  0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "383/383 [==============================] - 0s 863us/step - loss: 7.5436 - accuracy: 0.6087\n",
      "Epoch 2/10\n",
      "383/383 [==============================] - 0s 865us/step - loss: 4.5286 - accuracy: 0.6168\n",
      "Epoch 3/10\n",
      "383/383 [==============================] - 0s 844us/step - loss: 2.8703 - accuracy: 0.6275\n",
      "Epoch 4/10\n",
      "383/383 [==============================] - 0s 841us/step - loss: 1.7504 - accuracy: 0.6445\n",
      "Epoch 5/10\n",
      "383/383 [==============================] - 0s 847us/step - loss: 1.4704 - accuracy: 0.6524\n",
      "Epoch 6/10\n",
      "383/383 [==============================] - 0s 866us/step - loss: 1.7754 - accuracy: 0.6422\n",
      "Epoch 7/10\n",
      "383/383 [==============================] - 0s 896us/step - loss: 1.4277 - accuracy: 0.6579\n",
      "Epoch 8/10\n",
      "383/383 [==============================] - 0s 844us/step - loss: 1.6143 - accuracy: 0.6383\n",
      "Epoch 9/10\n",
      "383/383 [==============================] - 0s 837us/step - loss: 1.2916 - accuracy: 0.6485\n",
      "Epoch 10/10\n",
      "383/383 [==============================] - 0s 835us/step - loss: 1.1140 - accuracy: 0.6657\n",
      "30/30 [==============================] - 0s 669us/step\n",
      "120/120 [==============================] - 0s 669us/step\n",
      "Epoch 1/10\n",
      "383/383 [==============================] - 0s 846us/step - loss: 9.1593 - accuracy: 0.5920\n",
      "Epoch 2/10\n",
      "383/383 [==============================] - 0s 858us/step - loss: 2.7054 - accuracy: 0.6221\n",
      "Epoch 3/10\n",
      "383/383 [==============================] - 0s 854us/step - loss: 2.2947 - accuracy: 0.6354\n",
      "Epoch 4/10\n",
      "383/383 [==============================] - 0s 851us/step - loss: 1.4010 - accuracy: 0.6283\n",
      "Epoch 5/10\n",
      "383/383 [==============================] - 0s 850us/step - loss: 1.1483 - accuracy: 0.6610\n",
      "Epoch 6/10\n",
      "383/383 [==============================] - 0s 850us/step - loss: 1.1167 - accuracy: 0.6581\n",
      "Epoch 7/10\n",
      "383/383 [==============================] - 0s 844us/step - loss: 1.1502 - accuracy: 0.6615\n",
      "Epoch 8/10\n",
      "383/383 [==============================] - 0s 846us/step - loss: 0.9878 - accuracy: 0.6707\n",
      "Epoch 9/10\n",
      "383/383 [==============================] - 0s 843us/step - loss: 1.0555 - accuracy: 0.6615\n",
      "Epoch 10/10\n",
      "383/383 [==============================] - 0s 850us/step - loss: 0.9175 - accuracy: 0.6822\n",
      "30/30 [==============================] - 0s 672us/step\n",
      "120/120 [==============================] - 0s 674us/step\n",
      "Epoch 1/10\n",
      "383/383 [==============================] - 0s 866us/step - loss: 11.8225 - accuracy: 0.5944\n",
      "Epoch 2/10\n",
      "383/383 [==============================] - 0s 870us/step - loss: 3.3426 - accuracy: 0.6409\n",
      "Epoch 3/10\n",
      "383/383 [==============================] - 0s 869us/step - loss: 3.8269 - accuracy: 0.6184\n",
      "Epoch 4/10\n",
      "383/383 [==============================] - 0s 858us/step - loss: 2.0239 - accuracy: 0.6312\n",
      "Epoch 5/10\n",
      "383/383 [==============================] - 0s 854us/step - loss: 2.1285 - accuracy: 0.6377\n",
      "Epoch 6/10\n",
      "383/383 [==============================] - 0s 860us/step - loss: 1.4891 - accuracy: 0.6722\n",
      "Epoch 7/10\n",
      "383/383 [==============================] - 0s 866us/step - loss: 1.1610 - accuracy: 0.6532\n",
      "Epoch 8/10\n",
      "383/383 [==============================] - 0s 864us/step - loss: 1.2430 - accuracy: 0.6615\n",
      "Epoch 9/10\n",
      "383/383 [==============================] - 0s 854us/step - loss: 1.2561 - accuracy: 0.6477\n",
      "Epoch 10/10\n",
      "383/383 [==============================] - 0s 855us/step - loss: 1.1718 - accuracy: 0.6628\n",
      "30/30 [==============================] - 0s 649us/step\n",
      "120/120 [==============================] - 0s 632us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating final ensemble training data: |██        | 20%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "383/383 [==============================] - 0s 862us/step - loss: 10.7717 - accuracy: 0.5823\n",
      "Epoch 2/10\n",
      "383/383 [==============================] - 0s 858us/step - loss: 2.8079 - accuracy: 0.6359\n",
      "Epoch 3/10\n",
      "383/383 [==============================] - 0s 856us/step - loss: 2.3437 - accuracy: 0.6555\n",
      "Epoch 4/10\n",
      "383/383 [==============================] - 0s 858us/step - loss: 2.2096 - accuracy: 0.6427\n",
      "Epoch 5/10\n",
      "383/383 [==============================] - 0s 845us/step - loss: 1.6633 - accuracy: 0.6568\n",
      "Epoch 6/10\n",
      "383/383 [==============================] - 0s 852us/step - loss: 1.5004 - accuracy: 0.6668\n",
      "Epoch 7/10\n",
      "383/383 [==============================] - 0s 864us/step - loss: 1.2736 - accuracy: 0.6636\n",
      "Epoch 8/10\n",
      "383/383 [==============================] - 0s 862us/step - loss: 1.6798 - accuracy: 0.6649\n",
      "Epoch 9/10\n",
      "383/383 [==============================] - 0s 861us/step - loss: 1.0805 - accuracy: 0.6746\n",
      "Epoch 10/10\n",
      "383/383 [==============================] - 0s 856us/step - loss: 1.0119 - accuracy: 0.6924\n",
      "30/30 [==============================] - 0s 641us/step\n",
      "120/120 [==============================] - 0s 607us/step\n",
      "Epoch 1/10\n",
      "383/383 [==============================] - 0s 852us/step - loss: 9.9015 - accuracy: 0.6127\n",
      "Epoch 2/10\n",
      "383/383 [==============================] - 0s 849us/step - loss: 3.1096 - accuracy: 0.6226\n",
      "Epoch 3/10\n",
      "383/383 [==============================] - 0s 856us/step - loss: 2.6032 - accuracy: 0.6380\n",
      "Epoch 4/10\n",
      "383/383 [==============================] - 0s 849us/step - loss: 2.1480 - accuracy: 0.6370\n",
      "Epoch 5/10\n",
      "383/383 [==============================] - 0s 856us/step - loss: 1.8163 - accuracy: 0.6547\n",
      "Epoch 6/10\n",
      "383/383 [==============================] - 0s 851us/step - loss: 1.5833 - accuracy: 0.6594\n",
      "Epoch 7/10\n",
      "383/383 [==============================] - 0s 837us/step - loss: 1.5298 - accuracy: 0.6584\n",
      "Epoch 8/10\n",
      "383/383 [==============================] - 0s 841us/step - loss: 1.9045 - accuracy: 0.6547\n",
      "Epoch 9/10\n",
      "383/383 [==============================] - 0s 834us/step - loss: 1.0748 - accuracy: 0.6858\n",
      "Epoch 10/10\n",
      "383/383 [==============================] - 0s 840us/step - loss: 1.2161 - accuracy: 0.6827\n",
      "30/30 [==============================] - 0s 649us/step\n",
      "120/120 [==============================] - 0s 675us/step\n",
      "Epoch 1/10\n",
      "383/383 [==============================] - 0s 827us/step - loss: 10.0661 - accuracy: 0.5925\n",
      "Epoch 2/10\n",
      "383/383 [==============================] - 0s 823us/step - loss: 3.7578 - accuracy: 0.6059\n",
      "Epoch 3/10\n",
      "383/383 [==============================] - 0s 831us/step - loss: 2.6842 - accuracy: 0.6357\n",
      "Epoch 4/10\n",
      "383/383 [==============================] - 0s 843us/step - loss: 2.5674 - accuracy: 0.6299\n",
      "Epoch 5/10\n",
      "383/383 [==============================] - 0s 838us/step - loss: 2.0852 - accuracy: 0.6349\n",
      "Epoch 6/10\n",
      "383/383 [==============================] - 0s 842us/step - loss: 1.7235 - accuracy: 0.6521\n",
      "Epoch 7/10\n",
      "383/383 [==============================] - 0s 839us/step - loss: 1.7375 - accuracy: 0.6521\n",
      "Epoch 8/10\n",
      "383/383 [==============================] - 0s 835us/step - loss: 1.5577 - accuracy: 0.6581\n",
      "Epoch 9/10\n",
      "383/383 [==============================] - 0s 834us/step - loss: 1.7800 - accuracy: 0.6406\n",
      "Epoch 10/10\n",
      "383/383 [==============================] - 0s 836us/step - loss: 1.0075 - accuracy: 0.6649\n",
      "30/30 [==============================] - 0s 657us/step\n",
      "120/120 [==============================] - 0s 619us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating final ensemble training data: |████      | 40%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "383/383 [==============================] - 0s 840us/step - loss: 8.1836 - accuracy: 0.5813\n",
      "Epoch 2/10\n",
      "383/383 [==============================] - 0s 836us/step - loss: 3.0821 - accuracy: 0.6257\n",
      "Epoch 3/10\n",
      "383/383 [==============================] - 0s 847us/step - loss: 3.2429 - accuracy: 0.6066\n",
      "Epoch 4/10\n",
      "383/383 [==============================] - 0s 846us/step - loss: 2.2495 - accuracy: 0.6265\n",
      "Epoch 5/10\n",
      "383/383 [==============================] - 0s 850us/step - loss: 1.9470 - accuracy: 0.6291\n",
      "Epoch 6/10\n",
      "383/383 [==============================] - 0s 870us/step - loss: 1.6785 - accuracy: 0.6427\n",
      "Epoch 7/10\n",
      "383/383 [==============================] - 0s 879us/step - loss: 2.0703 - accuracy: 0.6448\n",
      "Epoch 8/10\n",
      "383/383 [==============================] - 0s 858us/step - loss: 1.4169 - accuracy: 0.6592\n",
      "Epoch 9/10\n",
      "383/383 [==============================] - 0s 862us/step - loss: 1.2159 - accuracy: 0.6644\n",
      "Epoch 10/10\n",
      "383/383 [==============================] - 0s 866us/step - loss: 1.4495 - accuracy: 0.6409\n",
      "30/30 [==============================] - 0s 719us/step\n",
      "120/120 [==============================] - 0s 637us/step\n",
      "Epoch 1/10\n",
      "383/383 [==============================] - 0s 864us/step - loss: 7.9143 - accuracy: 0.5949\n",
      "Epoch 2/10\n",
      "383/383 [==============================] - 0s 843us/step - loss: 3.0411 - accuracy: 0.6100\n",
      "Epoch 3/10\n",
      "383/383 [==============================] - 0s 842us/step - loss: 2.9574 - accuracy: 0.6121\n",
      "Epoch 4/10\n",
      "383/383 [==============================] - 0s 856us/step - loss: 2.0543 - accuracy: 0.6385\n",
      "Epoch 5/10\n",
      "383/383 [==============================] - 0s 851us/step - loss: 1.6454 - accuracy: 0.6443\n",
      "Epoch 6/10\n",
      "383/383 [==============================] - 0s 861us/step - loss: 1.8003 - accuracy: 0.6458\n",
      "Epoch 7/10\n",
      "383/383 [==============================] - 0s 859us/step - loss: 1.2943 - accuracy: 0.6547\n",
      "Epoch 8/10\n",
      "383/383 [==============================] - 0s 866us/step - loss: 1.2928 - accuracy: 0.6584\n",
      "Epoch 9/10\n",
      "383/383 [==============================] - 0s 870us/step - loss: 1.1009 - accuracy: 0.6762\n",
      "Epoch 10/10\n",
      "383/383 [==============================] - 0s 863us/step - loss: 1.4132 - accuracy: 0.6542\n",
      "30/30 [==============================] - 0s 671us/step\n",
      "120/120 [==============================] - 0s 654us/step\n",
      "Epoch 1/10\n",
      "383/383 [==============================] - 0s 849us/step - loss: 10.5843 - accuracy: 0.5732\n",
      "Epoch 2/10\n",
      "383/383 [==============================] - 0s 852us/step - loss: 2.9952 - accuracy: 0.6158\n",
      "Epoch 3/10\n",
      "383/383 [==============================] - 0s 856us/step - loss: 1.8871 - accuracy: 0.6176\n",
      "Epoch 4/10\n",
      "383/383 [==============================] - 0s 878us/step - loss: 1.5919 - accuracy: 0.6362\n",
      "Epoch 5/10\n",
      "383/383 [==============================] - 0s 894us/step - loss: 1.2423 - accuracy: 0.6380\n",
      "Epoch 6/10\n",
      "383/383 [==============================] - 0s 891us/step - loss: 1.0964 - accuracy: 0.6529\n",
      "Epoch 7/10\n",
      "383/383 [==============================] - 0s 870us/step - loss: 1.0663 - accuracy: 0.6485\n",
      "Epoch 8/10\n",
      "383/383 [==============================] - 0s 878us/step - loss: 1.1016 - accuracy: 0.6503\n",
      "Epoch 9/10\n",
      "383/383 [==============================] - 0s 877us/step - loss: 0.9245 - accuracy: 0.6735\n",
      "Epoch 10/10\n",
      "383/383 [==============================] - 0s 870us/step - loss: 1.0925 - accuracy: 0.6532\n",
      "30/30 [==============================] - 0s 664us/step\n",
      "120/120 [==============================] - 0s 653us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating final ensemble training data: |██████    | 60%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "383/383 [==============================] - 0s 932us/step - loss: 9.8503 - accuracy: 0.5975\n",
      "Epoch 2/10\n",
      "383/383 [==============================] - 0s 921us/step - loss: 2.7594 - accuracy: 0.6145\n",
      "Epoch 3/10\n",
      "383/383 [==============================] - 0s 922us/step - loss: 1.7362 - accuracy: 0.6404\n",
      "Epoch 4/10\n",
      "383/383 [==============================] - 0s 912us/step - loss: 2.5034 - accuracy: 0.6273\n",
      "Epoch 5/10\n",
      "383/383 [==============================] - 0s 884us/step - loss: 1.8656 - accuracy: 0.6364\n",
      "Epoch 6/10\n",
      "383/383 [==============================] - 0s 867us/step - loss: 2.2813 - accuracy: 0.6357\n",
      "Epoch 7/10\n",
      "383/383 [==============================] - 0s 872us/step - loss: 1.3811 - accuracy: 0.6508\n",
      "Epoch 8/10\n",
      "383/383 [==============================] - 0s 864us/step - loss: 1.3098 - accuracy: 0.6704\n",
      "Epoch 9/10\n",
      "383/383 [==============================] - 0s 862us/step - loss: 0.9829 - accuracy: 0.6785\n",
      "Epoch 10/10\n",
      "383/383 [==============================] - 0s 866us/step - loss: 1.2127 - accuracy: 0.6848\n",
      "30/30 [==============================] - 0s 734us/step\n",
      "120/120 [==============================] - 0s 635us/step\n",
      "Epoch 1/10\n",
      "383/383 [==============================] - 0s 874us/step - loss: 9.0734 - accuracy: 0.5823\n",
      "Epoch 2/10\n",
      "383/383 [==============================] - 0s 879us/step - loss: 3.0573 - accuracy: 0.6184\n",
      "Epoch 3/10\n",
      "383/383 [==============================] - 0s 891us/step - loss: 2.6293 - accuracy: 0.6158\n",
      "Epoch 4/10\n",
      "383/383 [==============================] - 0s 885us/step - loss: 1.5864 - accuracy: 0.6532\n",
      "Epoch 5/10\n",
      "383/383 [==============================] - 0s 882us/step - loss: 1.7087 - accuracy: 0.6477\n",
      "Epoch 6/10\n",
      "383/383 [==============================] - 0s 878us/step - loss: 1.3307 - accuracy: 0.6532\n",
      "Epoch 7/10\n",
      "383/383 [==============================] - 0s 852us/step - loss: 1.0180 - accuracy: 0.6717\n",
      "Epoch 8/10\n",
      "383/383 [==============================] - 0s 840us/step - loss: 0.9082 - accuracy: 0.6722\n",
      "Epoch 9/10\n",
      "383/383 [==============================] - 0s 851us/step - loss: 0.9011 - accuracy: 0.6581\n",
      "Epoch 10/10\n",
      "383/383 [==============================] - 0s 853us/step - loss: 0.9925 - accuracy: 0.6529\n",
      "30/30 [==============================] - 0s 723us/step\n",
      "120/120 [==============================] - 0s 641us/step\n",
      "Epoch 1/10\n",
      "383/383 [==============================] - 0s 878us/step - loss: 8.0154 - accuracy: 0.5839\n",
      "Epoch 2/10\n",
      "383/383 [==============================] - 0s 877us/step - loss: 2.6121 - accuracy: 0.6270\n",
      "Epoch 3/10\n",
      "383/383 [==============================] - 0s 885us/step - loss: 2.5029 - accuracy: 0.6275\n",
      "Epoch 4/10\n",
      "383/383 [==============================] - 0s 876us/step - loss: 1.7350 - accuracy: 0.6325\n",
      "Epoch 5/10\n",
      "383/383 [==============================] - 0s 844us/step - loss: 1.3791 - accuracy: 0.6560\n",
      "Epoch 6/10\n",
      "383/383 [==============================] - 0s 847us/step - loss: 1.4956 - accuracy: 0.6479\n",
      "Epoch 7/10\n",
      "383/383 [==============================] - 0s 842us/step - loss: 1.2864 - accuracy: 0.6568\n",
      "Epoch 8/10\n",
      "383/383 [==============================] - 0s 845us/step - loss: 1.5990 - accuracy: 0.6524\n",
      "Epoch 9/10\n",
      "383/383 [==============================] - 0s 844us/step - loss: 1.0949 - accuracy: 0.6634\n",
      "Epoch 10/10\n",
      "383/383 [==============================] - 0s 848us/step - loss: 1.3289 - accuracy: 0.6479\n",
      "30/30 [==============================] - 0s 670us/step\n",
      "120/120 [==============================] - 0s 735us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating final ensemble training data: |████████  | 80%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "383/383 [==============================] - 0s 866us/step - loss: 8.7517 - accuracy: 0.5962\n",
      "Epoch 2/10\n",
      "383/383 [==============================] - 0s 836us/step - loss: 3.8720 - accuracy: 0.6184\n",
      "Epoch 3/10\n",
      "383/383 [==============================] - 0s 836us/step - loss: 2.6629 - accuracy: 0.6302\n",
      "Epoch 4/10\n",
      "383/383 [==============================] - 0s 865us/step - loss: 1.7906 - accuracy: 0.6482\n",
      "Epoch 5/10\n",
      "383/383 [==============================] - 0s 836us/step - loss: 1.9930 - accuracy: 0.6205\n",
      "Epoch 6/10\n",
      "383/383 [==============================] - 0s 839us/step - loss: 1.6500 - accuracy: 0.6503\n",
      "Epoch 7/10\n",
      "383/383 [==============================] - 0s 835us/step - loss: 1.6799 - accuracy: 0.6372\n",
      "Epoch 8/10\n",
      "383/383 [==============================] - 0s 844us/step - loss: 1.2449 - accuracy: 0.6539\n",
      "Epoch 9/10\n",
      "383/383 [==============================] - 0s 852us/step - loss: 1.1383 - accuracy: 0.6490\n",
      "Epoch 10/10\n",
      "383/383 [==============================] - 0s 842us/step - loss: 1.4791 - accuracy: 0.6537\n",
      "30/30 [==============================] - 0s 646us/step\n",
      "120/120 [==============================] - 0s 626us/step\n",
      "Epoch 1/10\n",
      "383/383 [==============================] - 0s 870us/step - loss: 9.1301 - accuracy: 0.5813\n",
      "Epoch 2/10\n",
      "383/383 [==============================] - 0s 854us/step - loss: 3.1406 - accuracy: 0.6108\n",
      "Epoch 3/10\n",
      "383/383 [==============================] - 0s 853us/step - loss: 2.9035 - accuracy: 0.6226\n",
      "Epoch 4/10\n",
      "383/383 [==============================] - 0s 865us/step - loss: 2.2804 - accuracy: 0.6411\n",
      "Epoch 5/10\n",
      "383/383 [==============================] - 0s 871us/step - loss: 2.2345 - accuracy: 0.6257\n",
      "Epoch 6/10\n",
      "383/383 [==============================] - 0s 874us/step - loss: 1.6421 - accuracy: 0.6579\n",
      "Epoch 7/10\n",
      "383/383 [==============================] - 0s 871us/step - loss: 1.7860 - accuracy: 0.6422\n",
      "Epoch 8/10\n",
      "383/383 [==============================] - 0s 860us/step - loss: 1.6172 - accuracy: 0.6479\n",
      "Epoch 9/10\n",
      "383/383 [==============================] - 0s 862us/step - loss: 1.1187 - accuracy: 0.6662\n",
      "Epoch 10/10\n",
      "383/383 [==============================] - 0s 863us/step - loss: 1.0984 - accuracy: 0.6581\n",
      "30/30 [==============================] - 0s 643us/step\n",
      "120/120 [==============================] - 0s 661us/step\n",
      "Epoch 1/10\n",
      "383/383 [==============================] - 0s 845us/step - loss: 8.5411 - accuracy: 0.5857\n",
      "Epoch 2/10\n",
      "383/383 [==============================] - 0s 842us/step - loss: 3.1636 - accuracy: 0.6051\n",
      "Epoch 3/10\n",
      "383/383 [==============================] - 0s 848us/step - loss: 2.3242 - accuracy: 0.6140\n",
      "Epoch 4/10\n",
      "383/383 [==============================] - 0s 856us/step - loss: 1.6336 - accuracy: 0.6406\n",
      "Epoch 5/10\n",
      "383/383 [==============================] - 0s 850us/step - loss: 1.3172 - accuracy: 0.6458\n",
      "Epoch 6/10\n",
      "383/383 [==============================] - 0s 856us/step - loss: 0.7996 - accuracy: 0.6654\n",
      "Epoch 7/10\n",
      "383/383 [==============================] - 0s 849us/step - loss: 0.7544 - accuracy: 0.6785\n",
      "Epoch 8/10\n",
      "383/383 [==============================] - 0s 857us/step - loss: 0.7322 - accuracy: 0.6688\n",
      "Epoch 9/10\n",
      "383/383 [==============================] - 0s 853us/step - loss: 0.6929 - accuracy: 0.6809\n",
      "Epoch 10/10\n",
      "383/383 [==============================] - 0s 850us/step - loss: 0.6496 - accuracy: 0.6916\n",
      "30/30 [==============================] - 0s 647us/step\n",
      "120/120 [==============================] - 0s 631us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating final ensemble training data: |██████████|100%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "101/479 [=====>........................] - ETA: 0s - loss: 14.5051 - accuracy: 0.4861"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "479/479 [==============================] - 0s 1ms/step - loss: 4.7710 - accuracy: 0.5079\n",
      "Epoch 2/10\n",
      "479/479 [==============================] - 0s 1ms/step - loss: 0.8227 - accuracy: 0.5259\n",
      "Epoch 3/10\n",
      "479/479 [==============================] - 0s 1ms/step - loss: 0.7437 - accuracy: 0.5370\n",
      "Epoch 4/10\n",
      "479/479 [==============================] - 0s 990us/step - loss: 0.7544 - accuracy: 0.5261\n",
      "Epoch 5/10\n",
      "479/479 [==============================] - 0s 1ms/step - loss: 0.7067 - accuracy: 0.5257\n",
      "Epoch 6/10\n",
      "479/479 [==============================] - 0s 1ms/step - loss: 0.7002 - accuracy: 0.5217\n",
      "Epoch 7/10\n",
      "479/479 [==============================] - 0s 1ms/step - loss: 0.7218 - accuracy: 0.5067\n",
      "Epoch 8/10\n",
      "479/479 [==============================] - 0s 1ms/step - loss: 0.7116 - accuracy: 0.5000\n",
      "Epoch 9/10\n",
      "479/479 [==============================] - 0s 1ms/step - loss: 0.7041 - accuracy: 0.5192\n",
      "Epoch 10/10\n",
      "479/479 [==============================] - 0s 1ms/step - loss: 0.6871 - accuracy: 0.5565\n",
      "150/150 [==============================] - 0s 648us/step\n",
      "Epoch 1/10\n",
      "479/479 [==============================] - 0s 988us/step - loss: 3.6866 - accuracy: 0.5100\n",
      "Epoch 2/10\n",
      "479/479 [==============================] - 0s 976us/step - loss: 0.7939 - accuracy: 0.5128\n",
      "Epoch 3/10\n",
      "479/479 [==============================] - 0s 1ms/step - loss: 0.7577 - accuracy: 0.4994\n",
      "Epoch 4/10\n",
      "479/479 [==============================] - 0s 1ms/step - loss: 0.7286 - accuracy: 0.5004\n",
      "Epoch 5/10\n",
      "479/479 [==============================] - 0s 1ms/step - loss: 0.7084 - accuracy: 0.4992\n",
      "Epoch 6/10\n",
      "479/479 [==============================] - 0s 1ms/step - loss: 0.7047 - accuracy: 0.4992\n",
      "Epoch 7/10\n",
      "479/479 [==============================] - 0s 1ms/step - loss: 0.7178 - accuracy: 0.5031\n",
      "Epoch 8/10\n",
      "479/479 [==============================] - 0s 1ms/step - loss: 0.7054 - accuracy: 0.5094\n",
      "Epoch 9/10\n",
      "479/479 [==============================] - 1s 1ms/step - loss: 0.6865 - accuracy: 0.5606\n",
      "Epoch 10/10\n",
      "479/479 [==============================] - 0s 1ms/step - loss: 0.6809 - accuracy: 0.5694\n",
      "150/150 [==============================] - 0s 686us/step\n",
      "Epoch 1/10\n",
      "479/479 [==============================] - 0s 1ms/step - loss: 3.5959 - accuracy: 0.5247\n",
      "Epoch 2/10\n",
      "479/479 [==============================] - 0s 1ms/step - loss: 0.7916 - accuracy: 0.5082\n",
      "Epoch 3/10\n",
      "479/479 [==============================] - 0s 1ms/step - loss: 0.7518 - accuracy: 0.5205\n",
      "Epoch 4/10\n",
      "479/479 [==============================] - 0s 1ms/step - loss: 0.7232 - accuracy: 0.5088\n",
      "Epoch 5/10\n",
      "479/479 [==============================] - 0s 1ms/step - loss: 0.7076 - accuracy: 0.5061\n",
      "Epoch 6/10\n",
      "479/479 [==============================] - 0s 1ms/step - loss: 0.6953 - accuracy: 0.5318\n",
      "Epoch 7/10\n",
      "479/479 [==============================] - 0s 1ms/step - loss: 0.6990 - accuracy: 0.5690\n",
      "Epoch 8/10\n",
      "479/479 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.5828\n",
      "Epoch 9/10\n",
      "479/479 [==============================] - 0s 1ms/step - loss: 0.6852 - accuracy: 0.5958\n",
      "Epoch 10/10\n",
      "479/479 [==============================] - 0s 1ms/step - loss: 0.6680 - accuracy: 0.6148\n",
      "150/150 [==============================] - 0s 665us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating final ensemble training data: |          |  0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 3.4169 - accuracy: 0.5152\n",
      "Epoch 2/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.7586 - accuracy: 0.5144\n",
      "Epoch 3/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.7596 - accuracy: 0.5099\n",
      "Epoch 4/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.7465 - accuracy: 0.5039\n",
      "Epoch 5/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.7033 - accuracy: 0.5058\n",
      "Epoch 6/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.7026 - accuracy: 0.4974\n",
      "Epoch 7/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.7083 - accuracy: 0.4971\n",
      "Epoch 8/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.7009 - accuracy: 0.5141\n",
      "Epoch 9/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.6985 - accuracy: 0.5058\n",
      "Epoch 10/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.5290\n",
      "30/30 [==============================] - 0s 696us/step\n",
      "120/120 [==============================] - 0s 665us/step\n",
      "Epoch 1/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 2.7384 - accuracy: 0.5149\n",
      "Epoch 2/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.7297 - accuracy: 0.5159\n",
      "Epoch 3/10\n",
      "383/383 [==============================] - 0s 997us/step - loss: 0.7231 - accuracy: 0.5029\n",
      "Epoch 4/10\n",
      "383/383 [==============================] - 0s 989us/step - loss: 0.7094 - accuracy: 0.5029\n",
      "Epoch 5/10\n",
      "383/383 [==============================] - 0s 994us/step - loss: 0.7062 - accuracy: 0.5042\n",
      "Epoch 6/10\n",
      "383/383 [==============================] - 0s 982us/step - loss: 0.7020 - accuracy: 0.5005\n",
      "Epoch 7/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.6987 - accuracy: 0.5261\n",
      "Epoch 8/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.6982 - accuracy: 0.5269\n",
      "Epoch 9/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.6977 - accuracy: 0.5193\n",
      "Epoch 10/10\n",
      "383/383 [==============================] - 0s 974us/step - loss: 0.6893 - accuracy: 0.5633\n",
      "30/30 [==============================] - 0s 704us/step\n",
      "120/120 [==============================] - 0s 672us/step\n",
      "Epoch 1/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 6.5627 - accuracy: 0.5073\n",
      "Epoch 2/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.8225 - accuracy: 0.5345\n",
      "Epoch 3/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.7958 - accuracy: 0.5196\n",
      "Epoch 4/10\n",
      "383/383 [==============================] - 0s 975us/step - loss: 0.7535 - accuracy: 0.5193\n",
      "Epoch 5/10\n",
      "383/383 [==============================] - 0s 979us/step - loss: 0.7691 - accuracy: 0.5086\n",
      "Epoch 6/10\n",
      "383/383 [==============================] - 0s 973us/step - loss: 0.7061 - accuracy: 0.4997\n",
      "Epoch 7/10\n",
      "383/383 [==============================] - 0s 968us/step - loss: 0.7072 - accuracy: 0.5186\n",
      "Epoch 8/10\n",
      "383/383 [==============================] - 0s 964us/step - loss: 0.7030 - accuracy: 0.5120\n",
      "Epoch 9/10\n",
      "383/383 [==============================] - 0s 964us/step - loss: 0.7479 - accuracy: 0.5669\n",
      "Epoch 10/10\n",
      "383/383 [==============================] - 0s 959us/step - loss: 0.6784 - accuracy: 0.5910\n",
      "30/30 [==============================] - 0s 660us/step\n",
      "120/120 [==============================] - 0s 640us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating final ensemble training data: |██        | 20%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "383/383 [==============================] - 0s 982us/step - loss: 4.1992 - accuracy: 0.5178\n",
      "Epoch 2/10\n",
      "383/383 [==============================] - 0s 976us/step - loss: 0.8067 - accuracy: 0.5308\n",
      "Epoch 3/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.7306 - accuracy: 0.5254\n",
      "Epoch 4/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.7500 - accuracy: 0.5055\n",
      "Epoch 5/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.7059 - accuracy: 0.5097\n",
      "Epoch 6/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.5311\n",
      "Epoch 7/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.6958 - accuracy: 0.5829\n",
      "Epoch 8/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.6786 - accuracy: 0.5766\n",
      "Epoch 9/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.6998 - accuracy: 0.5870\n",
      "Epoch 10/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.6808 - accuracy: 0.6045\n",
      "30/30 [==============================] - 0s 688us/step\n",
      "120/120 [==============================] - 0s 689us/step\n",
      "Epoch 1/10\n",
      "383/383 [==============================] - 0s 999us/step - loss: 4.9505 - accuracy: 0.5097\n",
      "Epoch 2/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.8971 - accuracy: 0.5272\n",
      "Epoch 3/10\n",
      "383/383 [==============================] - 0s 970us/step - loss: 0.7721 - accuracy: 0.5298\n",
      "Epoch 4/10\n",
      "383/383 [==============================] - 0s 970us/step - loss: 0.7275 - accuracy: 0.5355\n",
      "Epoch 5/10\n",
      "383/383 [==============================] - 0s 980us/step - loss: 0.7881 - accuracy: 0.5204\n",
      "Epoch 6/10\n",
      "383/383 [==============================] - 0s 996us/step - loss: 0.6946 - accuracy: 0.5389\n",
      "Epoch 7/10\n",
      "383/383 [==============================] - 0s 992us/step - loss: 0.7141 - accuracy: 0.5081\n",
      "Epoch 8/10\n",
      "383/383 [==============================] - 0s 991us/step - loss: 0.7081 - accuracy: 0.5112\n",
      "Epoch 9/10\n",
      "383/383 [==============================] - 0s 990us/step - loss: 0.6928 - accuracy: 0.5105\n",
      "Epoch 10/10\n",
      "383/383 [==============================] - 0s 980us/step - loss: 0.7015 - accuracy: 0.5131\n",
      "30/30 [==============================] - 0s 671us/step\n",
      "120/120 [==============================] - 0s 670us/step\n",
      "Epoch 1/10\n",
      "383/383 [==============================] - 0s 998us/step - loss: 4.4639 - accuracy: 0.5170\n",
      "Epoch 2/10\n",
      "383/383 [==============================] - 0s 991us/step - loss: 0.8031 - accuracy: 0.5251\n",
      "Epoch 3/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.7268 - accuracy: 0.5118\n",
      "Epoch 4/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.7148 - accuracy: 0.5209\n",
      "Epoch 5/10\n",
      "383/383 [==============================] - 0s 999us/step - loss: 0.7008 - accuracy: 0.5227\n",
      "Epoch 6/10\n",
      "383/383 [==============================] - 0s 994us/step - loss: 0.7385 - accuracy: 0.5123\n",
      "Epoch 7/10\n",
      "383/383 [==============================] - 0s 999us/step - loss: 0.7125 - accuracy: 0.5047\n",
      "Epoch 8/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.5335\n",
      "Epoch 9/10\n",
      "383/383 [==============================] - 0s 998us/step - loss: 0.6985 - accuracy: 0.5105\n",
      "Epoch 10/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.7125 - accuracy: 0.5403\n",
      "30/30 [==============================] - 0s 686us/step\n",
      "120/120 [==============================] - 0s 665us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating final ensemble training data: |████      | 40%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 5.7161 - accuracy: 0.5133\n",
      "Epoch 2/10\n",
      "383/383 [==============================] - 0s 1000us/step - loss: 0.8609 - accuracy: 0.5018\n",
      "Epoch 3/10\n",
      "383/383 [==============================] - 0s 980us/step - loss: 0.7624 - accuracy: 0.5217\n",
      "Epoch 4/10\n",
      "383/383 [==============================] - 0s 986us/step - loss: 0.7231 - accuracy: 0.5256\n",
      "Epoch 5/10\n",
      "383/383 [==============================] - 0s 981us/step - loss: 0.7102 - accuracy: 0.5369\n",
      "Epoch 6/10\n",
      "383/383 [==============================] - 0s 997us/step - loss: 0.7125 - accuracy: 0.5144\n",
      "Epoch 7/10\n",
      "383/383 [==============================] - 0s 990us/step - loss: 0.7101 - accuracy: 0.5091\n",
      "Epoch 8/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.7097 - accuracy: 0.5055\n",
      "Epoch 9/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.7032 - accuracy: 0.5183\n",
      "Epoch 10/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.6989 - accuracy: 0.5152\n",
      "30/30 [==============================] - 0s 680us/step\n",
      "120/120 [==============================] - 0s 645us/step\n",
      "Epoch 1/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 5.6314 - accuracy: 0.5013\n",
      "Epoch 2/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.8805 - accuracy: 0.5212\n",
      "Epoch 3/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.7424 - accuracy: 0.5162\n",
      "Epoch 4/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.7390 - accuracy: 0.5204\n",
      "Epoch 5/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.7379 - accuracy: 0.5180\n",
      "Epoch 6/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.7008 - accuracy: 0.5222\n",
      "Epoch 7/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.7047 - accuracy: 0.5183\n",
      "Epoch 8/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.7277 - accuracy: 0.5029\n",
      "Epoch 9/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.6984 - accuracy: 0.5167\n",
      "Epoch 10/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.7015 - accuracy: 0.4997\n",
      "30/30 [==============================] - 0s 713us/step\n",
      "120/120 [==============================] - 0s 629us/step\n",
      "Epoch 1/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 5.3290 - accuracy: 0.5324\n",
      "Epoch 2/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.9035 - accuracy: 0.5282\n",
      "Epoch 3/10\n",
      "383/383 [==============================] - 0s 1000us/step - loss: 0.7681 - accuracy: 0.5489\n",
      "Epoch 4/10\n",
      "383/383 [==============================] - 0s 995us/step - loss: 0.7316 - accuracy: 0.5374\n",
      "Epoch 5/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.7207 - accuracy: 0.5473\n",
      "Epoch 6/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5520\n",
      "Epoch 7/10\n",
      "383/383 [==============================] - 0s 983us/step - loss: 0.6885 - accuracy: 0.5690\n",
      "Epoch 8/10\n",
      "383/383 [==============================] - 0s 964us/step - loss: 0.6826 - accuracy: 0.5740\n",
      "Epoch 9/10\n",
      "383/383 [==============================] - 0s 964us/step - loss: 0.6747 - accuracy: 0.5706\n",
      "Epoch 10/10\n",
      "383/383 [==============================] - 0s 974us/step - loss: 0.6797 - accuracy: 0.5836\n",
      "30/30 [==============================] - 0s 699us/step\n",
      "120/120 [==============================] - 0s 633us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating final ensemble training data: |██████    | 60%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 3.8485 - accuracy: 0.4997\n",
      "Epoch 2/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.7600 - accuracy: 0.5042\n",
      "Epoch 3/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.7374 - accuracy: 0.5068\n",
      "Epoch 4/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.7118 - accuracy: 0.5105\n",
      "Epoch 5/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.7340 - accuracy: 0.4969\n",
      "Epoch 6/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.5016\n",
      "Epoch 7/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.6937 - accuracy: 0.5005\n",
      "Epoch 8/10\n",
      "383/383 [==============================] - 0s 982us/step - loss: 0.6990 - accuracy: 0.4846\n",
      "Epoch 9/10\n",
      "383/383 [==============================] - 0s 983us/step - loss: 0.6962 - accuracy: 0.5071\n",
      "Epoch 10/10\n",
      "383/383 [==============================] - 0s 992us/step - loss: 0.6985 - accuracy: 0.4984\n",
      "30/30 [==============================] - 0s 657us/step\n",
      "120/120 [==============================] - 0s 664us/step\n",
      "Epoch 1/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 3.3110 - accuracy: 0.5073\n",
      "Epoch 2/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.7481 - accuracy: 0.5183\n",
      "Epoch 3/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.7424 - accuracy: 0.5217\n",
      "Epoch 4/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.7208 - accuracy: 0.5071\n",
      "Epoch 5/10\n",
      "383/383 [==============================] - 0s 983us/step - loss: 0.7034 - accuracy: 0.5065\n",
      "Epoch 6/10\n",
      "383/383 [==============================] - 0s 985us/step - loss: 0.7070 - accuracy: 0.5005\n",
      "Epoch 7/10\n",
      "383/383 [==============================] - 0s 986us/step - loss: 0.7111 - accuracy: 0.5136\n",
      "Epoch 8/10\n",
      "383/383 [==============================] - 0s 986us/step - loss: 0.7004 - accuracy: 0.4945\n",
      "Epoch 9/10\n",
      "383/383 [==============================] - 0s 985us/step - loss: 0.7050 - accuracy: 0.4966\n",
      "Epoch 10/10\n",
      "383/383 [==============================] - 0s 969us/step - loss: 0.7101 - accuracy: 0.4942\n",
      "30/30 [==============================] - 0s 694us/step\n",
      "120/120 [==============================] - 0s 654us/step\n",
      "Epoch 1/10\n",
      "383/383 [==============================] - 0s 983us/step - loss: 4.6288 - accuracy: 0.5089\n",
      "Epoch 2/10\n",
      "383/383 [==============================] - 0s 972us/step - loss: 0.8394 - accuracy: 0.4995\n",
      "Epoch 3/10\n",
      "383/383 [==============================] - 0s 979us/step - loss: 0.7805 - accuracy: 0.5348\n",
      "Epoch 4/10\n",
      "383/383 [==============================] - 0s 981us/step - loss: 0.7171 - accuracy: 0.5656\n",
      "Epoch 5/10\n",
      "383/383 [==============================] - 0s 978us/step - loss: 0.7171 - accuracy: 0.5750\n",
      "Epoch 6/10\n",
      "383/383 [==============================] - 0s 985us/step - loss: 0.6977 - accuracy: 0.5748\n",
      "Epoch 7/10\n",
      "383/383 [==============================] - 0s 980us/step - loss: 0.6810 - accuracy: 0.6043\n",
      "Epoch 8/10\n",
      "383/383 [==============================] - 0s 974us/step - loss: 0.6941 - accuracy: 0.5808\n",
      "Epoch 9/10\n",
      "383/383 [==============================] - 0s 988us/step - loss: 0.6776 - accuracy: 0.5957\n",
      "Epoch 10/10\n",
      "383/383 [==============================] - 0s 986us/step - loss: 0.6746 - accuracy: 0.6098\n",
      "30/30 [==============================] - 0s 682us/step\n",
      "120/120 [==============================] - 0s 715us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating final ensemble training data: |████████  | 80%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 4.9002 - accuracy: 0.5280\n",
      "Epoch 2/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.8029 - accuracy: 0.5081\n",
      "Epoch 3/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.7854 - accuracy: 0.5183\n",
      "Epoch 4/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.7301 - accuracy: 0.5152\n",
      "Epoch 5/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.7587 - accuracy: 0.5159\n",
      "Epoch 6/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.7001 - accuracy: 0.5112\n",
      "Epoch 7/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.7040 - accuracy: 0.5065\n",
      "Epoch 8/10\n",
      "383/383 [==============================] - 0s 992us/step - loss: 0.6972 - accuracy: 0.5068\n",
      "Epoch 9/10\n",
      "383/383 [==============================] - 0s 984us/step - loss: 0.6964 - accuracy: 0.4961\n",
      "Epoch 10/10\n",
      "383/383 [==============================] - 0s 986us/step - loss: 0.7018 - accuracy: 0.5044\n",
      "30/30 [==============================] - 0s 692us/step\n",
      "120/120 [==============================] - 0s 656us/step\n",
      "Epoch 1/10\n",
      "383/383 [==============================] - 0s 988us/step - loss: 5.7892 - accuracy: 0.5099\n",
      "Epoch 2/10\n",
      "383/383 [==============================] - 0s 988us/step - loss: 0.9810 - accuracy: 0.5204\n",
      "Epoch 3/10\n",
      "383/383 [==============================] - 0s 975us/step - loss: 0.8109 - accuracy: 0.5363\n",
      "Epoch 4/10\n",
      "383/383 [==============================] - 0s 980us/step - loss: 0.7391 - accuracy: 0.5413\n",
      "Epoch 5/10\n",
      "383/383 [==============================] - 0s 963us/step - loss: 0.7173 - accuracy: 0.5470\n",
      "Epoch 6/10\n",
      "383/383 [==============================] - 0s 965us/step - loss: 0.7454 - accuracy: 0.5376\n",
      "Epoch 7/10\n",
      "383/383 [==============================] - 0s 973us/step - loss: 0.7364 - accuracy: 0.5374\n",
      "Epoch 8/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.7154 - accuracy: 0.5515\n",
      "Epoch 9/10\n",
      "383/383 [==============================] - 0s 969us/step - loss: 0.6887 - accuracy: 0.5609\n",
      "Epoch 10/10\n",
      "383/383 [==============================] - 0s 991us/step - loss: 0.6850 - accuracy: 0.5669\n",
      "30/30 [==============================] - 0s 677us/step\n",
      "120/120 [==============================] - 0s 642us/step\n",
      "Epoch 1/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 6.0097 - accuracy: 0.5073\n",
      "Epoch 2/10\n",
      "383/383 [==============================] - 0s 1ms/step - loss: 0.9041 - accuracy: 0.5267\n",
      "Epoch 3/10\n",
      "383/383 [==============================] - 0s 969us/step - loss: 0.7890 - accuracy: 0.5157\n",
      "Epoch 4/10\n",
      "383/383 [==============================] - 0s 978us/step - loss: 0.7381 - accuracy: 0.5285\n",
      "Epoch 5/10\n",
      "383/383 [==============================] - 0s 975us/step - loss: 0.7148 - accuracy: 0.5193\n",
      "Epoch 6/10\n",
      "383/383 [==============================] - 0s 985us/step - loss: 0.7134 - accuracy: 0.5120\n",
      "Epoch 7/10\n",
      "383/383 [==============================] - 0s 1000us/step - loss: 0.7113 - accuracy: 0.5491\n",
      "Epoch 8/10\n",
      "383/383 [==============================] - 0s 982us/step - loss: 0.7060 - accuracy: 0.5633\n",
      "Epoch 9/10\n",
      "383/383 [==============================] - 0s 985us/step - loss: 0.6780 - accuracy: 0.5768\n",
      "Epoch 10/10\n",
      "383/383 [==============================] - 0s 983us/step - loss: 0.6968 - accuracy: 0.5896\n",
      "30/30 [==============================] - 0s 675us/step\n",
      "120/120 [==============================] - 0s 694us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating final ensemble training data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on admission...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |          |  0%2024-03-04 20:05:58.431116: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-04 20:05:58.459323: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-04 20:05:58.459367: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-04 20:05:58.460137: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-04 20:05:58.464906: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-04 20:05:58.465082: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-04 20:05:58.723307: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-04 20:05:58.752484: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-04 20:05:58.752551: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-04 20:05:58.753330: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-04 20:05:58.758389: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-04 20:05:58.758608: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-04 20:05:58.770313: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-04 20:05:58.783818: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-04 20:05:58.807161: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-04 20:05:58.815883: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-04 20:05:58.816022: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-04 20:05:58.816020: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-04 20:05:58.816020: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-04 20:05:58.816022: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-04 20:05:58.816282: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-04 20:05:58.816316: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-04 20:05:58.817372: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-04 20:05:58.824251: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-04 20:05:58.824475: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-04 20:05:58.831284: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-04 20:05:58.831341: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-04 20:05:58.832377: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-04 20:05:58.839342: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-04 20:05:58.839596: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-04 20:05:58.846183: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-04 20:05:58.852512: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-04 20:05:58.852576: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-04 20:05:58.853598: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-04 20:05:58.858608: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-04 20:05:58.860545: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-04 20:05:58.860755: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-04 20:05:58.862035: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-04 20:05:58.862088: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-04 20:05:58.863139: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-04 20:05:58.863221: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-04 20:05:58.863221: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-04 20:05:58.863230: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-04 20:05:58.863231: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-04 20:05:58.863259: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-04 20:05:58.863260: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-04 20:05:58.863261: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-04 20:05:58.863262: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-04 20:05:58.864341: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-04 20:05:58.864349: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-04 20:05:58.864357: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-04 20:05:58.864357: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-04 20:05:58.867756: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-04 20:05:58.867755: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-04 20:05:58.869968: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-04 20:05:58.870183: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-04 20:05:58.871140: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-04 20:05:58.871139: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-04 20:05:58.871139: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-04 20:05:58.871139: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-04 20:05:58.871345: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-04 20:05:58.871345: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-04 20:05:58.871353: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-04 20:05:58.871357: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-04 20:05:58.877878: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-04 20:05:58.879303: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-04 20:05:58.893282: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-04 20:05:58.893330: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-04 20:05:58.894401: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-04 20:05:58.896750: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-04 20:05:58.901581: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-04 20:05:58.901797: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-04 20:05:58.905707: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-04 20:05:58.905750: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-04 20:05:58.906813: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-04 20:05:58.909192: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-04 20:05:58.912698: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-04 20:05:58.912698: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-04 20:05:58.912739: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-04 20:05:58.912742: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-04 20:05:58.913879: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-04 20:05:58.913883: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-04 20:05:58.913928: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-04 20:05:58.914184: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-04 20:05:58.920834: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-04 20:05:58.920833: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-04 20:05:58.921047: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-04 20:05:58.921048: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-04 20:05:58.926215: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-04 20:05:58.928290: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-04 20:05:58.928339: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-04 20:05:58.929543: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-04 20:05:58.931961: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-04 20:05:58.932014: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-04 20:05:58.933175: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-04 20:05:58.937376: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-04 20:05:58.937639: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-04 20:05:58.940685: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-04 20:05:58.940769: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-04 20:05:58.940983: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-04 20:05:58.942592: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-04 20:05:58.942624: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-04 20:05:58.943631: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-04 20:05:58.950355: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-04 20:05:58.950578: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-04 20:05:58.955080: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-04 20:05:58.955120: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-04 20:05:58.956918: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-04 20:05:58.956955: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-04 20:05:58.957993: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-04 20:05:58.964909: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-04 20:05:58.965142: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-04 20:05:58.975479: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-04 20:05:58.975548: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-04 20:05:58.976664: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-04 20:05:58.980576: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-04 20:05:58.982140: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-04 20:05:58.984272: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-04 20:05:58.984478: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-04 20:05:58.994175: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-04 20:05:58.994232: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-04 20:05:58.995397: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-04 20:05:58.997186: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-04 20:05:59.003297: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-04 20:05:59.003506: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-04 20:05:59.006134: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-04 20:05:59.008349: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-04 20:05:59.008403: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-04 20:05:59.008401: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-04 20:05:59.008432: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-04 20:05:59.009627: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-04 20:05:59.009628: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-04 20:05:59.009734: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-04 20:05:59.017281: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-04 20:05:59.017282: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-04 20:05:59.017485: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-04 20:05:59.017507: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-04 20:05:59.017507: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-04 20:05:59.021322: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-04 20:05:59.027859: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-04 20:05:59.027859: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-04 20:05:59.027905: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-04 20:05:59.027897: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-04 20:05:59.028887: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-04 20:05:59.028887: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-04 20:05:59.035583: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-04 20:05:59.035583: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-04 20:05:59.035795: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-04 20:05:59.035852: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-04 20:05:59.045282: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-04 20:05:59.051395: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-04 20:05:59.051456: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-04 20:05:59.052629: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-04 20:05:59.054401: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-04 20:05:59.054452: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-04 20:05:59.055470: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-04 20:05:59.060338: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-04 20:05:59.060608: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-04 20:05:59.061968: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-04 20:05:59.062196: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-04 20:05:59.063349: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-04 20:05:59.063402: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-04 20:05:59.064543: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-04 20:05:59.071722: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-04 20:05:59.071780: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-04 20:05:59.072314: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-04 20:05:59.072567: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-04 20:05:59.072960: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-04 20:05:59.074551: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-04 20:05:59.074591: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-04 20:05:59.075660: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-04 20:05:59.080310: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-04 20:05:59.080567: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-04 20:05:59.083215: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-04 20:05:59.083441: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-04 20:05:59.098595: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-04 20:05:59.098649: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-04 20:05:59.099802: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-04 20:05:59.107742: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-04 20:05:59.107962: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-04 20:05:59.314205: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-03-04 20:05:59.562716: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-03-04 20:05:59.938022: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-03-04 20:05:59.972090: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-03-04 20:05:59.975275: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-03-04 20:05:59.997757: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-03-04 20:06:00.012896: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-03-04 20:06:00.016025: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-03-04 20:06:00.020271: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-03-04 20:06:00.036640: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-03-04 20:06:00.042260: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-03-04 20:06:00.045736: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-03-04 20:06:00.055798: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-03-04 20:06:00.075811: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-03-04 20:06:00.077957: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-03-04 20:06:00.092833: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-03-04 20:06:00.094323: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-03-04 20:06:00.121877: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-03-04 20:06:00.131752: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-03-04 20:06:00.144144: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-03-04 20:06:00.176355: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-03-04 20:06:00.178105: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-03-04 20:06:00.181483: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-03-04 20:06:00.185868: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-03-04 20:06:00.186156: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-03-04 20:06:00.189602: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-03-04 20:06:00.198017: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-03-04 20:06:00.213951: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-03-04 20:06:00.234967: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-03-04 20:06:00.240716: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Generating ensemble training data: |██        | 20%2024-03-04 20:06:02.259977: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-04 20:06:02.285279: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-04 20:06:02.285313: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-04 20:06:02.286021: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-04 20:06:02.290313: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-04 20:06:02.290489: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-04 20:06:02.305199: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-04 20:06:02.331158: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-04 20:06:02.331196: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-04 20:06:02.331933: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-04 20:06:02.336372: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-04 20:06:02.336568: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-04 20:06:02.949056: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-03-04 20:06:02.999639: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "... for final ensemble...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Training final base predictors: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on comorbidities...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "... for final ensemble...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Training final base predictors: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training base predictors on vitals...\n",
      "        \n",
      "... for ensemble performance analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Generating ensemble test data: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "... for final ensemble...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating ensemble training data: |██████████|100%\n",
      "Training final base predictors: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing ensembles: |██████████|100%\n",
      "Training final ensemble models: |██████████|100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE WITH MODALITY labs YAYYYY!!!!\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "performance = {}\n",
    "for k in data.keys():\n",
    "    # #modality alone structured\n",
    "    # EI = e.EnsembleIntegration(\n",
    "    #             k_outer=5,\n",
    "    #             k_inner=5,\n",
    "    #             n_samples=1,\n",
    "    #             sampling_strategy=\"undersampling\",\n",
    "    #             sampling_aggregation=None,\n",
    "    #             n_jobs=-1,\n",
    "    #             metrics=metrics,\n",
    "    #             random_state=38,\n",
    "    #             project_name=f\"{k}\",\n",
    "    #             model_building=False,\n",
    "    #             )\n",
    "    # EI.fit_base(data[k], labels, modality_name=k, base_predictors=base_predictors)\n",
    "    \n",
    "    # EI.fit_ensemble(ensemble_predictors=ensemble_predictors)\n",
    "    \n",
    "    # performance[k] = EI.ensemble_summary\n",
    "\n",
    "    d_base_predictors = build_deep_bps(input_dim=data[k].shape[1])\n",
    "    # #modality alone unstructured\n",
    "    # EI = e.EnsembleIntegration(\n",
    "    #             k_outer=5,\n",
    "    #             k_inner=5,\n",
    "    #             n_samples=1,\n",
    "    #             sampling_strategy=\"undersampling\",\n",
    "    #             sampling_aggregation=None,\n",
    "    #             n_jobs=-1,\n",
    "    #             metrics=metrics,\n",
    "    #             random_state=38,\n",
    "    #             project_name=f\"{k} deep\",\n",
    "    #             model_building=False,\n",
    "    #             )\n",
    "    # EI.fit_base(data[k], labels, modality_name=k, base_predictors=d_base_predictors)\n",
    "    \n",
    "    # EI.fit_ensemble(ensemble_predictors=ensemble_predictors)\n",
    "\n",
    "    # performance[f\"{k} deep\"] = EI.ensemble_summary\n",
    "\n",
    "    #EI with one modality unstructured\n",
    "    if k==\"labs\":\n",
    "        EI = e.EnsembleIntegration(\n",
    "                        k_outer=5,\n",
    "                        k_inner=5,\n",
    "                        n_samples=3,\n",
    "                        sampling_strategy=\"hybrid\",\n",
    "                        sampling_aggregation=\"mean\",\n",
    "                        n_jobs=-1,\n",
    "                        metrics=metrics,\n",
    "                        random_state=38,\n",
    "                        project_name=f\"EI with {k} deep\",\n",
    "                        model_building=True,\n",
    "                        )\n",
    "        for m in data.keys():\n",
    "            if m == k:\n",
    "                EI.fit_base(data[m], labels, modality_name=m, base_predictors=d_base_predictors)\n",
    "            else:\n",
    "                EI.fit_base(data[m], labels, modality_name=m, base_predictors=base_predictors)\n",
    "        \n",
    "        EI.fit_ensemble(ensemble_predictors=ensemble_predictors)\n",
    "\n",
    "        performance[f\"EI with {k} deep\"] = EI.ensemble_summary\n",
    "\n",
    "        print(f\"DONE WITH MODALITY {k} YAYYYY!!!!\")\n",
    "\n",
    "# # normal EI\n",
    "# EI = e.EnsembleIntegration(\n",
    "#                 k_outer=5,\n",
    "#                 k_inner=5,\n",
    "#                 n_samples=1,\n",
    "#                 sampling_strategy=\"undersampling\",\n",
    "#                 sampling_aggregation=None,\n",
    "#                 n_jobs=-1,\n",
    "#                 metrics=metrics,\n",
    "#                 random_state=38,\n",
    "#                 project_name=\"EI\",\n",
    "#                 model_building=False,\n",
    "#                 )\n",
    "# EI.fit_base(data, labels, base_predictors=base_predictors)\n",
    "# EI.fit_ensemble(ensemble_predictors=ensemble_predictors)\n",
    "\n",
    "# performance[\"EI\"] = EI.ensemble_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>modality</th>\n",
       "      <th colspan=\"2\" halign=\"left\">admission</th>\n",
       "      <th colspan=\"2\" halign=\"left\">comorbidities</th>\n",
       "      <th colspan=\"2\" halign=\"left\">labs</th>\n",
       "      <th colspan=\"2\" halign=\"left\">vitals</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base predictor</th>\n",
       "      <th>ADAB</th>\n",
       "      <th>XGB</th>\n",
       "      <th>ADAB</th>\n",
       "      <th>XGB</th>\n",
       "      <th>deep_w_dropout</th>\n",
       "      <th>simple</th>\n",
       "      <th>ADAB</th>\n",
       "      <th>XGB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f_max</th>\n",
       "      <td>0.548315</td>\n",
       "      <td>0.540468</td>\n",
       "      <td>0.444802</td>\n",
       "      <td>0.437554</td>\n",
       "      <td>0.492405</td>\n",
       "      <td>0.542175</td>\n",
       "      <td>0.494155</td>\n",
       "      <td>0.485262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auc</th>\n",
       "      <td>0.751567</td>\n",
       "      <td>0.747154</td>\n",
       "      <td>0.597070</td>\n",
       "      <td>0.561273</td>\n",
       "      <td>0.660958</td>\n",
       "      <td>0.741741</td>\n",
       "      <td>0.690542</td>\n",
       "      <td>0.679582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mcc</th>\n",
       "      <td>0.334149</td>\n",
       "      <td>0.326549</td>\n",
       "      <td>0.140382</td>\n",
       "      <td>0.095928</td>\n",
       "      <td>0.169659</td>\n",
       "      <td>0.317642</td>\n",
       "      <td>0.269227</td>\n",
       "      <td>0.249209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "modality       admission           comorbidities                     labs  \\\n",
       "base predictor      ADAB       XGB          ADAB       XGB deep_w_dropout   \n",
       "f_max           0.548315  0.540468      0.444802  0.437554       0.492405   \n",
       "auc             0.751567  0.747154      0.597070  0.561273       0.660958   \n",
       "mcc             0.334149  0.326549      0.140382  0.095928       0.169659   \n",
       "\n",
       "modality                    vitals            \n",
       "base predictor    simple      ADAB       XGB  \n",
       "f_max           0.542175  0.494155  0.485262  \n",
       "auc             0.741741  0.690542  0.679582  \n",
       "mcc             0.317642  0.269227  0.249209  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EI.base_summary['metrics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 663us/step\n",
      "150/150 [==============================] - 0s 648us/step\n",
      "150/150 [==============================] - 0s 641us/step\n",
      "150/150 [==============================] - 0s 663us/step\n",
      "150/150 [==============================] - 0s 674us/step\n",
      "150/150 [==============================] - 0s 665us/step\n"
     ]
    }
   ],
   "source": [
    "EI.ensemble_summary['metrics']\n",
    "y_pred = EI.predict(data, \"S.GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8789462680326156"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(np.round(y_pred), labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#EI with every modality deep\\nEI = e.EnsembleIntegration(\\n                k_outer=5,\\n                k_inner=5,\\n                n_samples=1,\\n                sampling_strategy=\"undersampling\",\\n                sampling_aggregation=None,\\n                n_jobs=-1,\\n                metrics=metrics,\\n                random_state=38,\\n                project_name=\"EI all deep\",\\n                model_building=False,\\n                )\\nfor k in data.keys():\\n    d_base_predictors = build_deep_bps(input_dim=data[k].shape[1])\\n    EI.fit_base(data[k], labels, modality_name=k, base_predictors=d_base_predictors)\\nEI.fit_ensemble(ensemble_predictors=ensemble_predictors)\\n\\nperformance[\"deep EI\"] = EI.ensemble_summary'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''#EI with every modality deep\n",
    "EI = e.EnsembleIntegration(\n",
    "                k_outer=5,\n",
    "                k_inner=5,\n",
    "                n_samples=1,\n",
    "                sampling_strategy=\"undersampling\",\n",
    "                sampling_aggregation=None,\n",
    "                n_jobs=-1,\n",
    "                metrics=metrics,\n",
    "                random_state=38,\n",
    "                project_name=\"EI all deep\",\n",
    "                model_building=False,\n",
    "                )\n",
    "for k in data.keys():\n",
    "    d_base_predictors = build_deep_bps(input_dim=data[k].shape[1])\n",
    "    EI.fit_base(data[k], labels, modality_name=k, base_predictors=d_base_predictors)\n",
    "EI.fit_ensemble(ensemble_predictors=ensemble_predictors)\n",
    "\n",
    "performance[\"deep EI\"] = EI.ensemble_summary'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'with open(\"/home/opc/eipy/eipy/performance.pkl\", \"wb\") as file:\\n    pkl.dump(obj=performance, file=file)'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''with open(\"/home/opc/eipy/eipy/performance.pkl\", \"wb\") as file:\n",
    "    pkl.dump(obj=performance, file=file)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/opc/eipy/eipy/performance.pkl\", \"rb\") as file:\n",
    "    performance = pkl.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_metrics = {k: v[\"metrics\"] for k,v in performance.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Example dictionary with DataFrames\n",
    "data_dict = performance_metrics\n",
    "\n",
    "# Specify the row index for which you want to generate the boxplot\n",
    "row_index = 'f_max'\n",
    "\n",
    "# Create a list to store the data for the boxplot\n",
    "data_list = []\n",
    "\n",
    "# Iterate through the dictionary keys and extract the row data\n",
    "for key, df in data_dict.items():\n",
    "    if row_index in df.index:\n",
    "        data_list.append(df.loc[row_index].values)\n",
    "\n",
    "# Create a DataFrame for Seaborn\n",
    "data_df = pd.DataFrame(data_list, index=data_dict.keys(), columns=df.columns)\n",
    "# Box and Whiskers Plot using Seaborn\n",
    "box_order = data_df.median(axis=1).sort_values(ascending=False).index\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=data_df.T[box_order])\n",
    "plt.title(\"Deep EI on COVID data\")\n",
    "plt.ylabel(row_index)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>CES</th>\n",
       "      <th>S.ADAB</th>\n",
       "      <th>S.XGB</th>\n",
       "      <th>S.DT</th>\n",
       "      <th>S.RF</th>\n",
       "      <th>S.GB</th>\n",
       "      <th>S.KNN</th>\n",
       "      <th>S.LR</th>\n",
       "      <th>S.NB</th>\n",
       "      <th>S.MLP</th>\n",
       "      <th>S.SVM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EI with labs deep</th>\n",
       "      <td>0.587243</td>\n",
       "      <td>0.594508</td>\n",
       "      <td>0.593472</td>\n",
       "      <td>0.582978</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.59733</td>\n",
       "      <td>0.610043</td>\n",
       "      <td>0.54303</td>\n",
       "      <td>0.600238</td>\n",
       "      <td>0.59456</td>\n",
       "      <td>0.597209</td>\n",
       "      <td>0.597865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Mean       CES    S.ADAB     S.XGB      S.DT     S.RF  \\\n",
       "EI with labs deep  0.587243  0.594508  0.593472  0.582978  0.461538  0.59733   \n",
       "\n",
       "                       S.GB    S.KNN      S.LR     S.NB     S.MLP     S.SVM  \n",
       "EI with labs deep  0.610043  0.54303  0.600238  0.59456  0.597209  0.597865  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Example dictionary with DataFrames\n",
    "data_dict = performance_metrics\n",
    "\n",
    "# Specify the row index for which you want to generate the boxplot\n",
    "row_index = 'auc'\n",
    "\n",
    "# Create a list to store the data for the boxplot\n",
    "data_list = []\n",
    "\n",
    "# Iterate through the dictionary keys and extract the row data\n",
    "for key, df in data_dict.items():\n",
    "    if row_index in df.index:\n",
    "        data_list.append(df.loc[row_index].values)\n",
    "\n",
    "# Create a DataFrame for Seaborn\n",
    "data_df = pd.DataFrame(data_list, index=data_dict.keys(), columns=df.columns)\n",
    "# Box and Whiskers Plot using Seaborn\n",
    "box_order = data_df.median(axis=1).sort_values(ascending=False).index\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=data_df.T[box_order])\n",
    "plt.ylabel(row_index)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>CES</th>\n",
       "      <th>S.ADAB</th>\n",
       "      <th>S.XGB</th>\n",
       "      <th>S.DT</th>\n",
       "      <th>S.RF</th>\n",
       "      <th>S.GB</th>\n",
       "      <th>S.KNN</th>\n",
       "      <th>S.LR</th>\n",
       "      <th>S.NB</th>\n",
       "      <th>S.MLP</th>\n",
       "      <th>S.SVM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>admission</th>\n",
       "      <td>0.761031</td>\n",
       "      <td>0.756862</td>\n",
       "      <td>0.753303</td>\n",
       "      <td>0.720673</td>\n",
       "      <td>0.579215</td>\n",
       "      <td>0.742814</td>\n",
       "      <td>0.757926</td>\n",
       "      <td>0.694064</td>\n",
       "      <td>0.771042</td>\n",
       "      <td>0.767125</td>\n",
       "      <td>0.768544</td>\n",
       "      <td>0.691569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>admission deep</th>\n",
       "      <td>0.758686</td>\n",
       "      <td>0.756817</td>\n",
       "      <td>0.757589</td>\n",
       "      <td>0.718621</td>\n",
       "      <td>0.600080</td>\n",
       "      <td>0.727212</td>\n",
       "      <td>0.753798</td>\n",
       "      <td>0.692039</td>\n",
       "      <td>0.765665</td>\n",
       "      <td>0.763349</td>\n",
       "      <td>0.765115</td>\n",
       "      <td>0.686143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EI with admission deep</th>\n",
       "      <td>0.820425</td>\n",
       "      <td>0.831318</td>\n",
       "      <td>0.820023</td>\n",
       "      <td>0.821231</td>\n",
       "      <td>0.628347</td>\n",
       "      <td>0.833407</td>\n",
       "      <td>0.836920</td>\n",
       "      <td>0.768504</td>\n",
       "      <td>0.842949</td>\n",
       "      <td>0.829779</td>\n",
       "      <td>0.831289</td>\n",
       "      <td>0.791135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comorbidities</th>\n",
       "      <td>0.574928</td>\n",
       "      <td>0.578629</td>\n",
       "      <td>0.560100</td>\n",
       "      <td>0.545048</td>\n",
       "      <td>0.520165</td>\n",
       "      <td>0.564757</td>\n",
       "      <td>0.566738</td>\n",
       "      <td>0.515650</td>\n",
       "      <td>0.586549</td>\n",
       "      <td>0.579131</td>\n",
       "      <td>0.580880</td>\n",
       "      <td>0.540861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comorbidities deep</th>\n",
       "      <td>0.586698</td>\n",
       "      <td>0.585158</td>\n",
       "      <td>0.559046</td>\n",
       "      <td>0.550285</td>\n",
       "      <td>0.543325</td>\n",
       "      <td>0.553722</td>\n",
       "      <td>0.567415</td>\n",
       "      <td>0.539949</td>\n",
       "      <td>0.582112</td>\n",
       "      <td>0.586073</td>\n",
       "      <td>0.582955</td>\n",
       "      <td>0.525751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EI with comorbidities deep</th>\n",
       "      <td>0.828858</td>\n",
       "      <td>0.833790</td>\n",
       "      <td>0.815168</td>\n",
       "      <td>0.809345</td>\n",
       "      <td>0.643609</td>\n",
       "      <td>0.830391</td>\n",
       "      <td>0.832511</td>\n",
       "      <td>0.772042</td>\n",
       "      <td>0.840393</td>\n",
       "      <td>0.832534</td>\n",
       "      <td>0.824633</td>\n",
       "      <td>0.786573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labs</th>\n",
       "      <td>0.800824</td>\n",
       "      <td>0.814680</td>\n",
       "      <td>0.800297</td>\n",
       "      <td>0.772254</td>\n",
       "      <td>0.634260</td>\n",
       "      <td>0.802590</td>\n",
       "      <td>0.813261</td>\n",
       "      <td>0.745175</td>\n",
       "      <td>0.818885</td>\n",
       "      <td>0.808592</td>\n",
       "      <td>0.815694</td>\n",
       "      <td>0.745408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labs deep</th>\n",
       "      <td>0.727711</td>\n",
       "      <td>0.738029</td>\n",
       "      <td>0.754873</td>\n",
       "      <td>0.731089</td>\n",
       "      <td>0.601849</td>\n",
       "      <td>0.743190</td>\n",
       "      <td>0.759917</td>\n",
       "      <td>0.699607</td>\n",
       "      <td>0.761392</td>\n",
       "      <td>0.746572</td>\n",
       "      <td>0.762766</td>\n",
       "      <td>0.696607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EI with labs deep</th>\n",
       "      <td>0.793817</td>\n",
       "      <td>0.792709</td>\n",
       "      <td>0.791026</td>\n",
       "      <td>0.798665</td>\n",
       "      <td>0.639818</td>\n",
       "      <td>0.809430</td>\n",
       "      <td>0.814431</td>\n",
       "      <td>0.749557</td>\n",
       "      <td>0.819380</td>\n",
       "      <td>0.803626</td>\n",
       "      <td>0.814590</td>\n",
       "      <td>0.774809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vitals</th>\n",
       "      <td>0.707028</td>\n",
       "      <td>0.701276</td>\n",
       "      <td>0.689987</td>\n",
       "      <td>0.658910</td>\n",
       "      <td>0.570378</td>\n",
       "      <td>0.678990</td>\n",
       "      <td>0.691548</td>\n",
       "      <td>0.640203</td>\n",
       "      <td>0.711458</td>\n",
       "      <td>0.710038</td>\n",
       "      <td>0.707073</td>\n",
       "      <td>0.635415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vitals deep</th>\n",
       "      <td>0.635160</td>\n",
       "      <td>0.641509</td>\n",
       "      <td>0.683378</td>\n",
       "      <td>0.637964</td>\n",
       "      <td>0.557818</td>\n",
       "      <td>0.651758</td>\n",
       "      <td>0.682620</td>\n",
       "      <td>0.621116</td>\n",
       "      <td>0.692023</td>\n",
       "      <td>0.676371</td>\n",
       "      <td>0.694733</td>\n",
       "      <td>0.645088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EI with vitals deep</th>\n",
       "      <td>0.827123</td>\n",
       "      <td>0.835537</td>\n",
       "      <td>0.821609</td>\n",
       "      <td>0.820584</td>\n",
       "      <td>0.648911</td>\n",
       "      <td>0.833033</td>\n",
       "      <td>0.838822</td>\n",
       "      <td>0.775779</td>\n",
       "      <td>0.845023</td>\n",
       "      <td>0.832592</td>\n",
       "      <td>0.838042</td>\n",
       "      <td>0.800065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EI</th>\n",
       "      <td>0.824928</td>\n",
       "      <td>0.834335</td>\n",
       "      <td>0.817057</td>\n",
       "      <td>0.817526</td>\n",
       "      <td>0.650133</td>\n",
       "      <td>0.831147</td>\n",
       "      <td>0.837252</td>\n",
       "      <td>0.769823</td>\n",
       "      <td>0.843274</td>\n",
       "      <td>0.830109</td>\n",
       "      <td>0.830340</td>\n",
       "      <td>0.789559</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Mean       CES    S.ADAB     S.XGB      S.DT  \\\n",
       "admission                   0.761031  0.756862  0.753303  0.720673  0.579215   \n",
       "admission deep              0.758686  0.756817  0.757589  0.718621  0.600080   \n",
       "EI with admission deep      0.820425  0.831318  0.820023  0.821231  0.628347   \n",
       "comorbidities               0.574928  0.578629  0.560100  0.545048  0.520165   \n",
       "comorbidities deep          0.586698  0.585158  0.559046  0.550285  0.543325   \n",
       "EI with comorbidities deep  0.828858  0.833790  0.815168  0.809345  0.643609   \n",
       "labs                        0.800824  0.814680  0.800297  0.772254  0.634260   \n",
       "labs deep                   0.727711  0.738029  0.754873  0.731089  0.601849   \n",
       "EI with labs deep           0.793817  0.792709  0.791026  0.798665  0.639818   \n",
       "vitals                      0.707028  0.701276  0.689987  0.658910  0.570378   \n",
       "vitals deep                 0.635160  0.641509  0.683378  0.637964  0.557818   \n",
       "EI with vitals deep         0.827123  0.835537  0.821609  0.820584  0.648911   \n",
       "EI                          0.824928  0.834335  0.817057  0.817526  0.650133   \n",
       "\n",
       "                                S.RF      S.GB     S.KNN      S.LR      S.NB  \\\n",
       "admission                   0.742814  0.757926  0.694064  0.771042  0.767125   \n",
       "admission deep              0.727212  0.753798  0.692039  0.765665  0.763349   \n",
       "EI with admission deep      0.833407  0.836920  0.768504  0.842949  0.829779   \n",
       "comorbidities               0.564757  0.566738  0.515650  0.586549  0.579131   \n",
       "comorbidities deep          0.553722  0.567415  0.539949  0.582112  0.586073   \n",
       "EI with comorbidities deep  0.830391  0.832511  0.772042  0.840393  0.832534   \n",
       "labs                        0.802590  0.813261  0.745175  0.818885  0.808592   \n",
       "labs deep                   0.743190  0.759917  0.699607  0.761392  0.746572   \n",
       "EI with labs deep           0.809430  0.814431  0.749557  0.819380  0.803626   \n",
       "vitals                      0.678990  0.691548  0.640203  0.711458  0.710038   \n",
       "vitals deep                 0.651758  0.682620  0.621116  0.692023  0.676371   \n",
       "EI with vitals deep         0.833033  0.838822  0.775779  0.845023  0.832592   \n",
       "EI                          0.831147  0.837252  0.769823  0.843274  0.830109   \n",
       "\n",
       "                               S.MLP     S.SVM  \n",
       "admission                   0.768544  0.691569  \n",
       "admission deep              0.765115  0.686143  \n",
       "EI with admission deep      0.831289  0.791135  \n",
       "comorbidities               0.580880  0.540861  \n",
       "comorbidities deep          0.582955  0.525751  \n",
       "EI with comorbidities deep  0.824633  0.786573  \n",
       "labs                        0.815694  0.745408  \n",
       "labs deep                   0.762766  0.696607  \n",
       "EI with labs deep           0.814590  0.774809  \n",
       "vitals                      0.707073  0.635415  \n",
       "vitals deep                 0.694733  0.645088  \n",
       "EI with vitals deep         0.838042  0.800065  \n",
       "EI                          0.830340  0.789559  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Data\n",
    "data_fmax = {\n",
    "    'admission': [0.5734265734265734, 0.5701078582434514, 0.5415617128463476, 0.5586776859504131, 0.580829756795422, 0.5531914893617021, 0.5505804311774462, 0.5929078014184397, 0.5783132530120483, 0.5763239875389408],\n",
    "    'comorbidities': [0.4399293286219082, 0.44616709732988796, 0.45276292335115864, 0.4488330341113105, 0.448, 0.44665461121157324, 0.4446381865736704, 0.43453237410071943, 0.43996494303242767, 0.44786324786324794],\n",
    "    'labs': [0.5371577574967406, 0.5903083700440529, 0.549237170596394, 0.4994663820704375, 0.5819209039548023, 0.5451851851851852, 0.5533834586466165, 0.5690140845070423, 0.56071964017991, 0.5757575757575758],\n",
    "    'vitals': [0.5413333333333333, 0.5199306759098786, 0.5006016847172082, 0.5241157556270095, 0.5346534653465347, 0.5163120567375886, 0.5050215208034433, 0.5008130081300812, 0.5333333333333333, 0.5103857566765578],\n",
    "    'EI': [0.623946037099494, 0.6388384754990926, 0.5924812030075187, 0.5745454545454546, 0.6459802538787024, 0.6376811594202898, 0.5988857938718662, 0.6324503311258278, 0.6088235294117648, 0.6319218241042345]\n",
    "}\n",
    "\n",
    "# Create a DataFrame from the data\n",
    "df_fmax = pd.DataFrame(data_fmax)\n",
    "\n",
    "# Melt the DataFrame to have 'variable' and 'value' columns\n",
    "melted_df_fmax = pd.melt(df_fmax, var_name='Box', value_name='fmax')\n",
    "\n",
    "# Order boxes by median value in descending order\n",
    "box_order_fmax = melted_df_fmax.groupby('Box')['fmax'].median().sort_values(ascending=False).index\n",
    "\n",
    "# Box and Whiskers Plot using Seaborn with sorted order\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='Box', y='fmax', data=melted_df_fmax, order=box_order_fmax)\n",
    "plt.title('fmax')\n",
    "plt.ylabel('fmax values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# New Data\n",
    "data_auc = {\n",
    "    'admission': [0.7693368960628204, 0.7763605627658414, 0.7450430799432872, 0.7462754935107427, 0.770792889082779, 0.7577980150507143, 0.7505071436361654, 0.7867052023121386, 0.7761533427854729, 0.7670302104918748],\n",
    "    'comorbidities': [0.5858681426545971, 0.6006898244083324, 0.5892790925946121, 0.6054913294797688, 0.6006434725706183, 0.6028792670956483, 0.5933962264150944, 0.5791389464499945, 0.5988330243210818, 0.5883438761042643],\n",
    "    'labs': [0.745435707274512, 0.7772576071545426, 0.7408386956047552, 0.6439551750463519, 0.7786563420220307, 0.7274511942414658, 0.729921474533755, 0.7614570836514343, 0.7573890282473552, 0.790827789289999],\n",
    "    'vitals': [0.723301341476715, 0.7141073181372014, 0.6892736394372342, 0.7114570836514342, 0.7110917221071, 0.7164358163376594, 0.6920111244410514, 0.6925019086050823, 0.7171011015377903, 0.7009870214854401],\n",
    "    'EI': [0.8165612389573564, 0.8320809248554913, 0.7991220416621223, 0.7975079070781983, 0.8307449012978515, 0.8131911876976771, 0.8019413240266113, 0.8284109499400153, 0.8158905005998474, 0.8327952884720253]\n",
    "}\n",
    "\n",
    "# Create a DataFrame from the new data\n",
    "df_auc = pd.DataFrame(data_auc)\n",
    "\n",
    "# Melt the DataFrame to have 'variable' and 'value' columns\n",
    "melted_df_auc = pd.melt(df_auc, var_name='Box', value_name='auc')\n",
    "\n",
    "# Order boxes by median value in descending order\n",
    "box_order = melted_df_auc.groupby('Box')['auc'].median().sort_values(ascending=False).index\n",
    "\n",
    "# Box and Whiskers Plot using Seaborn with sorted order\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='Box', y='auc', data=melted_df_auc, order=box_order)\n",
    "plt.title('EI vs modalities')\n",
    "plt.ylabel('AUC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EI = e.EnsembleIntegration(\n",
    "                        k_outer=5,\n",
    "                        k_inner=5,\n",
    "                        n_samples=1,\n",
    "                        sampling_strategy=\"undersampling\",\n",
    "                        sampling_aggregation=None,\n",
    "                        n_jobs=-1,\n",
    "                        metrics=metrics,\n",
    "                        random_state=38,\n",
    "                        project_name=\"diabetes\",\n",
    "                        model_building=True,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in X_train.items():\n",
    "    if k == \"xgboost\":\n",
    "        EI.fit_base(v, y_train, modality_name=k, base_predictors=d_base_predictors)\n",
    "    else:\n",
    "        EI.fit_base(v, y_train, modality_name=k, base_predictors=base_predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EI.base_summary[\"metrics\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EI.fit_ensemble(ensemble_predictors=ensemble_predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EI.ensemble_summary[\"metrics\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preferred_ensemble_key = EI.ensemble_summary[\"metrics\"].loc[\"auc\"].idxmax()\n",
    "print(preferred_ensemble_key)\n",
    "y_pred = EI.predict(X_dict=X_test, ensemble_model_key=preferred_ensemble_key)\n",
    "roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eipy.interpretation import PermutationInterpreter\n",
    "\n",
    "interpreter = PermutationInterpreter(EI=EI,\n",
    "                                     metric=lambda y_test, y_pred: roc_auc_score(y_test, y_pred),\n",
    "                                     ensemble_predictor_keys=preferred_ensemble_key,\n",
    "                                     n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EI.ensemble_predictors.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.rank_product_score(X_dict=X_test, y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
